{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the TF Agents to train the CartPole environment with DQN.\n",
    "TF Agents package makes the implementation of RL algo easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Keep using keras-2 (tf-keras) rather than keras-3 (keras).\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tf_agents\\typing\\types.py:114: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.environments import suite_gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = suite_gym.load(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.environments.wrappers.TimeLimit at 0x1591c55c050>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<OrderEnforcing<CartPoleEnv<CartPole-v1>>>>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([-0.02477055,  0.03632823,  0.01082317, -0.04031572], dtype=float32)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(1),\n",
       " 'reward': array(1., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([-0.02404399, -0.15894724,  0.01001686,  0.25576228], dtype=float32)})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore Environment Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': ArraySpec(shape=(), dtype=dtype('int32'), name='step_type'),\n",
       " 'reward': ArraySpec(shape=(), dtype=dtype('float32'), name='reward'),\n",
       " 'discount': BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0),\n",
       " 'observation': BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.discount_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(1),\n",
       " 'reward': array(1., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([-0.02404399, -0.15894724,  0.01001686,  0.25576228], dtype=float32)})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_time_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the environment with TFPyEnvironment which supports both py and tf environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments.tf_py_environment import TFPyEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TFPyEnvironment(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.environments.tf_py_environment.TFPyEnvironment at 0x1591ad5a9d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.01112201, -0.03203058, -0.03385083,  0.02849746]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.01176262, -0.22665115, -0.03328088,  0.3103108 ]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(), dtype=tf.float32, name='reward')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.discount_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.01176262, -0.22665115, -0.03328088,  0.3103108 ]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_time_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks.q_network import QNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class QNetwork in module tf_agents.networks.q_network:\n",
      "\n",
      "class QNetwork(tf_agents.networks.network.Network)\n",
      " |  QNetwork(input_tensor_spec, action_spec, preprocessing_layers=None, preprocessing_combiner=None, conv_layer_params=None, fc_layer_params=(75, 40), dropout_layer_params=None, activation_fn=<function relu at 0x000001591A638040>, kernel_initializer=None, batch_squash=True, dtype=tf.float32, q_layer_activation_fn=None, name='QNetwork')\n",
      " |  \n",
      " |  Feed Forward network.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      QNetwork\n",
      " |      tf_agents.networks.network.Network\n",
      " |      tf_keras.src.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      tf_keras.src.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_tensor_spec, action_spec, preprocessing_layers=None, preprocessing_combiner=None, conv_layer_params=None, fc_layer_params=(75, 40), dropout_layer_params=None, activation_fn=<function relu at 0x000001591A638040>, kernel_initializer=None, batch_squash=True, dtype=tf.float32, q_layer_activation_fn=None, name='QNetwork')\n",
      " |      Creates an instance of `QNetwork`.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_tensor_spec: A nest of `tensor_spec.TensorSpec` representing the\n",
      " |          input observations.\n",
      " |        action_spec: A nest of `tensor_spec.BoundedTensorSpec` representing the\n",
      " |          actions.\n",
      " |        preprocessing_layers: (Optional.) A nest of `tf.keras.layers.Layer`\n",
      " |          representing preprocessing for the different observations. All of these\n",
      " |          layers must not be already built. For more details see the documentation\n",
      " |          of `networks.EncodingNetwork`.\n",
      " |        preprocessing_combiner: (Optional.) A keras layer that takes a flat list\n",
      " |          of tensors and combines them. Good options include `tf.keras.layers.Add`\n",
      " |          and `tf.keras.layers.Concatenate(axis=-1)`. This layer must not be\n",
      " |          already built. For more details see the documentation of\n",
      " |          `networks.EncodingNetwork`.\n",
      " |        conv_layer_params: Optional list of convolution layers parameters, where\n",
      " |          each item is a length-three tuple indicating (filters, kernel_size,\n",
      " |          stride).\n",
      " |        fc_layer_params: Optional list of fully_connected parameters, where each\n",
      " |          item is the number of units in the layer.\n",
      " |        dropout_layer_params: Optional list of dropout layer parameters, where\n",
      " |          each item is the fraction of input units to drop. The dropout layers are\n",
      " |          interleaved with the fully connected layers; there is a dropout layer\n",
      " |          after each fully connected layer, except if the entry in the list is\n",
      " |          None. This list must have the same length of fc_layer_params, or be\n",
      " |          None.\n",
      " |        activation_fn: Activation function, e.g. tf.keras.activations.relu.\n",
      " |        kernel_initializer: Initializer to use for the kernels of the conv and\n",
      " |          dense layers. If none is provided a default variance_scaling_initializer\n",
      " |        batch_squash: If True the outer_ranks of the observation are squashed into\n",
      " |          the batch dimension. This allow encoding networks to be used with\n",
      " |          observations with shape [BxTx...].\n",
      " |        dtype: The dtype to use by the convolution and fully connected layers.\n",
      " |        q_layer_activation_fn: Activation function for the Q layer.\n",
      " |        name: A string representing the name of the network.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `input_tensor_spec` contains more than one observation. Or\n",
      " |          if `action_spec` contains more than one action.\n",
      " |  \n",
      " |  call(self, observation, step_type=None, network_state=(), training=False)\n",
      " |      Runs the given observation through the network.\n",
      " |      \n",
      " |      Args:\n",
      " |        observation: The observation to provide to the network.\n",
      " |        step_type: The step type for the given observation. See `StepType` in\n",
      " |          time_step.py.\n",
      " |        network_state: A state tuple to pass to the network, mainly used by RNNs.\n",
      " |        training: Whether the output is being used for training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple `(logits, network_state)`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tf_agents.networks.network.Network:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      A wrapper around `Network.call`.\n",
      " |      \n",
      " |      A typical `call` method in a class subclassing `Network` will have a\n",
      " |      signature that accepts `inputs`, as well as other `*args` and `**kwargs`.\n",
      " |      `call` can optionally also accept `step_type` and `network_state`\n",
      " |      (if `state_spec != ()` is not trivial).  e.g.:\n",
      " |      \n",
      " |      ```python\n",
      " |      def call(self,\n",
      " |               inputs,\n",
      " |               step_type=None,\n",
      " |               network_state=(),\n",
      " |               training=False):\n",
      " |          ...\n",
      " |          return outputs, new_network_state\n",
      " |      ```\n",
      " |      \n",
      " |      We will validate the first argument (`inputs`)\n",
      " |      against `self.input_tensor_spec` if one is available.\n",
      " |      \n",
      " |      If a `network_state` kwarg is given it is also validated against\n",
      " |      `self.state_spec`.  Similarly, the return value of the `call` method is\n",
      " |      expected to be a tuple/list with 2 values:  `(output, new_state)`.\n",
      " |      We validate `new_state` against `self.state_spec`.\n",
      " |      \n",
      " |      If no `network_state` kwarg is given (or if empty `network_state = ()` is\n",
      " |      given, it is up to `call` to assume a proper \"empty\" state, and to\n",
      " |      emit an appropriate `output_state`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: The input to `self.call`, matching `self.input_tensor_spec`.\n",
      " |        *args: Additional arguments to `self.call`.\n",
      " |        **kwargs: Additional keyword arguments to `self.call`. These can include\n",
      " |          `network_state` and `step_type`.  `step_type` is required if the\n",
      " |          network's `call` requires it. `network_state` is required if the\n",
      " |          underlying network's `call` requires it.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple `(outputs, new_network_state)`.\n",
      " |  \n",
      " |  copy(self, **kwargs)\n",
      " |      Create a shallow copy of this network.\n",
      " |      \n",
      " |      **NOTE** Network layer weights are *never* copied.  This method recreates\n",
      " |      the `Network` instance with the same arguments it was initialized with\n",
      " |      (excepting any new kwargs).\n",
      " |      \n",
      " |      Args:\n",
      " |        **kwargs: Args to override when recreating this network.  Commonly\n",
      " |          overridden args include 'name'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A shallow copy of this network.\n",
      " |  \n",
      " |  create_variables(self, input_tensor_spec=None, **kwargs)\n",
      " |      Force creation of the network's variables.\n",
      " |      \n",
      " |      Return output specs.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_tensor_spec: (Optional).  Override or provide an input tensor spec\n",
      " |          when creating variables.\n",
      " |        **kwargs: Other arguments to `network.call()`, e.g. `training=True`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output specs - a nested spec calculated from the outputs (excluding any\n",
      " |        batch dimensions).  If any of the output elements is a tfp `Distribution`,\n",
      " |        the associated spec entry returned is a `DistributionSpec`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If no `input_tensor_spec` is provided, and the network did\n",
      " |          not provide one during construction.\n",
      " |  \n",
      " |  get_initial_state(self, batch_size=None)\n",
      " |      Returns an initial state usable by the network.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: Tensor or constant: size of the batch dimension. Can be None\n",
      " |          in which case not dimensions gets added.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A nested object of type `self.state_spec` containing properly\n",
      " |        initialized Tensors.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Args:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Args:\n",
      " |          line_length: Total length of printed lines (e.g. set this to adapt the\n",
      " |            display to different terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements in each line.\n",
      " |            If not provided, defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`. It will be called\n",
      " |            on each line of the summary. You can set it to a custom function in\n",
      " |            order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tf_agents.networks.network.Network:\n",
      " |  \n",
      " |  input_tensor_spec\n",
      " |      Returns the spec of the input to the network of type InputSpec.\n",
      " |  \n",
      " |  layers\n",
      " |      Get the list of all (nested) sub-layers used in this Network.\n",
      " |  \n",
      " |  state_spec\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
      " |      not themselves TF-Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tf_keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be\n",
      " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
      " |      the same layer on different inputs `a` and `b`, some entries in\n",
      " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
      " |      automatically keeps track of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      The same code works in distributed training: the input to `add_loss()`\n",
      " |      is treated like a regularization loss and averaged across replicas\n",
      " |      by the training loop (both built-in `Model.fit()` and compliant custom\n",
      " |      training loops).\n",
      " |      \n",
      " |      The `add_loss` method can also be called directly on a Functional Model\n",
      " |      during construction. In this case, any loss Tensors passed to this Model\n",
      " |      must be symbolic and be able to be traced back to the model's `Input`s.\n",
      " |      These losses become part of the model's topology and are tracked in\n",
      " |      `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss\n",
      " |      references a `Variable` of one of the model's layers), you can wrap your\n",
      " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
      " |      the model's topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
      " |          losses may also be zero-argument callables which create a loss\n",
      " |          tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This\n",
      " |      is because we cannot trace the metric result tensor back to the model's\n",
      " |      inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result\n",
      " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
      " |          default using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and\n",
      " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
      " |      passed when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case,\n",
      " |      variable updates are run on the fly and thus do not need to be tracked\n",
      " |      for later execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use a `ResourceVariable` or not.\n",
      " |          See [this guide](\n",
      " |          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
      " |           for more information.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set\n",
      " |          to `AUTO` and the current `DistributionStrategy` chooses when to\n",
      " |          synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n",
      " |          must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as\n",
      " |          `ON_READ`.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call. It is invoked automatically before\n",
      " |      the first execution of `call()`.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses\n",
      " |      (at the discretion of the subclass implementer).\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  build_from_config(self, config)\n",
      " |      Builds the layer's states with the supplied config dict.\n",
      " |      \n",
      " |      By default, this method calls the `build(config[\"input_shape\"])` method,\n",
      " |      which creates weights based on the layer's input shape in the supplied\n",
      " |      config. If your config contains other information needed to load the\n",
      " |      layer's state, you should override this method.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: Dict containing the input shape associated with this layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,\n",
      " |              or structure of shape tuples / `tf.TensorShape` instances\n",
      " |              (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `tf.TensorShape` instance\n",
      " |          or structure of `tf.TensorShape` instances.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
      " |          describing how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after\n",
      " |      updating a layer weights. It can be overridden to finalize any\n",
      " |      additional layer state after a weight update.\n",
      " |      \n",
      " |      This function will be called after weights of a layer have been restored\n",
      " |      from a loaded model.\n",
      " |  \n",
      " |  get_build_config(self)\n",
      " |      Returns a dictionary with the layer's input shape.\n",
      " |      \n",
      " |      This method returns a config dict that can be used by\n",
      " |      `build_from_config(config)` to create all states (e.g. Variables and\n",
      " |      Lookup tables) needed by the layer.\n",
      " |      \n",
      " |      By default, the config only contains the input shape that the layer\n",
      " |      was built with. If you're writing a custom layer that creates state in\n",
      " |      an unusual way, you should override this method to make sure this state\n",
      " |      is already created when TF-Keras attempts to load its value upon model\n",
      " |      loading.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict containing the input shape associated with the layer.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of\n",
      " |      dict every time it is called. The callers should make a copy of the\n",
      " |      returned dict if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with\n",
      " |      this layer as a list of NumPy arrays, which can in turn be used to load\n",
      " |      state into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  load_own_variables(self, store)\n",
      " |      Loads the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is loaded upon calling `keras.models.load_model()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict from which the state of the model will be loaded.\n",
      " |  \n",
      " |  save_own_variables(self, store)\n",
      " |      Saves the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is saved upon calling `model.save()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict where the state of the model will be saved.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tf_keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config)\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tf_keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tf_keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which\n",
      " |      causes computations and the output to be in the compute dtype as well.\n",
      " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
      " |      have to insert these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision\n",
      " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
      " |      output will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is\n",
      " |      accessed, so it is eager safe: accessing `losses` under a\n",
      " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
      " |      variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics attached to the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are\n",
      " |      expected to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tf_keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to\n",
      " |      enable the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
      " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a\n",
      " |      nicely-formatted error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method)\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(QNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_net = QNetwork(env.observation_spec(), env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.agents.dqn.dqn_agent import DqnAgent\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DqnAgent in module tf_agents.agents.dqn.dqn_agent:\n",
      "\n",
      "class DqnAgent(tf_agents.agents.tf_agent.TFAgent)\n",
      " |  DqnAgent(time_step_spec: tf_agents.trajectories.time_step.TimeStep, action_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')]], q_network: tf_agents.networks.network.Network, optimizer: Union[tf_keras.src.optimizers.optimizer.Optimizer, tensorflow.python.training.optimizer.Optimizer], observation_and_action_constraint_splitter: Optional[Callable[[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]], Iterable[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]]]] = None, epsilon_greedy: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = 0.1, n_step_update: int = 1, boltzmann_temperature: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = None, emit_log_probability: bool = False, target_q_network: Optional[tf_agents.networks.network.Network] = None, target_update_tau: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, target_update_period: int = 1, td_errors_loss_fn: Optional[Callable[..., Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor]]] = None, gamma: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, reward_scale_factor: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, gradient_clipping: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, NoneType] = None, debug_summaries: bool = False, summarize_grads_and_vars: bool = False, train_step_counter: Optional[tensorflow.python.ops.variables.Variable] = None, training_data_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], NoneType] = None, name: Optional[str] = None)\n",
      " |  \n",
      " |  A DQN Agent.\n",
      " |  \n",
      " |  Implements the DQN algorithm from\n",
      " |  \n",
      " |  \"Human level control through deep reinforcement learning\"\n",
      " |    Mnih et al., 2015\n",
      " |    https://deepmind.com/research/dqn/\n",
      " |  \n",
      " |  This agent also implements n-step updates. See \"Rainbow: Combining\n",
      " |  Improvements in Deep Reinforcement Learning\" by Hessel et al., 2017, for a\n",
      " |  discussion on its benefits: https://arxiv.org/abs/1710.02298\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DqnAgent\n",
      " |      tf_agents.agents.tf_agent.TFAgent\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, time_step_spec: tf_agents.trajectories.time_step.TimeStep, action_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')]], q_network: tf_agents.networks.network.Network, optimizer: Union[tf_keras.src.optimizers.optimizer.Optimizer, tensorflow.python.training.optimizer.Optimizer], observation_and_action_constraint_splitter: Optional[Callable[[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]], Iterable[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]]]] = None, epsilon_greedy: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = 0.1, n_step_update: int = 1, boltzmann_temperature: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = None, emit_log_probability: bool = False, target_q_network: Optional[tf_agents.networks.network.Network] = None, target_update_tau: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, target_update_period: int = 1, td_errors_loss_fn: Optional[Callable[..., Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor]]] = None, gamma: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, reward_scale_factor: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, gradient_clipping: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, NoneType] = None, debug_summaries: bool = False, summarize_grads_and_vars: bool = False, train_step_counter: Optional[tensorflow.python.ops.variables.Variable] = None, training_data_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], NoneType] = None, name: Optional[str] = None)\n",
      " |      Creates a DQN Agent.\n",
      " |      \n",
      " |      Args:\n",
      " |        time_step_spec: A `TimeStep` spec of the expected time_steps.\n",
      " |        action_spec: A nest of BoundedTensorSpec representing the actions.\n",
      " |        q_network: A `tf_agents.network.Network` to be used by the agent. The\n",
      " |          network will be called with `call(observation, step_type)` and should\n",
      " |          emit logits over the action space.\n",
      " |        optimizer: The optimizer to use for training.\n",
      " |        observation_and_action_constraint_splitter: A function used to process\n",
      " |          observations with action constraints. These constraints can indicate,\n",
      " |          for example, a mask of valid/invalid actions for a given state of the\n",
      " |          environment. The function takes in a full observation and returns a\n",
      " |          tuple consisting of 1) the part of the observation intended as input to\n",
      " |          the network and 2) the constraint. An example\n",
      " |          `observation_and_action_constraint_splitter` could be as simple as: ```\n",
      " |          def observation_and_action_constraint_splitter(observation): return\n",
      " |          observation['network_input'], observation['constraint'] ``` *Note*: when\n",
      " |          using `observation_and_action_constraint_splitter`, make sure the\n",
      " |          provided `q_network` is compatible with the network-specific half of the\n",
      " |          output of the `observation_and_action_constraint_splitter`. In\n",
      " |          particular, `observation_and_action_constraint_splitter` will be called\n",
      " |          on the observation before passing to the network. If\n",
      " |          `observation_and_action_constraint_splitter` is None, action constraints\n",
      " |          are not applied.\n",
      " |        epsilon_greedy: probability of choosing a random action in the default\n",
      " |          epsilon-greedy collect policy (used only if a wrapper is not provided to\n",
      " |          the collect_policy method). Only one of epsilon_greedy and\n",
      " |          boltzmann_temperature should be provided.\n",
      " |        n_step_update: The number of steps to consider when computing TD error and\n",
      " |          TD loss. Defaults to single-step updates. Note that this requires the\n",
      " |          user to call train on Trajectory objects with a time dimension of\n",
      " |          `n_step_update + 1`. However, note that we do not yet support\n",
      " |          `n_step_update > 1` in the case of RNNs (i.e., non-empty\n",
      " |          `q_network.state_spec`).\n",
      " |        boltzmann_temperature: Temperature value to use for Boltzmann sampling of\n",
      " |          the actions during data collection. The closer to 0.0, the higher the\n",
      " |          probability of choosing the best action. Only one of epsilon_greedy and\n",
      " |          boltzmann_temperature should be provided.\n",
      " |        emit_log_probability: Whether policies emit log probabilities or not.\n",
      " |        target_q_network: (Optional.)  A `tf_agents.network.Network` to be used as\n",
      " |          the target network during Q learning.  Every `target_update_period`\n",
      " |          train steps, the weights from `q_network` are copied (possibly with\n",
      " |          smoothing via `target_update_tau`) to `target_q_network`.  If\n",
      " |          `target_q_network` is not provided, it is created by making a copy of\n",
      " |          `q_network`, which initializes a new network with the same structure and\n",
      " |          its own layers and weights.  Network copying is performed via the\n",
      " |          `Network.copy` superclass method, and may inadvertently lead to the\n",
      " |          resulting network to share weights with the original.  This can happen\n",
      " |          if, for example, the original network accepted a pre-built Keras layer\n",
      " |          in its `__init__`, or accepted a Keras layer that wasn't built, but\n",
      " |          neglected to create a new copy.  In these cases, it is up to you to\n",
      " |          provide a target Network having weights that are not shared with the\n",
      " |          original `q_network`. If you provide a `target_q_network` that shares\n",
      " |          any weights with `q_network`, a warning will be logged but no exception\n",
      " |          is thrown.  Note; shallow copies of Keras layers may be built via the\n",
      " |          code ```python new_layer =\n",
      " |          type(layer).from_config(layer.get_config())```\n",
      " |        target_update_tau: Factor for soft update of the target networks.\n",
      " |        target_update_period: Period for soft update of the target networks.\n",
      " |        td_errors_loss_fn: A function for computing the TD errors loss. If None, a\n",
      " |          default value of element_wise_huber_loss is used. This function takes as\n",
      " |          input the target and the estimated Q values and returns the loss for\n",
      " |          each element of the batch.\n",
      " |        gamma: A discount factor for future rewards.\n",
      " |        reward_scale_factor: Multiplicative scale for the reward.\n",
      " |        gradient_clipping: Norm length to clip gradients.\n",
      " |        debug_summaries: A bool to gather debug summaries.\n",
      " |        summarize_grads_and_vars: If True, gradient and network variable summaries\n",
      " |          will be written during training.\n",
      " |        train_step_counter: An optional counter to increment every time the train\n",
      " |          op is run.  Defaults to the global_step.\n",
      " |        training_data_spec: A nest of TensorSpec specifying the structure of data\n",
      " |          the train() function expects. If None, defaults to the trajectory_spec\n",
      " |          of the collect_policy.\n",
      " |        name: The name of this agent. All variables in this module will fall under\n",
      " |          that name. Defaults to the class name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `action_spec` contains more than one action or action\n",
      " |          spec minimum is not equal to 0.\n",
      " |        ValueError: If the q networks do not emit floating point outputs with\n",
      " |          inner shape matching `action_spec`.\n",
      " |        NotImplementedError: If `q_network` has non-empty `state_spec` (i.e., an\n",
      " |          RNN is provided) and `n_step_update > 1`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tf_agents.agents.tf_agent.TFAgent:\n",
      " |  \n",
      " |  initialize(self) -> Optional[tensorflow.python.framework.ops.Operation]\n",
      " |      Initializes the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An operation that can be used to initialize the agent.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  loss(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], weights: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, NoneType] = None, training: bool = False, **kwargs) -> tf_agents.agents.tf_agent.LossInfo\n",
      " |      Gets loss from the agent.\n",
      " |      \n",
      " |      If the user calls this from _train, it must be in a `tf.GradientTape` scope\n",
      " |      in order to apply gradients to trainable variables.\n",
      " |      If intermediate gradient steps are needed, _loss and _train will return\n",
      " |      different values since _loss only supports updating all gradients at once\n",
      " |      after all losses have been calculated.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: A batch of experience data in the form of a `Trajectory`. The\n",
      " |          structure of `experience` must match that of `self.training_data_spec`.\n",
      " |          All tensors in `experience` must be shaped `[batch, time, ...]` where\n",
      " |          `time` must be equal to `self.train_step_length` if that property is not\n",
      " |          `None`.\n",
      " |        weights: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`,\n",
      " |          containing weights to be used when calculating the total train loss.\n",
      " |          Weights are typically multiplied elementwise against the per-batch loss,\n",
      " |          but the implementation is up to the Agent.\n",
      " |        training: Explicit argument to pass to `loss`. This typically affects\n",
      " |          network computation paths like dropout and batch normalization.\n",
      " |        **kwargs: Any additional data as args to `loss`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `LossInfo` loss tuple containing loss and info tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  post_process_policy(self) -> tf_agents.policies.tf_policy.TFPolicy\n",
      " |      Post process policies after training.\n",
      " |      \n",
      " |      The policies of some agents require expensive post processing after training\n",
      " |      before they can be used. e.g. A Recommender agent might require rebuilding\n",
      " |      an index of actions. For such agents, this method will return a post\n",
      " |      processed version of the policy. The post processing may either update the\n",
      " |      existing policies in place or create a new policy, depnding on the agent.\n",
      " |      The default implementation for agents that do not want to override this\n",
      " |      method is to return agent.policy.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The post processed policy.\n",
      " |  \n",
      " |  preprocess_sequence(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]]) -> Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]]\n",
      " |      Defines preprocess_sequence function to be fed into replay buffers.\n",
      " |      \n",
      " |      This defines how we preprocess the collected data before training.\n",
      " |      Defaults to pass through for most agents.\n",
      " |      Structure of `experience` must match that of `self.collect_data_spec`.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: a `Trajectory` shaped [batch, time, ...] or [time, ...] which\n",
      " |          represents the collected experience data.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A post processed `Trajectory` with the same shape as the input.\n",
      " |  \n",
      " |  train(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], weights: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, NoneType] = None, **kwargs) -> tf_agents.agents.tf_agent.LossInfo\n",
      " |      Trains the agent.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: A batch of experience data in the form of a `Trajectory`. The\n",
      " |          structure of `experience` must match that of `self.training_data_spec`.\n",
      " |          All tensors in `experience` must be shaped `[batch, time, ...]` where\n",
      " |          `time` must be equal to `self.train_step_length` if that property is not\n",
      " |          `None`.\n",
      " |        weights: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`,\n",
      " |          containing weights to be used when calculating the total train loss.\n",
      " |          Weights are typically multiplied elementwise against the per-batch loss,\n",
      " |          but the implementation is up to the Agent.\n",
      " |        **kwargs: Any additional data to pass to the subclass.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `LossInfo` loss tuple containing loss and info tensors.\n",
      " |          - In eager mode, the loss values are first calculated, then a train step\n",
      " |            is performed before they are returned.\n",
      " |          - In graph mode, executing any or all of the loss tensors\n",
      " |            will first calculate the loss value(s), then perform a train step,\n",
      " |            and return the pre-train-step `LossInfo`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tf_agents.agents.tf_agent.TFAgent:\n",
      " |  \n",
      " |  action_spec\n",
      " |      TensorSpec describing the action produced by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An single BoundedTensorSpec, or a nested dict, list or tuple of\n",
      " |        `BoundedTensorSpec` objects, which describe the shape and\n",
      " |        dtype of each action Tensor.\n",
      " |  \n",
      " |  collect_data_context\n",
      " |  \n",
      " |  collect_data_spec\n",
      " |      Returns a `Trajectory` spec, as expected by the `collect_policy`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Trajectory` spec.\n",
      " |  \n",
      " |  collect_policy\n",
      " |      Return a policy that can be used to collect data from the environment.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf_policy.TFPolicy` object.\n",
      " |  \n",
      " |  data_context\n",
      " |  \n",
      " |  debug_summaries\n",
      " |  \n",
      " |  policy\n",
      " |      Return the current policy held by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf_policy.TFPolicy` object.\n",
      " |  \n",
      " |  summaries_enabled\n",
      " |  \n",
      " |  summarize_grads_and_vars\n",
      " |  \n",
      " |  time_step_spec\n",
      " |      Describes the `TimeStep` tensors expected by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `TimeStep` namedtuple with `TensorSpec` objects instead of Tensors,\n",
      " |        which describe the shape, dtype and name of each tensor.\n",
      " |  \n",
      " |  train_sequence_length\n",
      " |      The number of time steps needed in experience tensors passed to `train`.\n",
      " |      \n",
      " |      Train requires experience to be a `Trajectory` containing tensors shaped\n",
      " |      `[B, T, ...]`.  This argument describes the value of `T` required.\n",
      " |      \n",
      " |      For example, for non-RNN DQN training, `T=2` because DQN requires single\n",
      " |      transitions.\n",
      " |      \n",
      " |      If this value is `None`, then `train` can handle an unknown `T` (it can be\n",
      " |      determined at runtime from the data).  Most RNN-based agents fall into\n",
      " |      this category.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The number of time steps needed in experience tensors passed to `train`.\n",
      " |        May be `None` to mean no constraint.\n",
      " |  \n",
      " |  train_step_counter\n",
      " |  \n",
      " |  training_data_spec\n",
      " |      Returns a trajectory spec, as expected by the train() function.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method)\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  variables\n",
      " |      Sequence of variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.trackable.autotrackable.AutoTrackable:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DqnAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "discount_factor = 1\n",
    "epsilon_fn = PolynomialDecay(\n",
    "    initial_learning_rate=1.0,\n",
    "    decay_steps=1000,\n",
    "    end_learning_rate=0.01,\n",
    "    power=1\n",
    "    )\n",
    "target_model_update = 1\n",
    "train_step = tf.Variable(0)\n",
    "\n",
    "agent = DqnAgent(\n",
    "    env.time_step_spec(),\n",
    "    env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    epsilon_greedy=lambda:epsilon_fn(train_step),\n",
    "    train_step_counter=train_step,\n",
    "    gamma=discount_factor,\n",
    "    target_update_period=target_model_update\n",
    "    )\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.greedy_policy.GreedyPolicy at 0x15913b2b590>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Replay Buffer to store experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.replay_buffers.tf_uniform_replay_buffer import TFUniformReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32)),\n",
       " 'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = TFUniformReplayBuffer(\n",
    "    data_spec= agent.collect_data_spec,\n",
    "    batch_size= env.batch_size,\n",
    "    max_length= 100000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an observer to write into the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer_observer = replay_buffer.add_batch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer at 0x1591eabff10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ReplayBuffer.add_batch of <tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer object at 0x000001591EABFF10>>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer_observer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Driver that explores environment using a given policy, collects experience and broadcast them to observer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver\n",
    "from tf_agents.metrics import tf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = [\n",
    "    tf_metrics.AverageReturnMetric()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_driver = DynamicStepDriver(\n",
    "    env=env,\n",
    "    policy= agent.collect_policy,\n",
    "    observers= [replay_buffer_observer] + train_metrics,\n",
    "    num_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metrics[0].result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a driver to just fill the replay buffer with some experiences with a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_collect_policy = RandomTFPolicy(env.time_step_spec(), env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.random_tf_policy.RandomTFPolicy at 0x1591c69a650>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_driver = DynamicStepDriver(\n",
    "    env,\n",
    "    initial_collect_policy,\n",
    "    [replay_buffer_observer],\n",
    "    num_steps=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time_step, final_policy_state = initial_driver.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([2])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.08334601, -0.43385312,  0.21460758,  1.1857538 ]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_policy_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset of sample a batch of trajectories for agent to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.trajectories.trajectory import to_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iitka\\AppData\\Local\\Temp\\ipykernel_25812\\3194907317.py:1: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "trajectories, buffer_info = replay_buffer.get_next(sample_batch_size=2, num_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[ 0.00804686, -0.00561635, -0.10083202, -0.16280498],\n",
       "        [ 0.00793454,  0.19079366, -0.10408812, -0.485518  ],\n",
       "        [ 0.01175041,  0.3872186 , -0.11379848, -0.8091074 ]],\n",
       "\n",
       "       [[-0.00754528, -0.19310214, -0.04984554,  0.24757186],\n",
       "        [-0.01140732, -0.38747808, -0.04489411,  0.5241251 ],\n",
       "        [-0.01915688, -0.5819404 , -0.03441161,  0.8023303 ]]],\n",
       "      dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "array([[1, 1, 0],\n",
       "       [0, 0, 0]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BufferInfo(ids=<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "array([[381, 382, 383],\n",
       "       [125, 126, 127]], dtype=int64)>, probabilities=<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00096154, 0.00096154], dtype=float32)>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps, action_steps, next_time_steps = to_transition(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(2, 2, 4), dtype=float32, numpy=\n",
       "array([[[ 0.00804686, -0.00561635, -0.10083202, -0.16280498],\n",
       "        [ 0.00793454,  0.19079366, -0.10408812, -0.485518  ]],\n",
       "\n",
       "       [[-0.00754528, -0.19310214, -0.04984554,  0.24757186],\n",
       "        [-0.01140732, -0.38747808, -0.04489411,  0.5241251 ]]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=<tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
       "array([[1, 1],\n",
       "       [0, 0]], dtype=int64)>, state=(), info=())"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=64,\n",
    "    num_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(Trajectory(\n",
       "{'step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
       " 'observation': TensorSpec(shape=(64, 2, 4), dtype=tf.float32, name=None),\n",
       " 'action': TensorSpec(shape=(64, 2), dtype=tf.int64, name=None),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
       " 'reward': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None),\n",
       " 'discount': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None)}), BufferInfo(ids=TensorSpec(shape=(64, 2), dtype=tf.int64, name=None), probabilities=TensorSpec(shape=(64,), dtype=tf.float32, name=None)))>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x159209b3410>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1]])>,\n",
       "  'observation': <tf.Tensor: shape=(64, 2, 4), dtype=float32, numpy=\n",
       " array([[[-1.44914716e-01, -5.75911105e-01, -9.72824395e-02,\n",
       "          -8.44163727e-03],\n",
       "         [-1.56432942e-01, -7.69513011e-01, -9.74512696e-02,\n",
       "           2.52032220e-01]],\n",
       " \n",
       "        [[ 1.66737789e-03, -6.30956471e-01,  3.95696163e-02,\n",
       "           9.75523949e-01],\n",
       "         [-1.09517509e-02, -8.26586187e-01,  5.90800941e-02,\n",
       "           1.28036928e+00]],\n",
       " \n",
       "        [[-1.31225139e-02, -4.26792413e-01,  2.59159282e-02,\n",
       "           6.02819383e-01],\n",
       "         [-2.16583628e-02, -6.22267067e-01,  3.79723161e-02,\n",
       "           9.03551340e-01]],\n",
       " \n",
       "        [[-6.68304563e-02, -8.27640474e-01,  1.81587487e-01,\n",
       "           1.64024913e+00],\n",
       "         [-8.33832696e-02, -6.35051489e-01,  2.14392468e-01,\n",
       "           1.40920913e+00]],\n",
       " \n",
       "        [[ 3.78120653e-02, -7.47713586e-03, -6.98254909e-03,\n",
       "          -5.29464427e-03],\n",
       "         [ 3.76625247e-02,  1.87744260e-01, -7.08844187e-03,\n",
       "          -3.00172448e-01]],\n",
       " \n",
       "        [[ 1.86030995e-02,  1.89908251e-01,  5.53814210e-02,\n",
       "          -1.95071191e-01],\n",
       "         [ 2.24012639e-02,  3.84196073e-01,  5.14799990e-02,\n",
       "          -4.69782293e-01]],\n",
       " \n",
       "        [[ 5.62277203e-03,  5.80295563e-01,  1.17636152e-01,\n",
       "          -4.13220286e-01],\n",
       "         [ 1.72286835e-02,  3.83719742e-01,  1.09371744e-01,\n",
       "          -8.58890787e-02]],\n",
       " \n",
       "        [[-8.03333148e-02, -5.86888731e-01,  5.24829850e-02,\n",
       "           8.19173157e-01],\n",
       "         [-9.20710862e-02, -3.92522871e-01,  6.88664466e-02,\n",
       "           5.43448746e-01]],\n",
       " \n",
       "        [[ 7.43561238e-02,  6.05220556e-01, -2.11308405e-01,\n",
       "          -1.51554298e+00],\n",
       "         [-4.80240397e-02,  7.86330458e-03, -2.87803616e-02,\n",
       "          -2.20941473e-02]],\n",
       " \n",
       "        [[ 5.65110818e-02,  9.88629341e-01, -1.48581341e-01,\n",
       "          -1.42110109e+00],\n",
       "         [ 7.62836635e-02,  7.95624852e-01, -1.77003369e-01,\n",
       "          -1.17830646e+00]],\n",
       " \n",
       "        [[-3.94268297e-02,  1.58650428e-01, -4.65370864e-02,\n",
       "          -3.50783557e-01],\n",
       "         [-3.62538211e-02, -3.57798710e-02, -5.35527542e-02,\n",
       "          -7.31308088e-02]],\n",
       " \n",
       "        [[ 5.99370375e-02,  4.60701901e-03,  2.28743367e-02,\n",
       "           9.09028947e-02],\n",
       "         [ 6.00291789e-02, -1.90835208e-01,  2.46923938e-02,\n",
       "           3.90713990e-01]],\n",
       " \n",
       "        [[-3.22878920e-02,  2.31017321e-01, -1.41162733e-02,\n",
       "          -3.24867219e-01],\n",
       "         [-2.76675466e-02,  3.60991769e-02, -2.06136182e-02,\n",
       "          -3.66691872e-02]],\n",
       " \n",
       "        [[-6.22336790e-02, -4.29373175e-01,  1.64802879e-01,\n",
       "           1.07534909e+00],\n",
       "         [-7.08211437e-02, -6.26243293e-01,  1.86309859e-01,\n",
       "           1.41488612e+00]],\n",
       " \n",
       "        [[ 2.45448686e-02,  5.12979925e-02, -1.27245665e-01,\n",
       "          -3.74786347e-01],\n",
       "         [ 2.55708285e-02,  2.47976050e-01, -1.34741381e-01,\n",
       "          -7.04727650e-01]],\n",
       " \n",
       "        [[ 4.48746746e-03,  1.50061086e-01, -2.38151290e-02,\n",
       "          -3.29314262e-01],\n",
       "         [ 7.48868939e-03,  3.45513821e-01, -3.04014143e-02,\n",
       "          -6.29411221e-01]],\n",
       " \n",
       "        [[ 1.74345691e-02, -3.89393181e-01,  1.01101264e-01,\n",
       "           7.62446940e-01],\n",
       "         [ 9.64670628e-03, -5.85751593e-01,  1.16350204e-01,\n",
       "           1.08515370e+00]],\n",
       " \n",
       "        [[ 5.54923620e-03, -7.86426306e-01,  8.22538435e-02,\n",
       "           1.21356940e+00],\n",
       "         [-1.01792896e-02, -9.82507646e-01,  1.06525235e-01,\n",
       "           1.53085244e+00]],\n",
       " \n",
       "        [[-1.13663040e-02, -3.98240745e-01,  3.31095839e-03,\n",
       "           5.78240991e-01],\n",
       "         [-1.93311181e-02, -2.03165352e-01,  1.48757780e-02,\n",
       "           2.86602914e-01]],\n",
       " \n",
       "        [[ 3.77822667e-01,  3.43472391e-01, -1.47316739e-01,\n",
       "          -1.76525533e-01],\n",
       "         [ 3.84692132e-01,  5.40361822e-01, -1.50847256e-01,\n",
       "          -5.11815369e-01]],\n",
       " \n",
       "        [[-6.23389222e-02, -4.29982878e-02,  1.16989881e-01,\n",
       "           3.29623908e-01],\n",
       "         [-6.31988868e-02,  1.50280818e-01,  1.23582363e-01,\n",
       "           7.60036036e-02]],\n",
       " \n",
       "        [[-1.86851352e-01, -4.06814933e-01,  2.20492870e-01,\n",
       "           8.77205312e-01],\n",
       "         [-3.07503883e-02, -4.68969867e-02, -1.03616407e-02,\n",
       "          -6.40925532e-03]],\n",
       " \n",
       "        [[-1.28114503e-02,  7.69531071e-01,  5.80824446e-03,\n",
       "          -1.11275446e+00],\n",
       "         [ 2.57917191e-03,  5.74333370e-01, -1.64468456e-02,\n",
       "          -8.18255246e-01]],\n",
       " \n",
       "        [[-8.17577541e-02,  5.69245398e-01,  1.25470674e-02,\n",
       "          -9.04345572e-01],\n",
       "         [-7.03728423e-02,  3.73955786e-01, -5.53984428e-03,\n",
       "          -6.07745469e-01]],\n",
       " \n",
       "        [[ 5.39518986e-03, -4.53861244e-02, -2.32272428e-02,\n",
       "          -2.93943193e-02],\n",
       "         [ 4.48746746e-03,  1.50061086e-01, -2.38151290e-02,\n",
       "          -3.29314262e-01]],\n",
       " \n",
       "        [[ 2.83846073e-02, -2.14977041e-01, -1.19073346e-01,\n",
       "           5.30177727e-02],\n",
       "         [ 2.40850653e-02, -1.83668416e-02, -1.18012987e-01,\n",
       "          -2.74734169e-01]],\n",
       " \n",
       "        [[-2.06322167e-02,  9.52011254e-03, -3.39430049e-02,\n",
       "           2.37692054e-02],\n",
       "         [-2.04418134e-02,  2.05111980e-01, -3.34676206e-02,\n",
       "          -2.79426932e-01]],\n",
       " \n",
       "        [[-2.97732800e-02, -1.87162682e-01,  1.33821771e-01,\n",
       "           4.77319866e-01],\n",
       "         [-3.35165337e-02,  5.84115135e-03,  1.43368155e-01,\n",
       "           2.29628801e-01]],\n",
       " \n",
       "        [[-9.64248460e-03, -1.29014468e-02,  2.65033841e-02,\n",
       "          -1.60129126e-02],\n",
       "         [-9.90051311e-03, -2.08393261e-01,  2.61831265e-02,\n",
       "           2.84912914e-01]],\n",
       " \n",
       "        [[ 2.72092037e-02, -4.14397210e-01,  9.82555375e-03,\n",
       "           5.74998617e-01],\n",
       "         [ 1.89212598e-02, -2.19414368e-01,  2.13255268e-02,\n",
       "           2.85427123e-01]],\n",
       " \n",
       "        [[ 1.68869458e-02,  4.33469951e-01, -2.93080676e-02,\n",
       "          -5.74131131e-01],\n",
       "         [ 2.55563445e-02,  6.28990293e-01, -4.07906920e-02,\n",
       "          -8.75901043e-01]],\n",
       " \n",
       "        [[-7.83591568e-02, -1.20050287e+00,  1.66108921e-01,\n",
       "           1.89032459e+00],\n",
       "         [-1.02369212e-01, -1.39699399e+00,  2.03915417e-01,\n",
       "           2.22961617e+00]],\n",
       " \n",
       "        [[ 2.24012639e-02,  3.84196073e-01,  5.14799990e-02,\n",
       "          -4.69782293e-01],\n",
       "         [ 3.00851855e-02,  1.88386142e-01,  4.20843512e-02,\n",
       "          -1.61328077e-01]],\n",
       " \n",
       "        [[-1.82807352e-02,  1.18087196e+00, -4.34232727e-02,\n",
       "          -1.63808262e+00],\n",
       "         [ 5.33670420e-03,  1.37647533e+00, -7.61849210e-02,\n",
       "          -1.94397354e+00]],\n",
       " \n",
       "        [[-4.86006178e-02, -3.30725424e-02,  7.35931545e-02,\n",
       "           1.08821772e-01],\n",
       "         [-4.92620692e-02, -2.29167700e-01,  7.57695884e-02,\n",
       "           4.23785210e-01]],\n",
       " \n",
       "        [[-9.69100371e-02, -4.42570925e-01,  7.60651156e-02,\n",
       "           7.00430214e-01],\n",
       "         [-1.05761454e-01, -6.38660312e-01,  9.00737196e-02,\n",
       "           1.01605535e+00]],\n",
       " \n",
       "        [[ 1.37748923e-02, -2.80803517e-02,  1.07993912e-02,\n",
       "           4.05854918e-03],\n",
       "         [ 1.32132852e-02,  1.66885063e-01,  1.08805615e-02,\n",
       "          -2.85197556e-01]],\n",
       " \n",
       "        [[ 2.97042336e-02,  3.61294538e-01, -7.67966360e-02,\n",
       "          -5.67022204e-01],\n",
       "         [ 3.69301252e-02,  1.67329103e-01, -8.81370828e-02,\n",
       "          -2.99487621e-01]],\n",
       " \n",
       "        [[-1.59718413e-02, -2.63408516e-02,  3.39059904e-02,\n",
       "          -3.99736390e-02],\n",
       "         [-1.64986588e-02,  1.68278903e-01,  3.31065170e-02,\n",
       "          -3.21769029e-01]],\n",
       " \n",
       "        [[-2.76675466e-02,  3.60991769e-02, -2.06136182e-02,\n",
       "          -3.66691872e-02],\n",
       "         [-2.69455630e-02,  2.31510580e-01, -2.13470012e-02,\n",
       "          -3.35783988e-01]],\n",
       " \n",
       "        [[-1.38179846e-02, -1.97566375e-01, -3.97015959e-02,\n",
       "           2.53546000e-01],\n",
       "         [-1.77693125e-02, -3.92099619e-01, -3.46306749e-02,\n",
       "           5.33446729e-01]],\n",
       " \n",
       "        [[ 7.73738548e-02,  1.80797130e-01, -4.22589341e-03,\n",
       "          -1.98223084e-01],\n",
       "         [ 8.09898004e-02,  3.75979275e-01, -8.19035526e-03,\n",
       "          -4.92236078e-01]],\n",
       " \n",
       "        [[ 1.12594932e-01,  2.17291161e-01, -2.12358072e-01,\n",
       "          -8.31016779e-01],\n",
       "         [ 4.86691780e-02,  4.40196209e-02,  1.10505382e-02,\n",
       "          -1.15233166e-02]],\n",
       " \n",
       "        [[ 5.21833897e-02,  8.12506378e-01, -9.78758037e-02,\n",
       "          -1.20075309e+00],\n",
       "         [ 6.84335157e-02,  6.18777096e-01, -1.21890865e-01,\n",
       "          -9.40279484e-01]],\n",
       " \n",
       "        [[ 5.38061233e-03, -3.61061022e-02,  1.78684504e-03,\n",
       "           7.57378293e-03],\n",
       "         [ 4.65849042e-03, -2.31253639e-01,  1.93832070e-03,\n",
       "           3.00819933e-01]],\n",
       " \n",
       "        [[ 7.20511600e-02,  5.76307178e-01, -3.18167591e-03,\n",
       "          -6.95308268e-01],\n",
       "         [ 8.35773051e-02,  7.71473110e-01, -1.70878414e-02,\n",
       "          -9.88991082e-01]],\n",
       " \n",
       "        [[ 8.35773051e-02,  7.71473110e-01, -1.70878414e-02,\n",
       "          -9.88991082e-01],\n",
       "         [ 9.90067646e-02,  9.66819584e-01, -3.68676633e-02,\n",
       "          -1.28699160e+00]],\n",
       " \n",
       "        [[-8.37873388e-03,  2.33464345e-01, -4.92302738e-02,\n",
       "          -3.79222304e-01],\n",
       "         [-3.70944687e-03,  3.90748307e-02, -5.68147190e-02,\n",
       "          -1.02459162e-01]],\n",
       " \n",
       "        [[-6.86476678e-02,  2.39247698e-02,  2.93556508e-02,\n",
       "          -6.37620986e-02],\n",
       "         [-6.81691766e-02,  2.18613803e-01,  2.80804094e-02,\n",
       "          -3.47040504e-01]],\n",
       " \n",
       "        [[-6.47013709e-02, -7.81597257e-01,  3.04399319e-02,\n",
       "           1.10215271e+00],\n",
       "         [-8.03333148e-02, -5.86888731e-01,  5.24829850e-02,\n",
       "           8.19173157e-01]],\n",
       " \n",
       "        [[-5.93154952e-02, -1.59537848e-02, -2.40310058e-02,\n",
       "          -2.97620688e-02],\n",
       "         [-5.96345700e-02, -2.10723028e-01, -2.46262476e-02,\n",
       "           2.55243003e-01]],\n",
       " \n",
       "        [[-1.16768908e-02, -1.65157989e-01,  4.40146104e-02,\n",
       "           3.22783202e-01],\n",
       "         [-1.49800507e-02, -3.60878170e-01,  5.04702739e-02,\n",
       "           6.29015207e-01]],\n",
       " \n",
       "        [[ 5.25514148e-02, -1.47812292e-01, -7.77425840e-02,\n",
       "           2.14714304e-01],\n",
       "         [ 4.95951697e-02, -3.41741681e-01, -7.34483004e-02,\n",
       "           4.81896460e-01]],\n",
       " \n",
       "        [[-3.55710313e-02, -2.06101298e-01,  6.82332180e-03,\n",
       "           2.85080701e-01],\n",
       "         [-3.96930538e-02, -4.01319891e-01,  1.25249354e-02,\n",
       "           5.79907835e-01]],\n",
       " \n",
       "        [[ 4.86231707e-02,  7.93460011e-01, -1.09051846e-01,\n",
       "          -1.31760406e+00],\n",
       "         [ 6.44923672e-02,  5.99873126e-01, -1.35403931e-01,\n",
       "          -1.06094635e+00]],\n",
       " \n",
       "        [[ 1.55304587e-02,  3.20512317e-02, -5.87441493e-03,\n",
       "          -2.45960732e-03],\n",
       "         [ 1.61714833e-02, -1.62985981e-01, -5.92360692e-03,\n",
       "           2.88364083e-01]],\n",
       " \n",
       "        [[ 4.84865010e-02, -5.81856310e-01,  4.63282503e-02,\n",
       "           9.93815422e-01],\n",
       "         [ 3.68493721e-02, -3.87383699e-01,  6.62045553e-02,\n",
       "           7.16035128e-01]],\n",
       " \n",
       "        [[-3.94268297e-02,  1.58650428e-01, -4.65370864e-02,\n",
       "          -3.50783557e-01],\n",
       "         [-3.62538211e-02, -3.57798710e-02, -5.35527542e-02,\n",
       "          -7.31308088e-02]],\n",
       " \n",
       "        [[ 2.86473539e-02, -9.26818699e-03,  1.12437963e-01,\n",
       "           5.63805759e-01],\n",
       "         [ 2.84619909e-02, -2.05773294e-01,  1.23714074e-01,\n",
       "           8.89689386e-01]],\n",
       " \n",
       "        [[ 4.43457589e-02, -4.16594148e-02, -1.00429961e-02,\n",
       "           1.03125367e-02],\n",
       "         [ 4.35125716e-02, -2.36635908e-01, -9.83674545e-03,\n",
       "           2.99809933e-01]],\n",
       " \n",
       "        [[ 1.00063784e-02, -2.31288299e-01, -4.24500415e-03,\n",
       "           3.01592469e-01],\n",
       "         [ 5.38061233e-03, -3.61061022e-02,  1.78684504e-03,\n",
       "           7.57378293e-03]],\n",
       " \n",
       "        [[ 2.08320655e-02,  1.94834635e-01, -2.32350547e-02,\n",
       "          -3.18461895e-01],\n",
       "         [ 2.47287583e-02,  3.90279680e-01, -2.96042915e-02,\n",
       "          -6.18380785e-01]],\n",
       " \n",
       "        [[ 2.55563445e-02,  6.28990293e-01, -4.07906920e-02,\n",
       "          -8.75901043e-01],\n",
       "         [ 3.81361507e-02,  4.34445828e-01, -5.83087131e-02,\n",
       "          -5.96316218e-01]],\n",
       " \n",
       "        [[ 3.40759493e-02,  3.56022567e-02,  3.34801897e-02,\n",
       "           4.98905852e-02],\n",
       "         [ 3.47879939e-02, -1.59983382e-01,  3.44780013e-02,\n",
       "           3.52945954e-01]]], dtype=float32)>,\n",
       "  'action': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1]], dtype=int64)>,\n",
       "  'policy_info': (),\n",
       "  'next_step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]])>,\n",
       "  'reward': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)>,\n",
       "  'discount': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)>}),\n",
       " BufferInfo(ids=<tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[  32,   33],\n",
       "        [ 918,  919],\n",
       "        [ 957,  958],\n",
       "        [ 863,  864],\n",
       "        [ 326,  327],\n",
       "        [ 633,  634],\n",
       "        [ 524,  525],\n",
       "        [ 775,  776],\n",
       "        [ 361,  362],\n",
       "        [ 413,  414],\n",
       "        [ 468,  469],\n",
       "        [ 299,  300],\n",
       "        [  69,   70],\n",
       "        [1040, 1041],\n",
       "        [  86,   87],\n",
       "        [ 825,  826],\n",
       "        [ 305,  306],\n",
       "        [ 702,  703],\n",
       "        [ 552,  553],\n",
       "        [ 229,  230],\n",
       "        [ 195,  196],\n",
       "        [ 784,  785],\n",
       "        [ 560,  561],\n",
       "        [ 274,  275],\n",
       "        [ 824,  825],\n",
       "        [  12,   13],\n",
       "        [ 966,  967],\n",
       "        [ 518,  519],\n",
       "        [ 933,  934],\n",
       "        [ 711,  712],\n",
       "        [ 654,  655],\n",
       "        [ 719,  720],\n",
       "        [ 634,  635],\n",
       "        [ 410,  411],\n",
       "        [ 187,  188],\n",
       "        [ 797,  798],\n",
       "        [ 536,  537],\n",
       "        [ 619,  620],\n",
       "        [ 171,  172],\n",
       "        [  70,   71],\n",
       "        [ 769,  770],\n",
       "        [ 498,  499],\n",
       "        [ 450,  451],\n",
       "        [ 996,  997],\n",
       "        [ 953,  954],\n",
       "        [ 641,  642],\n",
       "        [ 642,  643],\n",
       "        [  75,   76],\n",
       "        [ 589,  590],\n",
       "        [ 774,  775],\n",
       "        [ 277,  278],\n",
       "        [ 739,  740],\n",
       "        [ 659,  660],\n",
       "        [ 252,  253],\n",
       "        [  56,   57],\n",
       "        [ 140,  141],\n",
       "        [ 302,  303],\n",
       "        [ 468,  469],\n",
       "        [ 527,  528],\n",
       "        [ 891,  892],\n",
       "        [ 952,  953],\n",
       "        [ 436,  437],\n",
       "        [ 655,  656],\n",
       "        [ 865,  866]], dtype=int64)>, probabilities=<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       " array([0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061, 0.00096061,\n",
       "        0.00096061, 0.00096061, 0.00096061, 0.00096061], dtype=float32)>))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       "array([[0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(64, 2, 4), dtype=float32, numpy=\n",
       "array([[[ 3.00198197e-02, -3.19793448e-02, -2.46987287e-02,\n",
       "         -3.46067101e-02],\n",
       "        [ 2.93802321e-02, -2.26738557e-01, -2.53908634e-02,\n",
       "          2.50182331e-01]],\n",
       "\n",
       "       [[-1.77693125e-02, -3.92099619e-01, -3.46306749e-02,\n",
       "          5.33446729e-01],\n",
       "        [-2.56113037e-02, -5.86717844e-01, -2.39617396e-02,\n",
       "          8.15019667e-01]],\n",
       "\n",
       "       [[-4.88742348e-03,  4.20207262e-01, -1.65716074e-02,\n",
       "         -5.65627575e-01],\n",
       "        [ 3.51672154e-03,  6.15557730e-01, -2.78841574e-02,\n",
       "         -8.63484859e-01]],\n",
       "\n",
       "       [[ 1.62835158e-02,  9.56968129e-01, -2.23226726e-01,\n",
       "         -1.95530927e+00],\n",
       "        [ 3.74592133e-02, -1.16540175e-02,  4.24773209e-02,\n",
       "          3.55795883e-02]],\n",
       "\n",
       "       [[-5.96345700e-02, -2.10723028e-01, -2.46262476e-02,\n",
       "          2.55243003e-01],\n",
       "        [-6.38490319e-02, -1.52582731e-02, -1.95213873e-02,\n",
       "         -4.51046117e-02]],\n",
       "\n",
       "       [[-2.54432089e-04,  1.90038636e-01, -1.42742917e-01,\n",
       "         -5.67532718e-01],\n",
       "        [ 3.54634062e-03,  3.86843890e-01, -1.54093578e-01,\n",
       "         -9.01562274e-01]],\n",
       "\n",
       "       [[-7.01463670e-02, -1.69612199e-01,  3.45793776e-02,\n",
       "          1.94090888e-01],\n",
       "        [-7.35386163e-02,  2.49984730e-02,  3.84611934e-02,\n",
       "         -8.74863118e-02]],\n",
       "\n",
       "       [[-2.35489551e-02, -3.59143168e-01,  5.82054667e-02,\n",
       "          6.04696870e-01],\n",
       "        [-3.07318177e-02, -5.55028737e-01,  7.02994019e-02,\n",
       "          9.15130377e-01]],\n",
       "\n",
       "       [[-1.59828365e-03, -4.31194335e-01, -3.38376388e-02,\n",
       "          4.58481193e-01],\n",
       "        [-1.02221705e-02, -6.25822008e-01, -2.46680137e-02,\n",
       "          7.40309238e-01]],\n",
       "\n",
       "       [[-5.16717136e-02, -5.59360385e-01,  9.63507965e-03,\n",
       "          7.68425345e-01],\n",
       "        [-6.28589243e-02, -3.64372402e-01,  2.50035860e-02,\n",
       "          4.78789568e-01]],\n",
       "\n",
       "       [[-6.28937259e-02,  1.78911716e-01, -1.76947545e-02,\n",
       "         -3.16812575e-01],\n",
       "        [-5.93154952e-02, -1.59537848e-02, -2.40310058e-02,\n",
       "         -2.97620688e-02]],\n",
       "\n",
       "       [[-1.82524115e-01, -1.17419398e+00,  2.00301588e-01,\n",
       "          1.86250401e+00],\n",
       "        [-2.06007987e-01, -9.81752455e-01,  2.37551659e-01,\n",
       "          1.63810873e+00]],\n",
       "\n",
       "       [[ 2.91016996e-02, -5.83356500e-01,  8.05252641e-02,\n",
       "          1.02880025e+00],\n",
       "        [ 1.74345691e-02, -3.89393181e-01,  1.01101264e-01,\n",
       "          7.62446940e-01]],\n",
       "\n",
       "       [[ 4.92766239e-02, -3.10989539e-03,  1.84024684e-02,\n",
       "         -2.25849114e-02],\n",
       "        [ 4.92144264e-02,  1.91743374e-01,  1.79507695e-02,\n",
       "         -3.09405327e-01]],\n",
       "\n",
       "       [[-7.90568516e-02, -8.00752163e-01,  1.33933619e-01,\n",
       "          1.32689261e+00],\n",
       "        [-9.50718895e-02, -6.07550800e-01,  1.60471469e-01,\n",
       "          1.07894480e+00]],\n",
       "\n",
       "       [[ 2.48454623e-02, -4.21488881e-01, -2.03872155e-02,\n",
       "          5.34749568e-01],\n",
       "        [ 1.64156836e-02, -6.16318285e-01, -9.69222561e-03,\n",
       "          8.20939541e-01]],\n",
       "\n",
       "       [[-2.55100778e-03,  1.94910362e-01,  1.37571711e-02,\n",
       "         -3.20114076e-01],\n",
       "        [ 1.34719943e-03,  3.89833719e-01,  7.35489000e-03,\n",
       "         -6.08426988e-01]],\n",
       "\n",
       "       [[-6.01932704e-02,  3.43434334e-01,  1.25102431e-01,\n",
       "         -1.75276235e-01],\n",
       "        [-5.33245839e-02,  1.46764696e-01,  1.21596910e-01,\n",
       "          1.54107004e-01]],\n",
       "\n",
       "       [[ 3.74592133e-02, -1.16540175e-02,  4.24773209e-02,\n",
       "          3.55795883e-02],\n",
       "        [ 3.72261330e-02,  1.82833865e-01,  4.31889109e-02,\n",
       "         -2.43404523e-01]],\n",
       "\n",
       "       [[ 5.39442338e-03, -4.24826145e-02,  3.31525132e-02,\n",
       "          2.84850206e-02],\n",
       "        [ 4.54477128e-03,  1.52148604e-01,  3.37222144e-02,\n",
       "         -2.53556341e-01]],\n",
       "\n",
       "       [[-1.16069220e-01, -1.01860440e+00,  1.81190282e-01,\n",
       "          1.64536953e+00],\n",
       "        [-1.36441305e-01, -1.21532500e+00,  2.14097664e-01,\n",
       "          1.98859894e+00]],\n",
       "\n",
       "       [[-1.59718413e-02, -2.63408516e-02,  3.39059904e-02,\n",
       "         -3.99736390e-02],\n",
       "        [-1.64986588e-02,  1.68278903e-01,  3.31065170e-02,\n",
       "         -3.21769029e-01]],\n",
       "\n",
       "       [[ 5.21833897e-02,  8.12506378e-01, -9.78758037e-02,\n",
       "         -1.20075309e+00],\n",
       "        [ 6.84335157e-02,  6.18777096e-01, -1.21890865e-01,\n",
       "         -9.40279484e-01]],\n",
       "\n",
       "       [[-4.36927527e-02, -2.10303217e-01, -2.87222750e-02,\n",
       "          2.46012732e-01],\n",
       "        [-4.78988178e-02, -4.05003428e-01, -2.38020215e-02,\n",
       "          5.29499412e-01]],\n",
       "\n",
       "       [[ 1.58278756e-02,  8.11047971e-01, -4.51538563e-02,\n",
       "         -1.16480315e+00],\n",
       "        [ 3.20488364e-02,  1.00672770e+00, -6.84499145e-02,\n",
       "         -1.47129428e+00]],\n",
       "\n",
       "       [[ 8.12682807e-02,  5.21114469e-01,  5.19477241e-02,\n",
       "         -8.19534361e-02],\n",
       "        [ 9.16905701e-02,  7.15454757e-01,  5.03086522e-02,\n",
       "         -3.57804865e-01]],\n",
       "\n",
       "       [[-3.84696163e-02, -3.73670071e-01, -2.84957234e-02,\n",
       "          5.62512517e-01],\n",
       "        [-4.59430180e-02, -1.78160071e-01, -1.72454733e-02,\n",
       "          2.60989994e-01]],\n",
       "\n",
       "       [[ 7.38550276e-02,  2.41373017e-01, -2.30098844e-01,\n",
       "         -8.70134950e-01],\n",
       "        [-4.87277918e-02, -2.97290049e-02,  3.68448086e-02,\n",
       "          3.70083340e-02]],\n",
       "\n",
       "       [[ 2.84619909e-02, -2.05773294e-01,  1.23714074e-01,\n",
       "          8.89689386e-01],\n",
       "        [ 2.43465248e-02, -1.25275590e-02,  1.41507864e-01,\n",
       "          6.38315380e-01]],\n",
       "\n",
       "       [[-1.09517509e-02, -8.26586187e-01,  5.90800941e-02,\n",
       "          1.28036928e+00],\n",
       "        [-2.74834745e-02, -6.32264674e-01,  8.46874788e-02,\n",
       "          1.00675499e+00]],\n",
       "\n",
       "       [[-1.20065674e-01, -9.74598110e-01,  1.05536200e-01,\n",
       "          1.44629407e+00],\n",
       "        [-1.39557630e-01, -1.17084801e+00,  1.34462088e-01,\n",
       "          1.77000117e+00]],\n",
       "\n",
       "       [[-4.77194525e-02, -5.96615076e-01,  2.41230913e-02,\n",
       "          8.76509905e-01],\n",
       "        [-5.96517548e-02, -4.01829183e-01,  4.16532904e-02,\n",
       "          5.91507494e-01]],\n",
       "\n",
       "       [[ 1.72026607e-03, -2.87347771e-02,  2.92055458e-02,\n",
       "          4.06589583e-02],\n",
       "        [ 1.14557054e-03,  1.65956467e-01,  3.00187245e-02,\n",
       "         -2.42668152e-01]],\n",
       "\n",
       "       [[-1.31199136e-01, -9.91923988e-01,  1.51124284e-01,\n",
       "          1.58813536e+00],\n",
       "        [-1.51037619e-01, -7.98886240e-01,  1.82887003e-01,\n",
       "          1.34614062e+00]],\n",
       "\n",
       "       [[ 2.22641993e-02,  1.77616887e-02,  4.47346568e-02,\n",
       "         -3.56023684e-02],\n",
       "        [ 2.26194337e-02, -1.77972272e-01,  4.40226085e-02,\n",
       "          2.70852447e-01]],\n",
       "\n",
       "       [[ 5.60401976e-02,  3.86110812e-01, -4.19765823e-02,\n",
       "         -6.64849222e-01],\n",
       "        [ 6.37624115e-02,  1.91597134e-01, -5.52735664e-02,\n",
       "         -3.85673195e-01]],\n",
       "\n",
       "       [[ 4.84290719e-02,  1.81673378e-01,  2.78776642e-02,\n",
       "         -2.17650041e-01],\n",
       "        [ 5.20625412e-02,  3.76385957e-01,  2.35246625e-02,\n",
       "         -5.01410425e-01]],\n",
       "\n",
       "       [[-4.60254550e-02,  3.59411269e-01,  3.27084586e-02,\n",
       "         -5.24420559e-01],\n",
       "        [-3.88372317e-02,  5.54058015e-01,  2.22200491e-02,\n",
       "         -8.06619942e-01]],\n",
       "\n",
       "       [[ 9.47690010e-02,  2.36969739e-01, -1.67374045e-01,\n",
       "         -5.42096317e-01],\n",
       "        [ 9.95083973e-02,  4.45465930e-02, -1.78215966e-01,\n",
       "         -3.06473613e-01]],\n",
       "\n",
       "       [[ 4.12777774e-02,  1.53399155e-01, -4.42355778e-03,\n",
       "         -2.80971944e-01],\n",
       "        [ 4.43457589e-02, -4.16594148e-02, -1.00429961e-02,\n",
       "          1.03125367e-02]],\n",
       "\n",
       "       [[ 7.00019300e-03, -2.04404905e-01, -1.29942983e-01,\n",
       "         -1.82077557e-01],\n",
       "        [ 2.91209505e-03, -3.97451222e-01, -1.33584529e-01,\n",
       "          6.69548064e-02]],\n",
       "\n",
       "       [[-2.96844542e-02, -7.35155046e-01,  2.06631832e-02,\n",
       "          9.11977470e-01],\n",
       "        [-4.43875529e-02, -5.40318668e-01,  3.89027335e-02,\n",
       "          6.25859857e-01]],\n",
       "\n",
       "       [[ 4.42503989e-02,  7.81465709e-01, -6.03766814e-02,\n",
       "         -1.22581136e+00],\n",
       "        [ 5.98797128e-02,  5.87170839e-01, -8.48929062e-02,\n",
       "         -9.52640057e-01]],\n",
       "\n",
       "       [[ 5.67238778e-02, -1.99163854e-01,  5.46377897e-03,\n",
       "          2.90661186e-01],\n",
       "        [ 5.27406000e-02, -3.94363284e-01,  1.12770032e-02,\n",
       "          5.85062325e-01]],\n",
       "\n",
       "       [[ 2.91016996e-02, -5.83356500e-01,  8.05252641e-02,\n",
       "          1.02880025e+00],\n",
       "        [ 1.74345691e-02, -3.89393181e-01,  1.01101264e-01,\n",
       "          7.62446940e-01]],\n",
       "\n",
       "       [[ 4.84865010e-02, -5.81856310e-01,  4.63282503e-02,\n",
       "          9.93815422e-01],\n",
       "        [ 3.68493721e-02, -3.87383699e-01,  6.62045553e-02,\n",
       "          7.16035128e-01]],\n",
       "\n",
       "       [[ 4.80725542e-02, -1.92033038e-01, -5.73198386e-02,\n",
       "          5.44127114e-02],\n",
       "        [ 4.42318954e-02, -3.86288255e-01, -5.62315844e-02,\n",
       "          3.28474194e-01]],\n",
       "\n",
       "       [[-1.48818130e-02,  5.76314211e-01, -5.91818504e-02,\n",
       "         -9.65507984e-01],\n",
       "        [-3.35552893e-03,  3.82034957e-01, -7.84920081e-02,\n",
       "         -6.91988647e-01]],\n",
       "\n",
       "       [[-4.30673212e-02, -1.01522851e+00,  4.23078053e-02,\n",
       "          1.49098051e+00],\n",
       "        [-6.33718967e-02, -8.20646346e-01,  7.21274167e-02,\n",
       "          1.21180320e+00]],\n",
       "\n",
       "       [[-3.08415480e-03, -2.23140687e-01,  8.42482876e-03,\n",
       "          2.89746642e-01],\n",
       "        [-7.54696829e-03, -2.81398818e-02,  1.42197618e-02,\n",
       "         -2.67325726e-04]],\n",
       "\n",
       "       [[ 2.32598912e-02,  1.87808111e-01,  1.69380605e-02,\n",
       "         -3.01638216e-01],\n",
       "        [ 2.70160530e-02,  3.82684588e-01,  1.09052965e-02,\n",
       "         -5.88931501e-01]],\n",
       "\n",
       "       [[-4.64925021e-02,  3.53283674e-01, -3.38849723e-02,\n",
       "         -6.32605553e-01],\n",
       "        [-3.94268297e-02,  1.58650428e-01, -4.65370864e-02,\n",
       "         -3.50783557e-01]],\n",
       "\n",
       "       [[-6.57139421e-02,  5.95634580e-01,  1.96101293e-02,\n",
       "         -7.62487352e-01],\n",
       "        [-5.38012534e-02,  7.90481031e-01,  4.36038105e-03,\n",
       "         -1.04893577e+00]],\n",
       "\n",
       "       [[ 2.93270648e-02, -3.79180275e-02, -3.06391865e-02,\n",
       "          4.75652702e-02],\n",
       "        [ 2.85687037e-02, -2.32587546e-01, -2.96878815e-02,\n",
       "          3.30425978e-01]],\n",
       "\n",
       "       [[ 4.28517023e-03,  1.88084707e-01, -9.23317820e-02,\n",
       "         -4.25011963e-01],\n",
       "        [ 8.04686453e-03, -5.61635289e-03, -1.00832023e-01,\n",
       "         -1.62804976e-01]],\n",
       "\n",
       "       [[ 2.65806857e-02,  1.50127694e-01,  1.93263812e-04,\n",
       "         -2.08809331e-01],\n",
       "        [ 2.95832399e-02, -4.49970178e-02, -3.98292299e-03,\n",
       "          8.39345530e-02]],\n",
       "\n",
       "       [[-7.88781908e-05, -4.00861353e-02, -1.89777035e-02,\n",
       "          3.72713730e-02],\n",
       "        [-8.80600885e-04, -2.34930873e-01, -1.82322767e-02,\n",
       "          3.23906749e-01]],\n",
       "\n",
       "       [[-1.17751034e-02,  2.07335874e-01, -4.54924367e-02,\n",
       "         -3.28648925e-01],\n",
       "        [-7.62838591e-03,  1.28900809e-02, -5.20654172e-02,\n",
       "         -5.06521501e-02]],\n",
       "\n",
       "       [[-1.25790229e-02, -2.85463836e-02,  2.01517753e-02,\n",
       "          8.70171096e-03],\n",
       "        [-1.31499507e-02, -2.23951459e-01,  2.03258097e-02,\n",
       "          3.07674021e-01]],\n",
       "\n",
       "       [[-5.51280379e-02, -8.19513321e-01,  8.71608779e-02,\n",
       "          1.24623418e+00],\n",
       "        [-7.15183020e-02, -1.01563835e+00,  1.12085558e-01,\n",
       "          1.56489778e+00]],\n",
       "\n",
       "       [[-3.11110052e-03, -3.22078764e-02,  4.08680514e-02,\n",
       "          1.17349692e-01],\n",
       "        [-3.75525816e-03, -2.27890834e-01,  4.32150438e-02,\n",
       "          4.22640890e-01]],\n",
       "\n",
       "       [[-9.34789479e-02,  5.96976161e-01,  5.68342283e-02,\n",
       "         -7.93464720e-01],\n",
       "        [-8.15394223e-02,  7.91273832e-01,  4.09649350e-02,\n",
       "         -1.06774032e+00]],\n",
       "\n",
       "       [[-6.57139421e-02,  5.95634580e-01,  1.96101293e-02,\n",
       "         -7.62487352e-01],\n",
       "        [-5.38012534e-02,  7.90481031e-01,  4.36038105e-03,\n",
       "         -1.04893577e+00]],\n",
       "\n",
       "       [[ 4.52551581e-02,  3.81910384e-01,  2.73335539e-02,\n",
       "         -4.18822289e-01],\n",
       "        [ 5.28933667e-02,  5.76634526e-01,  1.89571064e-02,\n",
       "         -7.02764392e-01]]], dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.utils.common import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DynamicStepDriver.run of <tf_agents.drivers.dynamic_step_driver.DynamicStepDriver object at 0x000001591ED5EF10>>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x000001591EAF6510>>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_driver.run = function(collect_driver.run)\n",
    "agent.train = function(agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x159206efe50>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x159209c8f90>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_policy.get_initial_state(env.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       "  'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       " array([[-0.01762554,  0.16892669,  0.02063639, -0.3050253 ]],\n",
       "       dtype=float32)>}),\n",
       " ())"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run(None, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, ps = collect_driver.run(None,())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories, buffer_info = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(64, 2, 4), dtype=float32, numpy=\n",
       "array([[[-7.88781908e-05, -4.00861353e-02, -1.89777035e-02,\n",
       "          3.72713730e-02],\n",
       "        [-8.80600885e-04, -2.34930873e-01, -1.82322767e-02,\n",
       "          3.23906749e-01]],\n",
       "\n",
       "       [[ 9.25258026e-02,  9.56372380e-01, -1.86038062e-01,\n",
       "         -1.68217576e+00],\n",
       "        [ 1.11653246e-01,  7.63828695e-01, -2.19681576e-01,\n",
       "         -1.45272398e+00]],\n",
       "\n",
       "       [[-4.86006178e-02, -3.30725424e-02,  7.35931545e-02,\n",
       "          1.08821772e-01],\n",
       "        [-4.92620692e-02, -2.29167700e-01,  7.57695884e-02,\n",
       "          4.23785210e-01]],\n",
       "\n",
       "       [[-1.85518682e-01, -8.42318177e-01,  2.22168565e-01,\n",
       "          1.52650416e+00],\n",
       "        [ 1.02439169e-02, -3.69894281e-02,  4.78539616e-02,\n",
       "         -1.60885509e-02]],\n",
       "\n",
       "       [[ 5.25514148e-02, -1.47812292e-01, -7.77425840e-02,\n",
       "          2.14714304e-01],\n",
       "        [ 4.95951697e-02, -3.41741681e-01, -7.34483004e-02,\n",
       "          4.81896460e-01]],\n",
       "\n",
       "       [[-4.60254550e-02,  3.59411269e-01,  3.27084586e-02,\n",
       "         -5.24420559e-01],\n",
       "        [-3.88372317e-02,  5.54058015e-01,  2.22200491e-02,\n",
       "         -8.06619942e-01]],\n",
       "\n",
       "       [[ 1.08008087e-03,  7.60171771e-01, -1.91033483e-01,\n",
       "         -1.60966182e+00],\n",
       "        [ 1.62835158e-02,  9.56968129e-01, -2.23226726e-01,\n",
       "         -1.95530927e+00]],\n",
       "\n",
       "       [[ 3.09447641e-04,  5.54422557e-01, -3.30519415e-02,\n",
       "         -8.14544618e-01],\n",
       "        [ 1.13978982e-02,  3.59768420e-01, -4.93428335e-02,\n",
       "         -5.32438457e-01]],\n",
       "\n",
       "       [[ 2.53819320e-02,  1.71806142e-01, -1.05871938e-01,\n",
       "         -4.58797455e-01],\n",
       "        [ 2.88180541e-02, -2.16723830e-02, -1.15047887e-01,\n",
       "         -2.01272890e-01]],\n",
       "\n",
       "       [[ 5.64692169e-02, -6.16473891e-03, -3.78212966e-02,\n",
       "         -3.42671908e-02],\n",
       "        [ 5.63459210e-02, -2.00724483e-01, -3.85066420e-02,\n",
       "          2.46246904e-01]],\n",
       "\n",
       "       [[ 6.51903600e-02,  4.33233380e-01, -2.08280578e-01,\n",
       "         -1.09091306e+00],\n",
       "        [ 7.38550276e-02,  2.41373017e-01, -2.30098844e-01,\n",
       "         -8.70134950e-01]],\n",
       "\n",
       "       [[-5.33245839e-02,  1.46764696e-01,  1.21596910e-01,\n",
       "          1.54107004e-01],\n",
       "        [-5.03892899e-02,  3.39954734e-01,  1.24679051e-01,\n",
       "         -9.78768840e-02]],\n",
       "\n",
       "       [[-1.10471874e-01, -5.81658483e-01, -5.35426103e-02,\n",
       "          1.18536822e-01],\n",
       "        [-1.22105040e-01, -3.85811895e-01, -5.11718765e-02,\n",
       "         -1.90546080e-01]],\n",
       "\n",
       "       [[ 4.29934971e-02, -3.24581206e-01, -2.03238219e-01,\n",
       "         -1.05396420e-01],\n",
       "        [ 3.65018733e-02, -1.27214655e-01, -2.05346152e-01,\n",
       "         -4.54694510e-01]],\n",
       "\n",
       "       [[ 8.08090568e-02,  4.25490171e-01, -1.40696451e-01,\n",
       "         -6.88247502e-01],\n",
       "        [ 8.93188640e-02,  2.32572258e-01, -1.54461399e-01,\n",
       "         -4.42958534e-01]],\n",
       "\n",
       "       [[-1.71823204e-01, -5.73144376e-01, -9.24106240e-02,\n",
       "         -6.97285756e-02],\n",
       "        [-1.83286086e-01, -3.76827389e-01, -9.38051939e-02,\n",
       "         -3.90077621e-01]],\n",
       "\n",
       "       [[-3.84609099e-03,  1.86340958e-01, -1.28362775e-01,\n",
       "         -4.84318823e-01],\n",
       "        [-1.19271986e-04, -6.75800489e-03, -1.38049155e-01,\n",
       "         -2.34688476e-01]],\n",
       "\n",
       "       [[ 6.84335157e-02,  6.18777096e-01, -1.21890865e-01,\n",
       "         -9.40279484e-01],\n",
       "        [ 8.08090568e-02,  4.25490171e-01, -1.40696451e-01,\n",
       "         -6.88247502e-01]],\n",
       "\n",
       "       [[ 4.44824845e-02, -1.55139312e-01, -6.40391409e-02,\n",
       "          1.52188033e-01],\n",
       "        [ 4.13796976e-02,  4.08383720e-02, -6.09953813e-02,\n",
       "         -1.59990549e-01]],\n",
       "\n",
       "       [[ 3.10215242e-02, -1.30676299e-01, -9.63443816e-02,\n",
       "         -1.64699361e-01],\n",
       "        [ 2.84079984e-02, -3.24296504e-01, -9.96383652e-02,\n",
       "          9.61026326e-02]],\n",
       "\n",
       "       [[-1.39203772e-01, -7.87441909e-01,  1.38605952e-01,\n",
       "          1.24080825e+00],\n",
       "        [-1.54952601e-01, -5.94344616e-01,  1.63422123e-01,\n",
       "          9.94559944e-01]],\n",
       "\n",
       "       [[-5.75830117e-02, -2.32533365e-01,  1.50013536e-01,\n",
       "          7.39466727e-01],\n",
       "        [-6.22336790e-02, -4.29373175e-01,  1.64802879e-01,\n",
       "          1.07534909e+00]],\n",
       "\n",
       "       [[ 3.68106395e-01,  3.39261442e-01, -1.48855373e-01,\n",
       "         -8.26670527e-02],\n",
       "        [ 3.74891639e-01,  1.46552056e-01, -1.50508702e-01,\n",
       "          1.59598380e-01]],\n",
       "\n",
       "       [[-6.37969002e-02,  4.13325310e-01,  2.11395994e-02,\n",
       "         -6.30738080e-01],\n",
       "        [-5.55303916e-02,  6.08146012e-01,  8.52483697e-03,\n",
       "         -9.16689277e-01]],\n",
       "\n",
       "       [[ 5.39518986e-03, -4.53861244e-02, -2.32272428e-02,\n",
       "         -2.93943193e-02],\n",
       "        [ 4.48746746e-03,  1.50061086e-01, -2.38151290e-02,\n",
       "         -3.29314262e-01]],\n",
       "\n",
       "       [[-1.88860986e-02, -5.39917707e-01,  8.32952652e-03,\n",
       "          6.16682827e-01],\n",
       "        [-2.96844542e-02, -7.35155046e-01,  2.06631832e-02,\n",
       "          9.11977470e-01]],\n",
       "\n",
       "       [[ 4.84865010e-02, -5.81856310e-01,  4.63282503e-02,\n",
       "          9.93815422e-01],\n",
       "        [ 3.68493721e-02, -3.87383699e-01,  6.62045553e-02,\n",
       "          7.16035128e-01]],\n",
       "\n",
       "       [[-5.69277406e-02, -2.49330904e-02,  5.07568493e-02,\n",
       "          5.45589253e-02],\n",
       "        [-5.74264042e-02, -2.20744699e-01,  5.18480279e-02,\n",
       "          3.62814158e-01]],\n",
       "\n",
       "       [[ 2.19220687e-02, -1.27898142e-01, -9.77163166e-02,\n",
       "         -2.26279020e-01],\n",
       "        [ 1.93641055e-02, -3.21497649e-01, -1.02241896e-01,\n",
       "          3.40519957e-02]],\n",
       "\n",
       "       [[ 9.79749393e-03,  7.89294485e-03, -3.91168743e-02,\n",
       "         -3.44558150e-01],\n",
       "        [ 9.95535310e-03,  2.03548893e-01, -4.60080393e-02,\n",
       "         -6.49315000e-01]],\n",
       "\n",
       "       [[ 1.37748923e-02, -2.80803517e-02,  1.07993912e-02,\n",
       "          4.05854918e-03],\n",
       "        [ 1.32132852e-02,  1.66885063e-01,  1.08805615e-02,\n",
       "         -2.85197556e-01]],\n",
       "\n",
       "       [[ 1.12755448e-02,  4.25537229e-02, -2.43522134e-02,\n",
       "          2.62365118e-02],\n",
       "        [ 1.21266190e-02,  2.38016292e-01, -2.38274839e-02,\n",
       "         -2.74029255e-01]],\n",
       "\n",
       "       [[ 1.07897490e-01,  1.18217599e+00, -4.88638170e-02,\n",
       "         -1.30507147e+00],\n",
       "        [ 1.31541014e-01,  9.87706482e-01, -7.49652460e-02,\n",
       "         -1.02807570e+00]],\n",
       "\n",
       "       [[-8.02330896e-02, -2.43167758e-01,  5.29308729e-02,\n",
       "          3.12001437e-01],\n",
       "        [-8.50964487e-02, -4.88382652e-02,  5.91709018e-02,\n",
       "          3.64698470e-02]],\n",
       "\n",
       "       [[-5.96345700e-02, -2.10723028e-01, -2.46262476e-02,\n",
       "          2.55243003e-01],\n",
       "        [-6.38490319e-02, -1.52582731e-02, -1.95213873e-02,\n",
       "         -4.51046117e-02]],\n",
       "\n",
       "       [[-1.91568844e-02, -5.81940413e-01, -3.44116054e-02,\n",
       "          8.02330315e-01],\n",
       "        [-3.07956934e-02, -7.76574016e-01, -1.83649994e-02,\n",
       "          1.08399284e+00]],\n",
       "\n",
       "       [[-5.75830117e-02, -2.32533365e-01,  1.50013536e-01,\n",
       "          7.39466727e-01],\n",
       "        [-6.22336790e-02, -4.29373175e-01,  1.64802879e-01,\n",
       "          1.07534909e+00]],\n",
       "\n",
       "       [[ 9.79749393e-03,  7.89294485e-03, -3.91168743e-02,\n",
       "         -3.44558150e-01],\n",
       "        [ 9.95535310e-03,  2.03548893e-01, -4.60080393e-02,\n",
       "         -6.49315000e-01]],\n",
       "\n",
       "       [[-3.35552893e-03,  3.82034957e-01, -7.84920081e-02,\n",
       "         -6.91988647e-01],\n",
       "        [ 4.28517023e-03,  1.88084707e-01, -9.23317820e-02,\n",
       "         -4.25011963e-01]],\n",
       "\n",
       "       [[ 2.99167670e-02, -4.15604599e-02,  2.40140455e-03,\n",
       "          8.12911242e-03],\n",
       "        [ 2.90855579e-02, -2.36716762e-01,  2.56398693e-03,\n",
       "          3.01568747e-01]],\n",
       "\n",
       "       [[-4.43869792e-02, -3.64236742e-01,  1.20993704e-04,\n",
       "          4.75704283e-01],\n",
       "        [-5.16717136e-02, -5.59360385e-01,  9.63507965e-03,\n",
       "          7.68425345e-01]],\n",
       "\n",
       "       [[-3.22878920e-02,  2.31017321e-01, -1.41162733e-02,\n",
       "         -3.24867219e-01],\n",
       "        [-2.76675466e-02,  3.60991769e-02, -2.06136182e-02,\n",
       "         -3.66691872e-02]],\n",
       "\n",
       "       [[ 2.40850653e-02, -1.83668416e-02, -1.18012987e-01,\n",
       "         -2.74734169e-01],\n",
       "        [ 2.37177294e-02, -2.11624622e-01, -1.23507671e-01,\n",
       "         -2.14791298e-02]],\n",
       "\n",
       "       [[ 1.96518898e-02,  2.44648933e-01, -1.14660218e-01,\n",
       "         -6.29272103e-01],\n",
       "        [ 2.45448686e-02,  5.12979925e-02, -1.27245665e-01,\n",
       "         -3.74786347e-01]],\n",
       "\n",
       "       [[ 4.48533334e-02, -5.89641392e-01,  2.29782499e-02,\n",
       "          8.81276190e-01],\n",
       "        [ 3.30605060e-02, -7.85067797e-01,  4.06037718e-02,\n",
       "          1.18109345e+00]],\n",
       "\n",
       "       [[ 2.94593684e-02,  5.75000286e-01, -5.51332608e-02,\n",
       "         -8.33853304e-01],\n",
       "        [ 4.09593731e-02,  3.80673200e-01, -7.18103275e-02,\n",
       "         -5.59006572e-01]],\n",
       "\n",
       "       [[ 4.80725542e-02, -1.92033038e-01, -5.73198386e-02,\n",
       "          5.44127114e-02],\n",
       "        [ 4.42318954e-02, -3.86288255e-01, -5.62315844e-02,\n",
       "          3.28474194e-01]],\n",
       "\n",
       "       [[ 3.90466675e-02,  1.53345197e-01,  9.08380724e-04,\n",
       "         -2.79783100e-01],\n",
       "        [ 4.21135724e-02, -4.17896993e-02, -4.68728133e-03,\n",
       "          1.31861875e-02]],\n",
       "\n",
       "       [[-6.87030470e-03,  3.58987629e-01, -2.27563716e-02,\n",
       "         -5.14778376e-01],\n",
       "        [ 3.09447641e-04,  5.54422557e-01, -3.30519415e-02,\n",
       "         -8.14544618e-01]],\n",
       "\n",
       "       [[-9.25475582e-02, -1.48136057e-02,  3.27799805e-02,\n",
       "         -5.49310930e-02],\n",
       "        [-9.28438306e-02,  1.79823369e-01,  3.16813588e-02,\n",
       "         -3.37094128e-01]],\n",
       "\n",
       "       [[-6.87030470e-03,  3.58987629e-01, -2.27563716e-02,\n",
       "         -5.14778376e-01],\n",
       "        [ 3.09447641e-04,  5.54422557e-01, -3.30519415e-02,\n",
       "         -8.14544618e-01]],\n",
       "\n",
       "       [[ 3.58041450e-02,  1.88110411e-01,  1.34249555e-03,\n",
       "         -3.08248758e-01],\n",
       "        [ 3.95663530e-02, -7.03064771e-03, -4.82247956e-03,\n",
       "         -1.51427481e-02]],\n",
       "\n",
       "       [[-5.49519882e-02, -2.25078776e-01,  1.22636303e-01,\n",
       "          5.71385920e-01],\n",
       "        [-5.94535656e-02, -3.18706259e-02,  1.34064019e-01,\n",
       "          3.19715053e-01]],\n",
       "\n",
       "       [[ 2.49030776e-02,  1.87213808e-01,  1.07653968e-01,\n",
       "          2.39199802e-01],\n",
       "        [ 2.86473539e-02, -9.26818699e-03,  1.12437963e-01,\n",
       "          5.63805759e-01]],\n",
       "\n",
       "       [[ 6.21841103e-02,  3.38061191e-02, -1.78604499e-01,\n",
       "         -2.85961181e-01],\n",
       "        [ 6.28602356e-02, -1.58378854e-01, -1.84323728e-01,\n",
       "         -5.45004793e-02]],\n",
       "\n",
       "       [[-7.96385184e-02, -7.93313384e-01,  7.14237392e-02,\n",
       "          1.20601845e+00],\n",
       "        [-9.55047831e-02, -9.89281893e-01,  9.55441073e-02,\n",
       "          1.52020240e+00]],\n",
       "\n",
       "       [[ 2.73374617e-02,  4.76844329e-03, -1.59947142e-01,\n",
       "         -3.95884663e-01],\n",
       "        [ 2.74328310e-02,  2.01755390e-01, -1.67864829e-01,\n",
       "         -7.34417677e-01]],\n",
       "\n",
       "       [[ 2.55563445e-02,  6.28990293e-01, -4.07906920e-02,\n",
       "         -8.75901043e-01],\n",
       "        [ 3.81361507e-02,  4.34445828e-01, -5.83087131e-02,\n",
       "         -5.96316218e-01]],\n",
       "\n",
       "       [[-3.99517231e-02, -4.10840437e-02,  1.16956562e-01,\n",
       "          3.15071940e-01],\n",
       "        [-4.07734029e-02, -2.37660915e-01,  1.23257995e-01,\n",
       "          6.42229736e-01]],\n",
       "\n",
       "       [[ 8.39788690e-02,  9.49032187e-01, -9.96756405e-02,\n",
       "         -1.49795067e+00],\n",
       "        [ 1.02959514e-01,  1.14521420e+00, -1.29634649e-01,\n",
       "         -1.82001913e+00]],\n",
       "\n",
       "       [[-4.88961563e-02, -6.34770095e-01,  1.19659036e-01,\n",
       "          1.06556833e+00],\n",
       "        [-6.15915582e-02, -8.31254721e-01,  1.40970394e-01,\n",
       "          1.39328361e+00]],\n",
       "\n",
       "       [[-1.02369212e-01, -1.39699399e+00,  2.03915417e-01,\n",
       "          2.22961617e+00],\n",
       "        [-1.30309090e-01, -1.20431209e+00,  2.48507738e-01,\n",
       "          2.00611806e+00]],\n",
       "\n",
       "       [[ 2.05180771e-03, -3.12970392e-02,  3.09341215e-02,\n",
       "          9.72083211e-02],\n",
       "        [ 1.42586697e-03, -2.26848379e-01,  3.28782871e-02,\n",
       "          3.99488181e-01]],\n",
       "\n",
       "       [[-7.82166496e-02, -6.38140619e-01,  1.68836072e-01,\n",
       "          1.14779413e+00],\n",
       "        [-9.09794644e-02, -4.45576161e-01,  1.91791952e-01,\n",
       "          9.12456870e-01]]], dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 2]])>,\n",
       " 'reward': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.]], dtype=float32)>})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32)),\n",
       " 'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LossInfo(loss=<tf.Tensor: shape=(), dtype=float32, numpy=1.1128343>, extra=DqnLossInfo(td_loss=<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([1.0886229 , 1.5892605 , 1.1110591 , 0.        , 1.1343968 ,\n",
       "       1.0969319 , 1.026634  , 1.2525074 , 1.0593758 , 1.0703673 ,\n",
       "       1.5365903 , 1.0551149 , 0.9358639 , 1.0036174 , 1.1690512 ,\n",
       "       0.95261174, 1.0690074 , 1.2823228 , 0.9863183 , 1.0834103 ,\n",
       "       0.9351009 , 1.280489  , 1.1224147 , 1.0973485 , 1.0758709 ,\n",
       "       1.2963628 , 0.930966  , 1.0985256 , 1.0724196 , 1.0795599 ,\n",
       "       1.0851401 , 1.0919621 , 1.6829996 , 0.9396096 , 0.9377649 ,\n",
       "       1.3334156 , 1.280489  , 1.0795599 , 1.1482856 , 1.0899493 ,\n",
       "       1.2293744 , 1.039397  , 1.0466753 , 1.116076  , 1.3569489 ,\n",
       "       1.261539  , 1.1373965 , 1.0376269 , 1.0994176 , 1.0810084 ,\n",
       "       1.0994176 , 1.0379374 , 0.9539401 , 1.120543  , 1.0384933 ,\n",
       "       1.4580355 , 1.0816119 , 1.3013648 , 1.1628381 , 1.0977865 ,\n",
       "       1.396906  , 0.8562319 , 1.1034409 , 0.94609267], dtype=float32)>, td_error=<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([1.043371  , 1.2606587 , 1.0540679 , 0.        , 1.0650806 ,\n",
       "       1.0473452 , 1.0132295 , 1.1191548 , 1.0292598 , 1.0345856 ,\n",
       "       1.2395928 , 1.0271878 , 0.9674006 , 1.0018071 , 1.0812267 ,\n",
       "       0.9760183 , 1.0339282 , 1.1323969 , 0.9931356 , 1.04087   ,\n",
       "       0.96700615, 1.1315869 , 1.0594407 , 1.047544  , 1.0372419 ,\n",
       "       1.1385792 , 0.9648658 , 1.0481057 , 1.0355769 , 1.0390188 ,\n",
       "       1.0417006 , 1.0449699 , 1.2973047 , 0.9693346 , 0.9683826 ,\n",
       "       1.1547362 , 1.1315869 , 1.0390188 , 1.0715809 , 1.0440063 ,\n",
       "       1.1087716 , 1.0195082 , 1.0230715 , 1.056445  , 1.1648815 ,\n",
       "       1.1231825 , 1.0664879 , 1.0186397 , 1.0485312 , 1.0397155 ,\n",
       "       1.0485312 , 1.0187922 , 0.9766986 , 1.058557  , 1.0190649 ,\n",
       "       1.2074914 , 1.0400057 , 1.1407738 , 1.0783497 , 1.0477531 ,\n",
       "       1.1819078 , 0.925328  , 1.050448  , 0.97267294], dtype=float32)>))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = suite_gym.load('CartPole-v1')\n",
    "eval_env = TFPyEnvironment(eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(n_iteration):\n",
    "    # losses = []\n",
    "    avg_returns = []\n",
    "    cus_return = []\n",
    "    train_step.assign(0)\n",
    "    time_step = None\n",
    "    policy_state = agent.collect_policy.get_initial_state(env.batch_size)\n",
    "    iterator = iter(dataset)\n",
    "\n",
    "    for iteration in range(n_iteration):\n",
    "        time_step, policy_state = collect_driver.run(time_step)\n",
    "        trajectories, buffer_info = next(iterator)\n",
    "        train_loss = agent.train(trajectories)\n",
    "        loss = train_loss.loss.numpy()\n",
    "        avg_return = train_metrics[0].result().numpy()\n",
    "        \n",
    "        if train_step%200 == 0:\n",
    "            print(f'train step: {train_step.value()}      loss: {loss}')\n",
    "        if train_step%1000 == 0:\n",
    "            cust_re = compute_avg_return(eval_env, agent.policy,2)\n",
    "            # losses.append(loss)\n",
    "            avg_returns.append(avg_return)\n",
    "            cus_return.append(cust_re)\n",
    "            print(f'train step: {train_step.value()}    avg_return: {avg_return}     customreturn: {cust_re}')\n",
    "\n",
    "    return avg_returns, cus_return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step: 200      loss: 822.406494140625\n",
      "train step: 400      loss: 38302.7734375\n",
      "train step: 600      loss: 183441.8125\n",
      "train step: 800      loss: 50025.0625\n",
      "train step: 1000      loss: 12445.2451171875\n",
      "train step: 1000    avg_return: 9.199999809265137     customreturn: 9.0\n",
      "train step: 1200      loss: 22046.15234375\n",
      "train step: 1400      loss: 9987.9462890625\n",
      "train step: 1600      loss: 8024.8544921875\n",
      "train step: 1800      loss: 4571.8212890625\n",
      "train step: 2000      loss: 1937.599365234375\n",
      "train step: 2000    avg_return: 9.600000381469727     customreturn: 9.5\n",
      "train step: 2200      loss: 2466.308349609375\n",
      "train step: 2400      loss: 1447.383544921875\n",
      "train step: 2600      loss: 774.0645751953125\n",
      "train step: 2800      loss: 610.4680786132812\n",
      "train step: 3000      loss: 121.85175323486328\n",
      "train step: 3000    avg_return: 9.5     customreturn: 9.5\n",
      "train step: 3200      loss: 290.7613220214844\n",
      "train step: 3400      loss: 50.676170349121094\n",
      "train step: 3600      loss: 36.18635177612305\n",
      "train step: 3800      loss: 133.09625244140625\n",
      "train step: 4000      loss: 26.121715545654297\n",
      "train step: 4000    avg_return: 57.29999923706055     customreturn: 60.0\n",
      "train step: 4200      loss: 96.26740264892578\n",
      "train step: 4400      loss: 21.285598754882812\n",
      "train step: 4600      loss: 327.43865966796875\n",
      "train step: 4800      loss: 147.5107421875\n",
      "train step: 5000      loss: 273.54132080078125\n",
      "train step: 5000    avg_return: 35.599998474121094     customreturn: 42.0\n",
      "train step: 5200      loss: 130.81637573242188\n",
      "train step: 5400      loss: 392.73455810546875\n",
      "train step: 5600      loss: 363.5910339355469\n",
      "train step: 5800      loss: 257.9346923828125\n",
      "train step: 6000      loss: 57.01104736328125\n",
      "train step: 6000    avg_return: 45.900001525878906     customreturn: 35.0\n",
      "train step: 6200      loss: 128.16555786132812\n",
      "train step: 6400      loss: 249.23248291015625\n",
      "train step: 6600      loss: 346.5849609375\n",
      "train step: 6800      loss: 264.1281433105469\n",
      "train step: 7000      loss: 93.67239379882812\n",
      "train step: 7000    avg_return: 45.0     customreturn: 42.5\n",
      "train step: 7200      loss: 13.973738670349121\n",
      "train step: 7400      loss: 206.52206420898438\n",
      "train step: 7600      loss: 316.1359558105469\n",
      "train step: 7800      loss: 211.6107940673828\n",
      "train step: 8000      loss: 50.850990295410156\n",
      "train step: 8000    avg_return: 65.0999984741211     customreturn: 246.5\n",
      "train step: 8200      loss: 46.8320426940918\n",
      "train step: 8400      loss: 60.68193817138672\n",
      "train step: 8600      loss: 98.24336242675781\n",
      "train step: 8800      loss: 39.39942932128906\n",
      "train step: 9000      loss: 393.51837158203125\n",
      "train step: 9000    avg_return: 101.0999984741211     customreturn: 317.0\n",
      "train step: 9200      loss: 13.264107704162598\n",
      "train step: 9400      loss: 10.952537536621094\n",
      "train step: 9600      loss: 63.498870849609375\n",
      "train step: 9800      loss: 12.474531173706055\n",
      "train step: 10000      loss: 22.399459838867188\n",
      "train step: 10000    avg_return: 128.6999969482422     customreturn: 288.0\n",
      "train step: 10200      loss: 550.9357299804688\n",
      "train step: 10400      loss: 527.10302734375\n",
      "train step: 10600      loss: 67.09690856933594\n",
      "train step: 10800      loss: 768.0131225585938\n",
      "train step: 11000      loss: 30.246326446533203\n",
      "train step: 11000    avg_return: 112.19999694824219     customreturn: 268.5\n",
      "train step: 11200      loss: 33.928367614746094\n",
      "train step: 11400      loss: 1450.394775390625\n",
      "train step: 11600      loss: 38.22696304321289\n",
      "train step: 11800      loss: 1070.7686767578125\n",
      "train step: 12000      loss: 83.70655822753906\n",
      "train step: 12000    avg_return: 150.89999389648438     customreturn: 360.5\n",
      "train step: 12200      loss: 78.25361633300781\n",
      "train step: 12400      loss: 138.6601104736328\n",
      "train step: 12600      loss: 983.7266235351562\n",
      "train step: 12800      loss: 3714.6201171875\n",
      "train step: 13000      loss: 207.62841796875\n",
      "train step: 13000    avg_return: 219.3000030517578     customreturn: 491.0\n",
      "train step: 13200      loss: 333.33148193359375\n",
      "train step: 13400      loss: 1809.4931640625\n",
      "train step: 13600      loss: 678.671875\n",
      "train step: 13800      loss: 2201.780517578125\n",
      "train step: 14000      loss: 5802.9453125\n",
      "train step: 14000    avg_return: 246.3000030517578     customreturn: 368.0\n",
      "train step: 14200      loss: 6780.3017578125\n",
      "train step: 14400      loss: 2740.2060546875\n",
      "train step: 14600      loss: 264.18609619140625\n",
      "train step: 14800      loss: 1417.9852294921875\n",
      "train step: 15000      loss: 504.7906494140625\n",
      "train step: 15000    avg_return: 258.20001220703125     customreturn: 202.0\n",
      "train step: 15200      loss: 710.7608032226562\n",
      "train step: 15400      loss: 788.9706420898438\n",
      "train step: 15600      loss: 689.1566162109375\n",
      "train step: 15800      loss: 6247.28271484375\n",
      "train step: 16000      loss: 16669.8203125\n",
      "train step: 16000    avg_return: 288.1000061035156     customreturn: 387.5\n",
      "train step: 16200      loss: 908.8984985351562\n",
      "train step: 16400      loss: 6878.400390625\n",
      "train step: 16600      loss: 1695.7021484375\n",
      "train step: 16800      loss: 905.0968017578125\n",
      "train step: 17000      loss: 3115.30859375\n",
      "train step: 17000    avg_return: 294.70001220703125     customreturn: 321.5\n",
      "train step: 17200      loss: 1589.1729736328125\n",
      "train step: 17400      loss: 6949.9814453125\n",
      "train step: 17600      loss: 1717.199951171875\n",
      "train step: 17800      loss: 14485.0341796875\n",
      "train step: 18000      loss: 2468.71240234375\n",
      "train step: 18000    avg_return: 321.5     customreturn: 500.0\n",
      "train step: 18200      loss: 1279.03369140625\n",
      "train step: 18400      loss: 1384.94091796875\n",
      "train step: 18600      loss: 1577.1806640625\n",
      "train step: 18800      loss: 10965.21484375\n",
      "train step: 19000      loss: 11196.3984375\n",
      "train step: 19000    avg_return: 301.70001220703125     customreturn: 425.0\n",
      "train step: 19200      loss: 21099.65625\n",
      "train step: 19400      loss: 12415.6591796875\n",
      "train step: 19600      loss: 13892.615234375\n",
      "train step: 19800      loss: 1466.744140625\n",
      "train step: 20000      loss: 1672.6513671875\n",
      "train step: 20000    avg_return: 311.20001220703125     customreturn: 380.5\n"
     ]
    }
   ],
   "source": [
    "avg_returns, cus_return = train_agent(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'returns': avg_returns}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'cus_return': cus_return}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a evaluation environment to test policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_py_env = suite_gym.load('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tf_env = TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.0381218 ,  0.02638063, -0.03834511, -0.00541219], dtype=float32)})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_py_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.03878308,  0.00974433, -0.02248679, -0.04457033]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tf_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.03878308,  0.00974433, -0.02248679, -0.04457033], dtype=float32)})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_py_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.03878308,  0.00974433, -0.02248679, -0.04457033]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tf_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tf_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.03878308,  0.00974433, -0.02248679, -0.04457033]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tf_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_py_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.03878308,  0.00974433, -0.02248679, -0.04457033], dtype=float32)})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_py_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.greedy_policy.GreedyPolicy at 0x15913b2b590>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_name': 'greedy_policy',\n",
       " '_name_scope': <tensorflow.python.framework.ops.name_scope_v2 at 0x1591eebc280>,\n",
       " '_time_step_spec': TimeStep(\n",
       " {'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       "  'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       "  'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "       dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "       dtype=float32))}),\n",
       " '_action_spec': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " '_policy_state_spec': (),\n",
       " '_emit_log_probability': False,\n",
       " '_validate_args': True,\n",
       " '_info_spec': (),\n",
       " '_policy_step_spec': PolicyStep(action=BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)), state=(), info=()),\n",
       " '_trajectory_spec': Trajectory(\n",
       " {'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "       dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "       dtype=float32)),\n",
       "  'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       "  'policy_info': (),\n",
       "  'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       "  'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))}),\n",
       " '_clip': True,\n",
       " '_action_fn': <function tf_agents.policies.tf_policy.TFPolicy._action(time_step: tf_agents.trajectories.time_step.TimeStep, policy_state: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], seed: Union[int, Sequence[int], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, float, str, bool, NoneType] = None) -> tf_agents.trajectories.policy_step.PolicyStep>,\n",
       " '_automatic_state_reset': True,\n",
       " '_observation_and_action_constraint_splitter': None,\n",
       " '_self_setattr_tracking': True,\n",
       " '_self_unconditional_checkpoint_dependencies': [TrackableReference(name=_wrapped_policy, ref=<tf_agents.policies.q_policy.QPolicy object at 0x000001591EB9CE50>)],\n",
       " '_self_unconditional_dependency_names': {'_wrapped_policy': <tf_agents.policies.q_policy.QPolicy at 0x1591eb9ce50>},\n",
       " '_self_unconditional_deferred_dependencies': {},\n",
       " '_self_update_uid': -1,\n",
       " '_self_name_based_restores': set(),\n",
       " '_self_saveable_object_factories': {},\n",
       " '_wrapped_policy': <tf_agents.policies.q_policy.QPolicy at 0x1591eb9ce50>}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0], dtype=int64)>, state=(), info=())"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.action(eval_tf_env.current_time_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_flat_action_spec': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " '_self_setattr_tracking': True,\n",
       " '_self_unconditional_checkpoint_dependencies': [TrackableReference(name=_q_network, ref=<tf_agents.networks.q_network.QNetwork object at 0x000001591D7BDD10>)],\n",
       " '_self_unconditional_dependency_names': {'_q_network': <tf_agents.networks.q_network.QNetwork at 0x1591d7bdd10>},\n",
       " '_self_unconditional_deferred_dependencies': {},\n",
       " '_self_update_uid': -1,\n",
       " '_self_name_based_restores': set(),\n",
       " '_self_saveable_object_factories': {},\n",
       " '_q_network': <tf_agents.networks.q_network.QNetwork at 0x1591d7bdd10>,\n",
       " '_name': 'q_policy',\n",
       " '_name_scope': <tensorflow.python.framework.ops.name_scope_v2 at 0x1591ebcfaf0>,\n",
       " '_time_step_spec': TimeStep(\n",
       " {'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       "  'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       "  'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "       dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "       dtype=float32))}),\n",
       " '_action_spec': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " '_policy_state_spec': (),\n",
       " '_emit_log_probability': False,\n",
       " '_validate_args': True,\n",
       " '_info_spec': (),\n",
       " '_policy_step_spec': PolicyStep(action=BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)), state=(), info=()),\n",
       " '_trajectory_spec': Trajectory(\n",
       " {'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "       dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "       dtype=float32)),\n",
       "  'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       "  'policy_info': (),\n",
       "  'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       "  'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))}),\n",
       " '_clip': False,\n",
       " '_action_fn': <function tf_agents.policies.tf_policy.TFPolicy._action(time_step: tf_agents.trajectories.time_step.TimeStep, policy_state: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], seed: Union[int, Sequence[int], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, float, str, bool, NoneType] = None) -> tf_agents.trajectories.policy_step.PolicyStep>,\n",
       " '_automatic_state_reset': True,\n",
       " '_observation_and_action_constraint_splitter': None}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.wrapped_policy.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    time_step = eval_tf_env.reset()\n",
    "\n",
    "    while not time_step.is_last():\n",
    "        time_step = eval_tf_env.step(policy.action(time_step))\n",
    "        eval_py_env.render(mode='human')\n",
    "\n",
    "eval_py_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_py_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a trained agent policy to be used in another program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies.policy_saver import PolicySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "this __dict__ descriptor does not support '_DictWrapper' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m policy_saver \u001b[38;5;241m=\u001b[39m \u001b[43mPolicySaver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tf_agents\\policies\\policy_saver.py:333\u001b[0m, in \u001b[0;36mPolicySaver.__init__\u001b[1;34m(self, policy, batch_size, use_nest_path_signatures, seed, train_step, input_fn_and_spec, metadata)\u001b[0m\n\u001b[0;32m    326\u001b[0m get_initial_state_fn\u001b[38;5;241m.\u001b[39mget_concrete_function(\u001b[38;5;241m*\u001b[39mget_initial_state_input_specs)\n\u001b[0;32m    328\u001b[0m train_step_fn \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: saved_policy\u001b[38;5;241m.\u001b[39mtrain_step\n\u001b[0;32m    330\u001b[0m )\u001b[38;5;241m.\u001b[39mget_concrete_function()\n\u001b[0;32m    331\u001b[0m get_metadata_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\n\u001b[1;32m--> 333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m batched_time_step_spec \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m spec: add_batch_dim(spec, [batch_size]), policy\u001b[38;5;241m.\u001b[39mtime_step_spec\n\u001b[0;32m    337\u001b[0m )\n\u001b[0;32m    338\u001b[0m batched_time_step_spec \u001b[38;5;241m=\u001b[39m cast(ts\u001b[38;5;241m.\u001b[39mTimeStep, batched_time_step_spec)\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    693\u001b[0m )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:331\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    328\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_captures\u001b[38;5;241m.\u001b[39mmerge_by_ref_with(graph_capture_container)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# Create a new FunctionType including captures and outputs.\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m output_type \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraced_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_context\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m traced_func_type \u001b[38;5;241m=\u001b[39m function_type_lib\u001b[38;5;241m.\u001b[39mFunctionType(\n\u001b[0;32m    335\u001b[0m     function_type\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    336\u001b[0m     traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\u001b[38;5;241m.\u001b[39mcapture_types,\n\u001b[0;32m    337\u001b[0m     return_annotation\u001b[38;5;241m=\u001b[39moutput_type,\n\u001b[0;32m    338\u001b[0m )\n\u001b[0;32m    340\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m concrete_function_lib\u001b[38;5;241m.\u001b[39mConcreteFunction\u001b[38;5;241m.\u001b[39mfrom_func_graph(\n\u001b[0;32m    341\u001b[0m     traced_func_graph,\n\u001b[0;32m    342\u001b[0m     traced_func_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py:144\u001b[0m, in \u001b[0;36mfrom_value\u001b[1;34m(value, context)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mis_legacy_signature \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, trace\u001b[38;5;241m.\u001b[39mTraceType):\n\u001b[0;32m    143\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, trace\u001b[38;5;241m.\u001b[39mSupportsTracingProtocol):\n\u001b[0;32m    145\u001b[0m   generated_type \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39m__tf_tracing_type__(context)\n\u001b[0;32m    146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generated_type, trace\u001b[38;5;241m.\u001b[39mTraceType):\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\typing_extensions.py:647\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol_attrs__:\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetattr_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\inspect.py:1821\u001b[0m, in \u001b[0;36mgetattr_static\u001b[1;34m(obj, attr, default)\u001b[0m\n\u001b[0;32m   1818\u001b[0m     dict_attr \u001b[38;5;241m=\u001b[39m _shadowed_dict(klass)\n\u001b[0;32m   1819\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1820\u001b[0m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types\u001b[38;5;241m.\u001b[39mMemberDescriptorType):\n\u001b[1;32m-> 1821\u001b[0m         instance_result \u001b[38;5;241m=\u001b[39m \u001b[43m_check_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1822\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1823\u001b[0m     klass \u001b[38;5;241m=\u001b[39m obj\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\inspect.py:1768\u001b[0m, in \u001b[0;36m_check_instance\u001b[1;34m(obj, attr)\u001b[0m\n\u001b[0;32m   1766\u001b[0m instance_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1768\u001b[0m     instance_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__dict__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   1770\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: this __dict__ descriptor does not support '_DictWrapper' objects"
     ]
    }
   ],
   "source": [
    "policy_saver = PolicySaver(policy= agent.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
