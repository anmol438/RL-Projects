{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the TF Agents to train the CartPole environment with DQN.\n",
    "TF Agents package makes the implementation of RL algo easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tf_agents\\typing\\types.py:114: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.environments import suite_gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = suite_gym.load(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.environments.wrappers.TimeLimit at 0x1facaf02f50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<OrderEnforcing<CartPoleEnv<CartPole-v1>>>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.00938285, -0.02642902,  0.03463222, -0.0304736 ], dtype=float32)})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(1),\n",
       " 'reward': array(1., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.00885427, -0.22203006,  0.03402275,  0.27293187], dtype=float32)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore Environment Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': ArraySpec(shape=(), dtype=dtype('int32'), name='step_type'),\n",
       " 'reward': ArraySpec(shape=(), dtype=dtype('float32'), name='reward'),\n",
       " 'discount': BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0),\n",
       " 'observation': BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.discount_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(1),\n",
       " 'reward': array(1., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.00885427, -0.22203006,  0.03402275,  0.27293187], dtype=float32)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_time_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the environment with TFPyEnvironment which supports both py and tf environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments.tf_py_environment import TFPyEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TFPyEnvironment(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.environments.tf_py_environment.TFPyEnvironment at 0x1facdd3da50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.01941166,  0.04063222, -0.04695464, -0.01227651]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.0202243 , -0.15378599, -0.04720017,  0.2652298 ]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(), dtype=tf.float32, name='reward')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.discount_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.0202243 , -0.15378599, -0.04720017,  0.2652298 ]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_time_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks.q_network import QNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class QNetwork in module tf_agents.networks.q_network:\n",
      "\n",
      "class QNetwork(tf_agents.networks.network.Network)\n",
      " |  QNetwork(input_tensor_spec, action_spec, preprocessing_layers=None, preprocessing_combiner=None, conv_layer_params=None, fc_layer_params=(75, 40), dropout_layer_params=None, activation_fn=<function relu at 0x000001FACB331120>, kernel_initializer=None, batch_squash=True, dtype=tf.float32, q_layer_activation_fn=None, name='QNetwork')\n",
      " |  \n",
      " |  Feed Forward network.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      QNetwork\n",
      " |      tf_agents.networks.network.Network\n",
      " |      keras.src.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      keras.src.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_tensor_spec, action_spec, preprocessing_layers=None, preprocessing_combiner=None, conv_layer_params=None, fc_layer_params=(75, 40), dropout_layer_params=None, activation_fn=<function relu at 0x000001FACB331120>, kernel_initializer=None, batch_squash=True, dtype=tf.float32, q_layer_activation_fn=None, name='QNetwork')\n",
      " |      Creates an instance of `QNetwork`.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_tensor_spec: A nest of `tensor_spec.TensorSpec` representing the\n",
      " |          input observations.\n",
      " |        action_spec: A nest of `tensor_spec.BoundedTensorSpec` representing the\n",
      " |          actions.\n",
      " |        preprocessing_layers: (Optional.) A nest of `tf.keras.layers.Layer`\n",
      " |          representing preprocessing for the different observations. All of these\n",
      " |          layers must not be already built. For more details see the documentation\n",
      " |          of `networks.EncodingNetwork`.\n",
      " |        preprocessing_combiner: (Optional.) A keras layer that takes a flat list\n",
      " |          of tensors and combines them. Good options include `tf.keras.layers.Add`\n",
      " |          and `tf.keras.layers.Concatenate(axis=-1)`. This layer must not be\n",
      " |          already built. For more details see the documentation of\n",
      " |          `networks.EncodingNetwork`.\n",
      " |        conv_layer_params: Optional list of convolution layers parameters, where\n",
      " |          each item is a length-three tuple indicating (filters, kernel_size,\n",
      " |          stride).\n",
      " |        fc_layer_params: Optional list of fully_connected parameters, where each\n",
      " |          item is the number of units in the layer.\n",
      " |        dropout_layer_params: Optional list of dropout layer parameters, where\n",
      " |          each item is the fraction of input units to drop. The dropout layers are\n",
      " |          interleaved with the fully connected layers; there is a dropout layer\n",
      " |          after each fully connected layer, except if the entry in the list is\n",
      " |          None. This list must have the same length of fc_layer_params, or be\n",
      " |          None.\n",
      " |        activation_fn: Activation function, e.g. tf.keras.activations.relu.\n",
      " |        kernel_initializer: Initializer to use for the kernels of the conv and\n",
      " |          dense layers. If none is provided a default variance_scaling_initializer\n",
      " |        batch_squash: If True the outer_ranks of the observation are squashed into\n",
      " |          the batch dimension. This allow encoding networks to be used with\n",
      " |          observations with shape [BxTx...].\n",
      " |        dtype: The dtype to use by the convolution and fully connected layers.\n",
      " |        q_layer_activation_fn: Activation function for the Q layer.\n",
      " |        name: A string representing the name of the network.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `input_tensor_spec` contains more than one observation. Or\n",
      " |          if `action_spec` contains more than one action.\n",
      " |  \n",
      " |  call(self, observation, step_type=None, network_state=(), training=False)\n",
      " |      Runs the given observation through the network.\n",
      " |      \n",
      " |      Args:\n",
      " |        observation: The observation to provide to the network.\n",
      " |        step_type: The step type for the given observation. See `StepType` in\n",
      " |          time_step.py.\n",
      " |        network_state: A state tuple to pass to the network, mainly used by RNNs.\n",
      " |        training: Whether the output is being used for training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple `(logits, network_state)`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tf_agents.networks.network.Network:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      A wrapper around `Network.call`.\n",
      " |      \n",
      " |      A typical `call` method in a class subclassing `Network` will have a\n",
      " |      signature that accepts `inputs`, as well as other `*args` and `**kwargs`.\n",
      " |      `call` can optionally also accept `step_type` and `network_state`\n",
      " |      (if `state_spec != ()` is not trivial).  e.g.:\n",
      " |      \n",
      " |      ```python\n",
      " |      def call(self,\n",
      " |               inputs,\n",
      " |               step_type=None,\n",
      " |               network_state=(),\n",
      " |               training=False):\n",
      " |          ...\n",
      " |          return outputs, new_network_state\n",
      " |      ```\n",
      " |      \n",
      " |      We will validate the first argument (`inputs`)\n",
      " |      against `self.input_tensor_spec` if one is available.\n",
      " |      \n",
      " |      If a `network_state` kwarg is given it is also validated against\n",
      " |      `self.state_spec`.  Similarly, the return value of the `call` method is\n",
      " |      expected to be a tuple/list with 2 values:  `(output, new_state)`.\n",
      " |      We validate `new_state` against `self.state_spec`.\n",
      " |      \n",
      " |      If no `network_state` kwarg is given (or if empty `network_state = ()` is\n",
      " |      given, it is up to `call` to assume a proper \"empty\" state, and to\n",
      " |      emit an appropriate `output_state`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: The input to `self.call`, matching `self.input_tensor_spec`.\n",
      " |        *args: Additional arguments to `self.call`.\n",
      " |        **kwargs: Additional keyword arguments to `self.call`. These can include\n",
      " |          `network_state` and `step_type`.  `step_type` is required if the\n",
      " |          network's `call` requires it. `network_state` is required if the\n",
      " |          underlying network's `call` requires it.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple `(outputs, new_network_state)`.\n",
      " |  \n",
      " |  copy(self, **kwargs)\n",
      " |      Create a shallow copy of this network.\n",
      " |      \n",
      " |      **NOTE** Network layer weights are *never* copied.  This method recreates\n",
      " |      the `Network` instance with the same arguments it was initialized with\n",
      " |      (excepting any new kwargs).\n",
      " |      \n",
      " |      Args:\n",
      " |        **kwargs: Args to override when recreating this network.  Commonly\n",
      " |          overridden args include 'name'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A shallow copy of this network.\n",
      " |  \n",
      " |  create_variables(self, input_tensor_spec=None, **kwargs)\n",
      " |      Force creation of the network's variables.\n",
      " |      \n",
      " |      Return output specs.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_tensor_spec: (Optional).  Override or provide an input tensor spec\n",
      " |          when creating variables.\n",
      " |        **kwargs: Other arguments to `network.call()`, e.g. `training=True`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output specs - a nested spec calculated from the outputs (excluding any\n",
      " |        batch dimensions).  If any of the output elements is a tfp `Distribution`,\n",
      " |        the associated spec entry returned is a `DistributionSpec`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If no `input_tensor_spec` is provided, and the network did\n",
      " |          not provide one during construction.\n",
      " |  \n",
      " |  get_initial_state(self, batch_size=None)\n",
      " |      Returns an initial state usable by the network.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: Tensor or constant: size of the batch dimension. Can be None\n",
      " |          in which case not dimensions gets added.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A nested object of type `self.state_spec` containing properly\n",
      " |        initialized Tensors.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Args:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Args:\n",
      " |          line_length: Total length of printed lines (e.g. set this to adapt the\n",
      " |            display to different terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements in each line.\n",
      " |            If not provided, defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`. It will be called\n",
      " |            on each line of the summary. You can set it to a custom function in\n",
      " |            order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tf_agents.networks.network.Network:\n",
      " |  \n",
      " |  input_tensor_spec\n",
      " |      Returns the spec of the input to the network of type InputSpec.\n",
      " |  \n",
      " |  layers\n",
      " |      Get the list of all (nested) sub-layers used in this Network.\n",
      " |  \n",
      " |  state_spec\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
      " |      not themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be\n",
      " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
      " |      the same layer on different inputs `a` and `b`, some entries in\n",
      " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
      " |      automatically keeps track of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      The same code works in distributed training: the input to `add_loss()`\n",
      " |      is treated like a regularization loss and averaged across replicas\n",
      " |      by the training loop (both built-in `Model.fit()` and compliant custom\n",
      " |      training loops).\n",
      " |      \n",
      " |      The `add_loss` method can also be called directly on a Functional Model\n",
      " |      during construction. In this case, any loss Tensors passed to this Model\n",
      " |      must be symbolic and be able to be traced back to the model's `Input`s.\n",
      " |      These losses become part of the model's topology and are tracked in\n",
      " |      `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss\n",
      " |      references a `Variable` of one of the model's layers), you can wrap your\n",
      " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
      " |      the model's topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
      " |          losses may also be zero-argument callables which create a loss\n",
      " |          tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This\n",
      " |      is because we cannot trace the metric result tensor back to the model's\n",
      " |      inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result\n",
      " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
      " |          default using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and\n",
      " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
      " |      passed when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case,\n",
      " |      variable updates are run on the fly and thus do not need to be tracked\n",
      " |      for later execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use a `ResourceVariable` or not.\n",
      " |          See [this guide](\n",
      " |          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
      " |           for more information.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set\n",
      " |          to `AUTO` and the current `DistributionStrategy` chooses when to\n",
      " |          synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n",
      " |          must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as\n",
      " |          `ON_READ`.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call. It is invoked automatically before\n",
      " |      the first execution of `call()`.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses\n",
      " |      (at the discretion of the subclass implementer).\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  build_from_config(self, config)\n",
      " |      Builds the layer's states with the supplied config dict.\n",
      " |      \n",
      " |      By default, this method calls the `build(config[\"input_shape\"])` method,\n",
      " |      which creates weights based on the layer's input shape in the supplied\n",
      " |      config. If your config contains other information needed to load the\n",
      " |      layer's state, you should override this method.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: Dict containing the input shape associated with this layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,\n",
      " |              or structure of shape tuples / `tf.TensorShape` instances\n",
      " |              (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `tf.TensorShape` instance\n",
      " |          or structure of `tf.TensorShape` instances.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
      " |          describing how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after\n",
      " |      updating a layer weights. It can be overridden to finalize any\n",
      " |      additional layer state after a weight update.\n",
      " |      \n",
      " |      This function will be called after weights of a layer have been restored\n",
      " |      from a loaded model.\n",
      " |  \n",
      " |  get_build_config(self)\n",
      " |      Returns a dictionary with the layer's input shape.\n",
      " |      \n",
      " |      This method returns a config dict that can be used by\n",
      " |      `build_from_config(config)` to create all states (e.g. Variables and\n",
      " |      Lookup tables) needed by the layer.\n",
      " |      \n",
      " |      By default, the config only contains the input shape that the layer\n",
      " |      was built with. If you're writing a custom layer that creates state in\n",
      " |      an unusual way, you should override this method to make sure this state\n",
      " |      is already created when Keras attempts to load its value upon model\n",
      " |      loading.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict containing the input shape associated with the layer.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of\n",
      " |      dict every time it is called. The callers should make a copy of the\n",
      " |      returned dict if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with\n",
      " |      this layer as a list of NumPy arrays, which can in turn be used to load\n",
      " |      state into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  load_own_variables(self, store)\n",
      " |      Loads the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is loaded upon calling `keras.models.load_model()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict from which the state of the model will be loaded.\n",
      " |  \n",
      " |  save_own_variables(self, store)\n",
      " |      Saves the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is saved upon calling `model.save()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict where the state of the model will be saved.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from tf_agents.networks.network._NetworkMeta\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which\n",
      " |      causes computations and the output to be in the compute dtype as well.\n",
      " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
      " |      have to insert these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision\n",
      " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
      " |      output will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is\n",
      " |      accessed, so it is eager safe: accessing `losses` under a\n",
      " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
      " |      variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics attached to the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are\n",
      " |      expected to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to\n",
      " |      enable the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
      " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a\n",
      " |      nicely-formatted error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from tf_agents.networks.network._NetworkMeta\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(QNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_net = QNetwork(env.observation_spec(), env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.agents.dqn.dqn_agent import DqnAgent\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DqnAgent in module tf_agents.agents.dqn.dqn_agent:\n",
      "\n",
      "class DqnAgent(tf_agents.agents.tf_agent.TFAgent)\n",
      " |  DqnAgent(time_step_spec: tf_agents.trajectories.time_step.TimeStep, action_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')]], q_network: tf_agents.networks.network.Network, optimizer: Union[keras.src.optimizers.optimizer.Optimizer, tensorflow.python.training.optimizer.Optimizer], observation_and_action_constraint_splitter: Optional[Callable[[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]], Iterable[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]]]] = None, epsilon_greedy: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = 0.1, n_step_update: int = 1, boltzmann_temperature: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = None, emit_log_probability: bool = False, target_q_network: Optional[tf_agents.networks.network.Network] = None, target_update_tau: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, target_update_period: int = 1, td_errors_loss_fn: Optional[Callable[..., Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor]]] = None, gamma: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, reward_scale_factor: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, gradient_clipping: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, NoneType] = None, debug_summaries: bool = False, summarize_grads_and_vars: bool = False, train_step_counter: Optional[tensorflow.python.ops.variables.Variable] = None, training_data_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], NoneType] = None, name: Optional[str] = None)\n",
      " |  \n",
      " |  A DQN Agent.\n",
      " |  \n",
      " |  Implements the DQN algorithm from\n",
      " |  \n",
      " |  \"Human level control through deep reinforcement learning\"\n",
      " |    Mnih et al., 2015\n",
      " |    https://deepmind.com/research/dqn/\n",
      " |  \n",
      " |  This agent also implements n-step updates. See \"Rainbow: Combining\n",
      " |  Improvements in Deep Reinforcement Learning\" by Hessel et al., 2017, for a\n",
      " |  discussion on its benefits: https://arxiv.org/abs/1710.02298\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DqnAgent\n",
      " |      tf_agents.agents.tf_agent.TFAgent\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, time_step_spec: tf_agents.trajectories.time_step.TimeStep, action_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')]], q_network: tf_agents.networks.network.Network, optimizer: Union[keras.src.optimizers.optimizer.Optimizer, tensorflow.python.training.optimizer.Optimizer], observation_and_action_constraint_splitter: Optional[Callable[[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]], Iterable[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]]]] = None, epsilon_greedy: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = 0.1, n_step_update: int = 1, boltzmann_temperature: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = None, emit_log_probability: bool = False, target_q_network: Optional[tf_agents.networks.network.Network] = None, target_update_tau: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, target_update_period: int = 1, td_errors_loss_fn: Optional[Callable[..., Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor]]] = None, gamma: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, reward_scale_factor: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, gradient_clipping: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, NoneType] = None, debug_summaries: bool = False, summarize_grads_and_vars: bool = False, train_step_counter: Optional[tensorflow.python.ops.variables.Variable] = None, training_data_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], NoneType] = None, name: Optional[str] = None)\n",
      " |      Creates a DQN Agent.\n",
      " |      \n",
      " |      Args:\n",
      " |        time_step_spec: A `TimeStep` spec of the expected time_steps.\n",
      " |        action_spec: A nest of BoundedTensorSpec representing the actions.\n",
      " |        q_network: A `tf_agents.network.Network` to be used by the agent. The\n",
      " |          network will be called with `call(observation, step_type)` and should\n",
      " |          emit logits over the action space.\n",
      " |        optimizer: The optimizer to use for training.\n",
      " |        observation_and_action_constraint_splitter: A function used to process\n",
      " |          observations with action constraints. These constraints can indicate,\n",
      " |          for example, a mask of valid/invalid actions for a given state of the\n",
      " |          environment. The function takes in a full observation and returns a\n",
      " |          tuple consisting of 1) the part of the observation intended as input to\n",
      " |          the network and 2) the constraint. An example\n",
      " |          `observation_and_action_constraint_splitter` could be as simple as: ```\n",
      " |          def observation_and_action_constraint_splitter(observation): return\n",
      " |          observation['network_input'], observation['constraint'] ``` *Note*: when\n",
      " |          using `observation_and_action_constraint_splitter`, make sure the\n",
      " |          provided `q_network` is compatible with the network-specific half of the\n",
      " |          output of the `observation_and_action_constraint_splitter`. In\n",
      " |          particular, `observation_and_action_constraint_splitter` will be called\n",
      " |          on the observation before passing to the network. If\n",
      " |          `observation_and_action_constraint_splitter` is None, action constraints\n",
      " |          are not applied.\n",
      " |        epsilon_greedy: probability of choosing a random action in the default\n",
      " |          epsilon-greedy collect policy (used only if a wrapper is not provided to\n",
      " |          the collect_policy method). Only one of epsilon_greedy and\n",
      " |          boltzmann_temperature should be provided.\n",
      " |        n_step_update: The number of steps to consider when computing TD error and\n",
      " |          TD loss. Defaults to single-step updates. Note that this requires the\n",
      " |          user to call train on Trajectory objects with a time dimension of\n",
      " |          `n_step_update + 1`. However, note that we do not yet support\n",
      " |          `n_step_update > 1` in the case of RNNs (i.e., non-empty\n",
      " |          `q_network.state_spec`).\n",
      " |        boltzmann_temperature: Temperature value to use for Boltzmann sampling of\n",
      " |          the actions during data collection. The closer to 0.0, the higher the\n",
      " |          probability of choosing the best action. Only one of epsilon_greedy and\n",
      " |          boltzmann_temperature should be provided.\n",
      " |        emit_log_probability: Whether policies emit log probabilities or not.\n",
      " |        target_q_network: (Optional.)  A `tf_agents.network.Network` to be used as\n",
      " |          the target network during Q learning.  Every `target_update_period`\n",
      " |          train steps, the weights from `q_network` are copied (possibly with\n",
      " |          smoothing via `target_update_tau`) to `target_q_network`.  If\n",
      " |          `target_q_network` is not provided, it is created by making a copy of\n",
      " |          `q_network`, which initializes a new network with the same structure and\n",
      " |          its own layers and weights.  Network copying is performed via the\n",
      " |          `Network.copy` superclass method, and may inadvertently lead to the\n",
      " |          resulting network to share weights with the original.  This can happen\n",
      " |          if, for example, the original network accepted a pre-built Keras layer\n",
      " |          in its `__init__`, or accepted a Keras layer that wasn't built, but\n",
      " |          neglected to create a new copy.  In these cases, it is up to you to\n",
      " |          provide a target Network having weights that are not shared with the\n",
      " |          original `q_network`. If you provide a `target_q_network` that shares\n",
      " |          any weights with `q_network`, a warning will be logged but no exception\n",
      " |          is thrown.  Note; shallow copies of Keras layers may be built via the\n",
      " |          code ```python new_layer =\n",
      " |          type(layer).from_config(layer.get_config())```\n",
      " |        target_update_tau: Factor for soft update of the target networks.\n",
      " |        target_update_period: Period for soft update of the target networks.\n",
      " |        td_errors_loss_fn: A function for computing the TD errors loss. If None, a\n",
      " |          default value of element_wise_huber_loss is used. This function takes as\n",
      " |          input the target and the estimated Q values and returns the loss for\n",
      " |          each element of the batch.\n",
      " |        gamma: A discount factor for future rewards.\n",
      " |        reward_scale_factor: Multiplicative scale for the reward.\n",
      " |        gradient_clipping: Norm length to clip gradients.\n",
      " |        debug_summaries: A bool to gather debug summaries.\n",
      " |        summarize_grads_and_vars: If True, gradient and network variable summaries\n",
      " |          will be written during training.\n",
      " |        train_step_counter: An optional counter to increment every time the train\n",
      " |          op is run.  Defaults to the global_step.\n",
      " |        training_data_spec: A nest of TensorSpec specifying the structure of data\n",
      " |          the train() function expects. If None, defaults to the trajectory_spec\n",
      " |          of the collect_policy.\n",
      " |        name: The name of this agent. All variables in this module will fall under\n",
      " |          that name. Defaults to the class name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `action_spec` contains more than one action or action\n",
      " |          spec minimum is not equal to 0.\n",
      " |        ValueError: If the q networks do not emit floating point outputs with\n",
      " |          inner shape matching `action_spec`.\n",
      " |        NotImplementedError: If `q_network` has non-empty `state_spec` (i.e., an\n",
      " |          RNN is provided) and `n_step_update > 1`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tf_agents.agents.tf_agent.TFAgent:\n",
      " |  \n",
      " |  initialize(self) -> Optional[tensorflow.python.framework.ops.Operation]\n",
      " |      Initializes the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An operation that can be used to initialize the agent.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  loss(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], weights: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, NoneType] = None, training: bool = False, **kwargs) -> tf_agents.agents.tf_agent.LossInfo\n",
      " |      Gets loss from the agent.\n",
      " |      \n",
      " |      If the user calls this from _train, it must be in a `tf.GradientTape` scope\n",
      " |      in order to apply gradients to trainable variables.\n",
      " |      If intermediate gradient steps are needed, _loss and _train will return\n",
      " |      different values since _loss only supports updating all gradients at once\n",
      " |      after all losses have been calculated.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: A batch of experience data in the form of a `Trajectory`. The\n",
      " |          structure of `experience` must match that of `self.training_data_spec`.\n",
      " |          All tensors in `experience` must be shaped `[batch, time, ...]` where\n",
      " |          `time` must be equal to `self.train_step_length` if that property is not\n",
      " |          `None`.\n",
      " |        weights: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`,\n",
      " |          containing weights to be used when calculating the total train loss.\n",
      " |          Weights are typically multiplied elementwise against the per-batch loss,\n",
      " |          but the implementation is up to the Agent.\n",
      " |        training: Explicit argument to pass to `loss`. This typically affects\n",
      " |          network computation paths like dropout and batch normalization.\n",
      " |        **kwargs: Any additional data as args to `loss`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `LossInfo` loss tuple containing loss and info tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  post_process_policy(self) -> tf_agents.policies.tf_policy.TFPolicy\n",
      " |      Post process policies after training.\n",
      " |      \n",
      " |      The policies of some agents require expensive post processing after training\n",
      " |      before they can be used. e.g. A Recommender agent might require rebuilding\n",
      " |      an index of actions. For such agents, this method will return a post\n",
      " |      processed version of the policy. The post processing may either update the\n",
      " |      existing policies in place or create a new policy, depnding on the agent.\n",
      " |      The default implementation for agents that do not want to override this\n",
      " |      method is to return agent.policy.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The post processed policy.\n",
      " |  \n",
      " |  preprocess_sequence(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]]) -> Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]]\n",
      " |      Defines preprocess_sequence function to be fed into replay buffers.\n",
      " |      \n",
      " |      This defines how we preprocess the collected data before training.\n",
      " |      Defaults to pass through for most agents.\n",
      " |      Structure of `experience` must match that of `self.collect_data_spec`.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: a `Trajectory` shaped [batch, time, ...] or [time, ...] which\n",
      " |          represents the collected experience data.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A post processed `Trajectory` with the same shape as the input.\n",
      " |  \n",
      " |  train(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], weights: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, NoneType] = None, **kwargs) -> tf_agents.agents.tf_agent.LossInfo\n",
      " |      Trains the agent.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: A batch of experience data in the form of a `Trajectory`. The\n",
      " |          structure of `experience` must match that of `self.training_data_spec`.\n",
      " |          All tensors in `experience` must be shaped `[batch, time, ...]` where\n",
      " |          `time` must be equal to `self.train_step_length` if that property is not\n",
      " |          `None`.\n",
      " |        weights: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`,\n",
      " |          containing weights to be used when calculating the total train loss.\n",
      " |          Weights are typically multiplied elementwise against the per-batch loss,\n",
      " |          but the implementation is up to the Agent.\n",
      " |        **kwargs: Any additional data to pass to the subclass.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `LossInfo` loss tuple containing loss and info tensors.\n",
      " |          - In eager mode, the loss values are first calculated, then a train step\n",
      " |            is performed before they are returned.\n",
      " |          - In graph mode, executing any or all of the loss tensors\n",
      " |            will first calculate the loss value(s), then perform a train step,\n",
      " |            and return the pre-train-step `LossInfo`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tf_agents.agents.tf_agent.TFAgent:\n",
      " |  \n",
      " |  action_spec\n",
      " |      TensorSpec describing the action produced by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An single BoundedTensorSpec, or a nested dict, list or tuple of\n",
      " |        `BoundedTensorSpec` objects, which describe the shape and\n",
      " |        dtype of each action Tensor.\n",
      " |  \n",
      " |  collect_data_context\n",
      " |  \n",
      " |  collect_data_spec\n",
      " |      Returns a `Trajectory` spec, as expected by the `collect_policy`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Trajectory` spec.\n",
      " |  \n",
      " |  collect_policy\n",
      " |      Return a policy that can be used to collect data from the environment.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf_policy.TFPolicy` object.\n",
      " |  \n",
      " |  data_context\n",
      " |  \n",
      " |  debug_summaries\n",
      " |  \n",
      " |  policy\n",
      " |      Return the current policy held by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf_policy.TFPolicy` object.\n",
      " |  \n",
      " |  summaries_enabled\n",
      " |  \n",
      " |  summarize_grads_and_vars\n",
      " |  \n",
      " |  time_step_spec\n",
      " |      Describes the `TimeStep` tensors expected by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `TimeStep` namedtuple with `TensorSpec` objects instead of Tensors,\n",
      " |        which describe the shape, dtype and name of each tensor.\n",
      " |  \n",
      " |  train_sequence_length\n",
      " |      The number of time steps needed in experience tensors passed to `train`.\n",
      " |      \n",
      " |      Train requires experience to be a `Trajectory` containing tensors shaped\n",
      " |      `[B, T, ...]`.  This argument describes the value of `T` required.\n",
      " |      \n",
      " |      For example, for non-RNN DQN training, `T=2` because DQN requires single\n",
      " |      transitions.\n",
      " |      \n",
      " |      If this value is `None`, then `train` can handle an unknown `T` (it can be\n",
      " |      determined at runtime from the data).  Most RNN-based agents fall into\n",
      " |      this category.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The number of time steps needed in experience tensors passed to `train`.\n",
      " |        May be `None` to mean no constraint.\n",
      " |  \n",
      " |  train_step_counter\n",
      " |  \n",
      " |  training_data_spec\n",
      " |      Returns a trajectory spec, as expected by the train() function.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from abc.ABCMeta\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  variables\n",
      " |      Sequence of variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.trackable.autotrackable.AutoTrackable:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DqnAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "loss = MeanSquaredError('none', 'mean_squared_error')\n",
    "loss_fn = loss.call\n",
    "discount_factor = 0.95\n",
    "epsilon_fn = PolynomialDecay(\n",
    "    initial_learning_rate=1.0,\n",
    "    decay_steps=1000,\n",
    "    end_learning_rate=0.01,\n",
    "    power=1\n",
    "    )\n",
    "target_model_update = 50\n",
    "train_step = tf.Variable(0)\n",
    "\n",
    "agent = DqnAgent(\n",
    "    env.time_step_spec(),\n",
    "    env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    gamma=discount_factor,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    epsilon_greedy=lambda:epsilon_fn(train_step),\n",
    "    train_step_counter=train_step,\n",
    "    target_update_period=target_model_update,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Replay Buffer to store experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.replay_buffers.tf_uniform_replay_buffer import TFUniformReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32)),\n",
       " 'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = TFUniformReplayBuffer(\n",
    "    data_spec= agent.collect_data_spec,\n",
    "    batch_size= env.batch_size,\n",
    "    max_length= 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an observer to write into the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer_observer = replay_buffer.add_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer at 0x1facf5c6c10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ReplayBuffer.add_batch of <tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer object at 0x000001FACF5C6C10>>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer_observer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Driver that explores environment using a given policy, collects experience and broadcast them to observer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver\n",
    "from tf_agents.metrics import tf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = [\n",
    "    tf_metrics.AverageReturnMetric()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_driver = DynamicStepDriver(\n",
    "    env=env,\n",
    "    policy= agent.collect_policy,\n",
    "    observers= [replay_buffer_observer] + train_metrics,\n",
    "    num_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metrics[0].result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a driver to just fill the replay buffer with some experiences with a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_collect_policy = RandomTFPolicy(env.time_step_spec(), env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.random_tf_policy.RandomTFPolicy at 0x1facf78f450>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_driver = DynamicStepDriver(\n",
    "    env,\n",
    "    initial_collect_policy,\n",
    "    [replay_buffer_observer],\n",
    "    num_steps=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time_step, final_policy_state = initial_driver.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.02465292, -1.0258754 ,  0.11786823,  1.5893848 ]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_policy_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset of sample a batch of trajectories for agent to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.trajectories.trajectory import to_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iitka\\AppData\\Local\\Temp\\ipykernel_6428\\3194907317.py:1: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "trajectories, buffer_info = replay_buffer.get_next(sample_batch_size=2, num_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 2],\n",
       "       [1, 1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[-0.07259054, -0.6232152 ,  0.170022  ,  1.1400421 ],\n",
       "        [-0.08505484, -0.4306737 ,  0.19282284,  0.9051402 ],\n",
       "        [-0.09366832, -0.23861197,  0.21092565,  0.678726  ]],\n",
       "\n",
       "       [[-0.01045731,  1.1301863 , -0.09057271, -1.8127806 ],\n",
       "        [ 0.01214642,  1.3261927 , -0.12682833, -2.132177  ],\n",
       "        [ 0.03867028,  1.5223236 , -0.16947187, -2.461198  ]]],\n",
       "      dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "array([[1, 1, 0],\n",
       "       [1, 1, 0]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 0],\n",
       "       [1, 1, 2]])>,\n",
       " 'reward': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 0.],\n",
       "       [1., 1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 1.],\n",
       "       [1., 1., 0.]], dtype=float32)>})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BufferInfo(ids=<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "array([[255, 256, 257],\n",
       "       [ 43,  44,  45]], dtype=int64)>, probabilities=<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00095785, 0.00095785], dtype=float32)>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps, action_steps, next_time_steps = to_transition(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(2, 2, 4), dtype=float32, numpy=\n",
       "array([[[-0.07259054, -0.6232152 ,  0.170022  ,  1.1400421 ],\n",
       "        [-0.08505484, -0.4306737 ,  0.19282284,  0.9051402 ]],\n",
       "\n",
       "       [[-0.01045731,  1.1301863 , -0.09057271, -1.8127806 ],\n",
       "        [ 0.01214642,  1.3261927 , -0.12682833, -2.132177  ]]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=<tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1]], dtype=int64)>, state=(), info=())"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=64,\n",
    "    num_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(Trajectory(\n",
       "{'step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
       " 'observation': TensorSpec(shape=(64, 2, 4), dtype=tf.float32, name=None),\n",
       " 'action': TensorSpec(shape=(64, 2), dtype=tf.int64, name=None),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
       " 'reward': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None),\n",
       " 'discount': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None)}), BufferInfo(ids=TensorSpec(shape=(64, 2), dtype=tf.int64, name=None), probabilities=TensorSpec(shape=(64,), dtype=tf.float32, name=None)))>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x1facd286a90>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1]])>,\n",
       "  'observation': <tf.Tensor: shape=(64, 2, 4), dtype=float32, numpy=\n",
       " array([[[ 3.83128077e-02, -4.40143272e-02,  3.03888563e-02,\n",
       "          -2.03284714e-02],\n",
       "         [ 3.74325179e-02, -2.39558607e-01,  2.99822874e-02,\n",
       "           2.81785488e-01]],\n",
       " \n",
       "        [[ 1.24287158e-01,  6.26830161e-01, -1.13357909e-01,\n",
       "          -9.69187915e-01],\n",
       "         [ 1.36823758e-01,  8.23276341e-01, -1.32741660e-01,\n",
       "          -1.29522192e+00]],\n",
       " \n",
       "        [[-4.65629101e-02, -8.18635404e-01,  1.01123020e-01,\n",
       "           1.25034249e+00],\n",
       "         [-6.29356205e-02, -1.01489747e+00,  1.26129866e-01,\n",
       "           1.57291114e+00]],\n",
       " \n",
       "        [[-1.16551623e-01, -6.11117601e-01,  1.89793408e-01,\n",
       "           1.21137238e+00],\n",
       "         [-1.28773972e-01, -8.08113515e-01,  2.14020863e-01,\n",
       "           1.55702496e+00]],\n",
       " \n",
       "        [[ 6.37940764e-02, -3.59869689e-01, -9.68482047e-02,\n",
       "           3.92172873e-01],\n",
       "         [ 5.65966815e-02, -1.63516313e-01, -8.90047476e-02,\n",
       "           7.05941170e-02]],\n",
       " \n",
       "        [[-3.49511318e-02, -4.45900448e-02,  3.51301581e-02,\n",
       "          -3.26875411e-02],\n",
       "         [-3.58429290e-02,  1.50010973e-01,  3.44764069e-02,\n",
       "          -3.14082831e-01]],\n",
       " \n",
       "        [[-5.08969128e-02,  1.45397499e-01, -1.33051677e-02,\n",
       "          -2.86088169e-01],\n",
       "         [-4.79889624e-02, -4.95321900e-02, -1.90269314e-02,\n",
       "           2.36887578e-03]],\n",
       " \n",
       "        [[ 9.38850194e-02,  1.65734366e-02, -1.18398324e-01,\n",
       "          -1.94947243e-01],\n",
       "         [ 9.42164883e-02,  2.13172480e-01, -1.22297272e-01,\n",
       "          -5.22509098e-01]],\n",
       " \n",
       "        [[-5.68613298e-02,  1.40515659e-02,  7.21810535e-02,\n",
       "           1.39063805e-01],\n",
       "         [-5.65802976e-02,  2.08069444e-01,  7.49623328e-02,\n",
       "          -1.30002394e-01]],\n",
       " \n",
       "        [[ 8.57630223e-02,  5.73936403e-01, -1.61624774e-01,\n",
       "          -9.99387324e-01],\n",
       "         [ 9.72417518e-02,  7.70806313e-01, -1.81612521e-01,\n",
       "          -1.33815455e+00]],\n",
       " \n",
       "        [[-4.01070192e-02,  1.15177687e-02,  6.16200827e-03,\n",
       "           3.10310926e-02],\n",
       "         [-3.98766659e-02, -1.83692008e-01,  6.78262999e-03,\n",
       "           3.25651824e-01]],\n",
       " \n",
       "        [[-6.48340136e-02, -1.00952923e+00,  5.62444888e-02,\n",
       "           1.45482862e+00],\n",
       "         [-8.50246027e-02, -1.20529473e+00,  8.53410661e-02,\n",
       "           1.76453972e+00]],\n",
       " \n",
       "        [[ 9.90769193e-02, -1.55451387e-01, -2.83936448e-02,\n",
       "           4.09536242e-01],\n",
       "         [ 9.59678888e-02, -3.50159496e-01, -2.02029198e-02,\n",
       "           6.93134129e-01]],\n",
       " \n",
       "        [[-1.51723875e-02,  1.84447452e-01,  1.07300773e-01,\n",
       "           1.53173611e-01],\n",
       "         [-1.14834383e-02,  3.77882451e-01,  1.10364243e-01,\n",
       "          -1.03824243e-01]],\n",
       " \n",
       "        [[ 6.70681074e-02,  2.31738538e-01, -1.21686310e-01,\n",
       "          -6.29827380e-01],\n",
       "         [ 7.17028752e-02,  4.28329557e-01, -1.34282857e-01,\n",
       "          -9.58220840e-01]],\n",
       " \n",
       "        [[ 1.92313954e-01,  2.15539128e-01,  3.42468694e-02,\n",
       "           2.48760849e-01],\n",
       "         [ 1.96624741e-01,  4.10155684e-01,  3.92220840e-02,\n",
       "          -3.29261944e-02]],\n",
       " \n",
       "        [[-9.95475724e-02, -7.62420654e-01,  2.08371744e-01,\n",
       "           1.45746946e+00],\n",
       "         [-1.14795983e-01, -9.59399700e-01,  2.37521127e-01,\n",
       "           1.80736566e+00]],\n",
       " \n",
       "        [[ 1.59357972e-02, -1.98768169e-01, -1.30446762e-01,\n",
       "          -6.47958145e-02],\n",
       "         [ 1.19604338e-02, -2.04065768e-03, -1.31742686e-01,\n",
       "          -3.95622611e-01]],\n",
       " \n",
       "        [[-2.17043739e-02, -1.96733817e-01, -2.33084057e-03,\n",
       "           2.57805943e-01],\n",
       "         [-2.56390516e-02, -3.91822398e-01,  2.82527809e-03,\n",
       "           5.49752772e-01]],\n",
       " \n",
       "        [[ 3.64848934e-02,  1.83734849e-01, -1.40510956e-02,\n",
       "          -2.78513938e-01],\n",
       "         [ 4.01595905e-02, -1.11838579e-02, -1.96213741e-02,\n",
       "           9.70437191e-03]],\n",
       " \n",
       "        [[ 2.21591108e-02, -1.64872959e-01, -8.66640243e-04,\n",
       "           2.83222169e-01],\n",
       "         [ 1.88616514e-02, -3.59982550e-01,  4.79780277e-03,\n",
       "           5.75631618e-01]],\n",
       " \n",
       "        [[ 1.07100658e-01,  4.22415286e-01, -5.57839610e-02,\n",
       "          -6.29728138e-01],\n",
       "         [ 1.15548961e-01,  2.28114307e-01, -6.83785230e-02,\n",
       "          -3.55122030e-01]],\n",
       " \n",
       "        [[ 8.04026574e-02,  4.15943742e-01, -3.90704609e-02,\n",
       "          -5.58728874e-01],\n",
       "         [ 8.87215286e-02,  2.21391380e-01, -5.02450392e-02,\n",
       "          -2.78606832e-01]],\n",
       " \n",
       "        [[ 4.19286229e-02,  2.41772801e-01, -4.87241633e-02,\n",
       "          -2.64222860e-01],\n",
       "         [ 4.67640758e-02,  4.37555104e-01, -5.40086180e-02,\n",
       "          -5.71867049e-01]],\n",
       " \n",
       "        [[ 6.91167489e-02,  1.32899153e+00, -2.18695834e-01,\n",
       "          -2.22494102e+00],\n",
       "         [ 3.31629813e-02, -4.06807400e-02,  3.29715088e-02,\n",
       "          -1.10893873e-02]],\n",
       " \n",
       "        [[-2.56390516e-02, -3.91822398e-01,  2.82527809e-03,\n",
       "           5.49752772e-01],\n",
       "         [-3.34754996e-02, -5.86983919e-01,  1.38203334e-02,\n",
       "           8.43324542e-01]],\n",
       " \n",
       "        [[-2.99812984e-02,  4.68562469e-02, -9.97573230e-03,\n",
       "          -7.66121875e-03],\n",
       "         [-2.90441737e-02,  2.42119834e-01, -1.01289572e-02,\n",
       "          -3.03474844e-01]],\n",
       " \n",
       "        [[-2.47047283e-02,  4.19492692e-01,  1.27807716e-02,\n",
       "          -5.52120805e-01],\n",
       "         [-1.63148735e-02,  6.14432812e-01,  1.73835561e-03,\n",
       "          -8.40749681e-01]],\n",
       " \n",
       "        [[-5.25500625e-02, -8.17858398e-01,  1.30826995e-01,\n",
       "           1.30759716e+00],\n",
       "         [-6.89072311e-02, -1.01437294e+00,  1.56978950e-01,\n",
       "           1.63820350e+00]],\n",
       " \n",
       "        [[ 3.13097984e-02, -2.28935733e-01, -3.92212858e-03,\n",
       "           2.71723092e-01],\n",
       "         [ 2.67310832e-02, -3.37580331e-02,  1.51233352e-03,\n",
       "          -2.21942961e-02]],\n",
       " \n",
       "        [[ 9.41439718e-02,  4.21207637e-01, -3.72937955e-02,\n",
       "          -6.02607548e-01],\n",
       "         [ 1.02568120e-01,  2.26626620e-01, -4.93459441e-02,\n",
       "          -3.21900815e-01]],\n",
       " \n",
       "        [[ 2.05065068e-02, -3.19507793e-02,  2.23139543e-02,\n",
       "           8.19287356e-03],\n",
       "         [ 1.98674910e-02,  1.62844166e-01,  2.24778131e-02,\n",
       "          -2.77367055e-01]],\n",
       " \n",
       "        [[-5.24189100e-02,  4.02041972e-01,  7.23622814e-02,\n",
       "          -3.98125798e-01],\n",
       "         [-4.43780720e-02,  2.05972046e-01,  6.43997639e-02,\n",
       "          -8.35346058e-02]],\n",
       " \n",
       "        [[ 1.56870484e-01,  1.73269022e+00, -2.26040050e-01,\n",
       "          -2.61082697e+00],\n",
       "         [ 2.18149405e-02,  3.02524213e-02, -5.13644330e-03,\n",
       "          -9.53720137e-03]],\n",
       " \n",
       "        [[-3.88305858e-02, -2.08763912e-01,  4.97010425e-02,\n",
       "           3.40055257e-01],\n",
       "         [-4.30058613e-02, -1.43830720e-02,  5.65021485e-02,\n",
       "           6.34501278e-02]],\n",
       " \n",
       "        [[ 4.72921543e-02,  6.27621055e-01, -7.05570281e-02,\n",
       "          -9.23888028e-01],\n",
       "         [ 5.98445758e-02,  8.23621571e-01, -8.90347883e-02,\n",
       "          -1.23788381e+00]],\n",
       " \n",
       "        [[ 2.38665398e-02,  2.09084433e-02, -3.30104381e-02,\n",
       "           1.35684032e-02],\n",
       "         [ 2.42847074e-02,  2.16487870e-01, -3.27390730e-02,\n",
       "          -2.89344221e-01]],\n",
       " \n",
       "        [[-4.74422798e-02, -4.30369198e-01, -1.03450771e-02,\n",
       "           5.24356246e-01],\n",
       "         [-5.60496673e-02, -6.25344038e-01,  1.42047560e-04,\n",
       "           8.13761473e-01]],\n",
       " \n",
       "        [[-2.04360280e-02, -4.66155522e-02, -3.75113934e-02,\n",
       "           5.04238205e-03],\n",
       "         [-2.13683397e-02,  1.49023727e-01, -3.74105461e-02,\n",
       "          -2.99235851e-01]],\n",
       " \n",
       "        [[ 4.97232890e-03,  2.35998541e-01, -1.03484774e-02,\n",
       "          -3.06369692e-01],\n",
       "         [ 9.69230011e-03,  4.31266427e-01, -1.64758712e-02,\n",
       "          -6.02298200e-01]],\n",
       " \n",
       "        [[-4.09846492e-02, -1.98081434e-02,  2.73826029e-02,\n",
       "          -3.44001292e-03],\n",
       "         [-4.13808115e-02, -2.15311885e-01,  2.73138043e-02,\n",
       "           2.97755152e-01]],\n",
       " \n",
       "        [[ 8.16116184e-02,  4.03677523e-01, -9.51225013e-02,\n",
       "          -7.12540805e-01],\n",
       "         [ 8.96851718e-02,  2.09992349e-01, -1.09373324e-01,\n",
       "          -4.51250315e-01]],\n",
       " \n",
       "        [[ 6.83111995e-02,  3.77178133e-01, -5.24751358e-02,\n",
       "          -6.21705949e-01],\n",
       "         [ 7.58547634e-02,  5.72992086e-01, -6.49092570e-02,\n",
       "          -9.30443168e-01]],\n",
       " \n",
       "        [[-4.70450744e-02,  5.56646705e-01,  4.65643294e-02,\n",
       "          -6.85921609e-01],\n",
       "         [-3.59121412e-02,  7.51092374e-01,  3.28458995e-02,\n",
       "          -9.63588953e-01]],\n",
       " \n",
       "        [[-3.05535085e-02,  1.00098168e-02,  1.49431091e-03,\n",
       "           6.42939284e-02],\n",
       "         [-3.03533114e-02,  2.05110312e-01,  2.78018950e-03,\n",
       "          -2.27917150e-01]],\n",
       " \n",
       "        [[ 7.40280002e-03,  2.01839089e-01,  1.89345144e-02,\n",
       "           7.80500192e-03],\n",
       "         [ 1.14395814e-02,  3.96684438e-01,  1.90906152e-02,\n",
       "          -2.78844237e-01]],\n",
       " \n",
       "        [[-2.07618456e-02, -3.79813462e-01,  6.00388683e-02,\n",
       "           6.77668214e-01],\n",
       "         [-2.83581149e-02, -5.75715899e-01,  7.35922307e-02,\n",
       "           9.88633275e-01]],\n",
       " \n",
       "        [[ 8.58694389e-02, -3.49794626e-01,  1.54296635e-03,\n",
       "           6.84837401e-01],\n",
       "         [ 7.88735449e-02, -1.54694125e-01,  1.52397146e-02,\n",
       "           3.92640650e-01]],\n",
       " \n",
       "        [[ 6.65740222e-02,  2.73059756e-02, -9.69348103e-02,\n",
       "          -1.28133044e-01],\n",
       "         [ 6.71201423e-02, -1.66303337e-01, -9.94974747e-02,\n",
       "           1.32463351e-01]],\n",
       " \n",
       "        [[-9.19583347e-03,  4.11307551e-02,  8.21598526e-03,\n",
       "          -1.92870274e-02],\n",
       "         [-8.37321766e-03,  2.36133918e-01,  7.83024542e-03,\n",
       "          -3.09366435e-01]],\n",
       " \n",
       "        [[ 3.68556865e-02,  2.17498973e-01, -5.03693633e-02,\n",
       "          -3.11867625e-01],\n",
       "         [ 4.12056670e-02,  4.13300991e-01, -5.66067137e-02,\n",
       "          -6.20000482e-01]],\n",
       " \n",
       "        [[-4.90321815e-02, -5.81391275e-01,  3.57254483e-02,\n",
       "           7.99593389e-01],\n",
       "         [-6.06600083e-02, -3.86777133e-01,  5.17173149e-02,\n",
       "           5.18359482e-01]],\n",
       " \n",
       "        [[-7.91584104e-02, -5.94231963e-01,  2.34004378e-01,\n",
       "           1.23212016e+00],\n",
       "         [ 3.28308977e-02,  4.51970398e-02,  1.31308027e-02,\n",
       "          -5.23705129e-03]],\n",
       " \n",
       "        [[-2.17043739e-02, -1.96733817e-01, -2.33084057e-03,\n",
       "           2.57805943e-01],\n",
       "         [-2.56390516e-02, -3.91822398e-01,  2.82527809e-03,\n",
       "           5.49752772e-01]],\n",
       " \n",
       "        [[-1.18282540e-02, -2.67753303e-02,  4.01721187e-02,\n",
       "          -3.91453579e-02],\n",
       "         [-1.23637607e-02,  1.67748213e-01,  3.93892117e-02,\n",
       "          -3.18887830e-01]],\n",
       " \n",
       "        [[-1.50867239e-01, -4.03071523e-01,  1.99100912e-01,\n",
       "           8.93393874e-01],\n",
       "         [-1.58928663e-01, -6.00255549e-01,  2.16968790e-01,\n",
       "           1.24147654e+00]],\n",
       " \n",
       "        [[ 1.52881239e-02, -7.15222023e-03,  3.62600796e-02,\n",
       "           8.76867324e-02],\n",
       "         [ 1.51450792e-02, -2.02774659e-01,  3.80138122e-02,\n",
       "           3.91585618e-01]],\n",
       " \n",
       "        [[-8.50246027e-02, -1.20529473e+00,  8.53410661e-02,\n",
       "           1.76453972e+00],\n",
       "         [-1.09130494e-01, -1.01123500e+00,  1.20631859e-01,\n",
       "           1.49956942e+00]],\n",
       " \n",
       "        [[ 5.38519546e-02,  4.15045649e-01, -7.59201124e-02,\n",
       "          -6.59289777e-01],\n",
       "         [ 6.21528663e-02,  2.21057802e-01, -8.91059041e-02,\n",
       "          -3.91445309e-01]],\n",
       " \n",
       "        [[-2.72320714e-02,  2.03556120e-01,  2.51616333e-02,\n",
       "          -1.93702057e-01],\n",
       "         [-2.31609493e-02,  3.98309261e-01,  2.12875921e-02,\n",
       "          -4.78342563e-01]],\n",
       " \n",
       "        [[-3.88305858e-02, -2.08763912e-01,  4.97010425e-02,\n",
       "           3.40055257e-01],\n",
       "         [-4.30058613e-02, -1.43830720e-02,  5.65021485e-02,\n",
       "           6.34501278e-02]],\n",
       " \n",
       "        [[ 6.37246072e-02,  4.22022194e-01,  8.62883255e-02,\n",
       "          -2.95844078e-01],\n",
       "         [ 7.21650496e-02,  6.15814805e-01,  8.03714469e-02,\n",
       "          -5.60114205e-01]],\n",
       " \n",
       "        [[ 3.93758304e-02, -1.47150187e-02, -4.20092745e-03,\n",
       "           7.08575419e-04],\n",
       "         [ 3.90815288e-02,  1.80466920e-01, -4.18675598e-03,\n",
       "          -2.93296844e-01]],\n",
       " \n",
       "        [[ 6.81830049e-02,  8.29338133e-01, -8.30672309e-02,\n",
       "          -1.19358230e+00],\n",
       "         [ 8.47697631e-02,  6.35384440e-01, -1.06938876e-01,\n",
       "          -9.28048491e-01]]], dtype=float32)>,\n",
       "  'action': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1]], dtype=int64)>,\n",
       "  'policy_info': (),\n",
       "  'next_step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]])>,\n",
       "  'reward': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)>,\n",
       "  'discount': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)>}),\n",
       " BufferInfo(ids=<tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[1037, 1038],\n",
       "        [ 901,  902],\n",
       "        [ 620,  621],\n",
       "        [ 192,  193],\n",
       "        [ 383,  384],\n",
       "        [ 864,  865],\n",
       "        [ 508,  509],\n",
       "        [ 130,  131],\n",
       "        [ 268,  269],\n",
       "        [ 457,  458],\n",
       "        [ 803,  804],\n",
       "        [ 216,  217],\n",
       "        [ 737,  738],\n",
       "        [ 108,  109],\n",
       "        [ 388,  389],\n",
       "        [ 767,  768],\n",
       "        [ 671,  672],\n",
       "        [ 948,  949],\n",
       "        [ 152,  153],\n",
       "        [ 138,  139],\n",
       "        [ 658,  659],\n",
       "        [ 475,  476],\n",
       "        [1008, 1009],\n",
       "        [ 694,  695],\n",
       "        [  46,   47],\n",
       "        [ 153,  154],\n",
       "        [ 564,  565],\n",
       "        [ 170,  171],\n",
       "        [ 403,  404],\n",
       "        [ 609,  610],\n",
       "        [ 473,  474],\n",
       "        [ 393,  394],\n",
       "        [ 270,  271],\n",
       "        [ 650,  651],\n",
       "        [ 182,  183],\n",
       "        [ 536,  537],\n",
       "        [ 373,  374],\n",
       "        [  31,   32],\n",
       "        [ 580,  581],\n",
       "        [ 532,  533],\n",
       "        [ 625,  626],\n",
       "        [ 128,  129],\n",
       "        [ 296,  297],\n",
       "        [ 638,  639],\n",
       "        [ 811,  812],\n",
       "        [ 277,  278],\n",
       "        [ 319,  320],\n",
       "        [ 740,  741],\n",
       "        [ 381,  382],\n",
       "        [ 529,  530],\n",
       "        [ 376,  377],\n",
       "        [ 922,  923],\n",
       "        [ 717,  718],\n",
       "        [ 152,  153],\n",
       "        [ 673,  674],\n",
       "        [ 933,  934],\n",
       "        [ 343,  344],\n",
       "        [ 217,  218],\n",
       "        [ 379,  380],\n",
       "        [ 828,  829],\n",
       "        [ 182,  183],\n",
       "        [ 752,  753],\n",
       "        [ 288,  289],\n",
       "        [ 697,  698]], dtype=int64)>, probabilities=<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       " array([0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694, 0.00095694,\n",
       "        0.00095694, 0.00095694, 0.00095694, 0.00095694], dtype=float32)>))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(64, 2, 4), dtype=float32, numpy=\n",
       "array([[[-1.92200206e-02,  3.93400460e-01, -8.67544115e-02,\n",
       "         -7.29528666e-01],\n",
       "        [-1.13520119e-02,  5.89607596e-01, -1.01344980e-01,\n",
       "         -1.04820633e+00]],\n",
       "\n",
       "       [[ 2.12908424e-02, -3.79366070e-01, -1.64109115e-02,\n",
       "          5.55116475e-01],\n",
       "        [ 1.37035204e-02, -1.84017584e-01, -5.30858198e-03,\n",
       "          2.57308602e-01]],\n",
       "\n",
       "       [[-3.08644678e-02,  2.30675191e-01,  2.38763355e-02,\n",
       "         -2.60363013e-01],\n",
       "        [-2.62509640e-02,  3.52206752e-02,  1.86690744e-02,\n",
       "          3.97541560e-02]],\n",
       "\n",
       "       [[-3.58429290e-02,  1.50010973e-01,  3.44764069e-02,\n",
       "         -3.14082831e-01],\n",
       "        [-3.28427106e-02, -4.55847047e-02,  2.81947516e-02,\n",
       "         -1.07295988e-02]],\n",
       "\n",
       "       [[-4.90321815e-02, -5.81391275e-01,  3.57254483e-02,\n",
       "          7.99593389e-01],\n",
       "        [-6.06600083e-02, -3.86777133e-01,  5.17173149e-02,\n",
       "          5.18359482e-01]],\n",
       "\n",
       "       [[ 2.43156943e-02, -3.93552005e-01,  1.44182285e-02,\n",
       "          5.88224649e-01],\n",
       "        [ 1.64446533e-02, -1.98634908e-01,  2.61827204e-02,\n",
       "          3.00118208e-01]],\n",
       "\n",
       "       [[-1.30025828e-02, -1.65058926e-01,  3.79612707e-02,\n",
       "          2.94563115e-01],\n",
       "        [-1.63037609e-02, -3.60700935e-01,  4.38525341e-02,\n",
       "          5.98972678e-01]],\n",
       "\n",
       "       [[ 4.08354253e-01, -5.80215812e-01,  1.95854142e-01,\n",
       "          1.78452086e+00],\n",
       "        [ 3.96749943e-01, -3.87760103e-01,  2.31544554e-01,\n",
       "          1.55857015e+00]],\n",
       "\n",
       "       [[ 8.65330249e-02, -1.12817427e-02, -3.06197237e-02,\n",
       "          1.78815946e-01],\n",
       "        [ 8.63073915e-02,  1.84264705e-01, -2.70434059e-02,\n",
       "         -1.23367019e-01]],\n",
       "\n",
       "       [[-7.90915340e-02, -4.00878601e-02,  1.44516110e-01,\n",
       "          2.57085323e-01],\n",
       "        [-7.98932910e-02, -2.36945614e-01,  1.49657816e-01,\n",
       "          5.91633797e-01]],\n",
       "\n",
       "       [[ 4.08354253e-01, -5.80215812e-01,  1.95854142e-01,\n",
       "          1.78452086e+00],\n",
       "        [ 3.96749943e-01, -3.87760103e-01,  2.31544554e-01,\n",
       "          1.55857015e+00]],\n",
       "\n",
       "       [[-5.09361317e-03, -1.24226799e-02, -2.43308805e-02,\n",
       "          5.17781638e-03],\n",
       "        [-5.34206675e-03,  1.83039606e-01, -2.42273230e-02,\n",
       "         -2.95081407e-01]],\n",
       "\n",
       "       [[-4.19220068e-02, -4.05479670e-02, -1.40393106e-02,\n",
       "         -5.17544523e-02],\n",
       "        [-4.27329652e-02, -2.35465825e-01, -1.50743993e-02,\n",
       "          2.36466095e-01]],\n",
       "\n",
       "       [[ 4.94716838e-02,  2.19013408e-01, -6.90067261e-02,\n",
       "         -3.45669389e-01],\n",
       "        [ 5.38519546e-02,  4.15045649e-01, -7.59201124e-02,\n",
       "         -6.59289777e-01]],\n",
       "\n",
       "       [[-1.23082779e-01,  2.53218859e-02,  1.96891636e-01,\n",
       "          3.31538230e-01],\n",
       "        [-1.22576341e-01,  2.17176303e-01,  2.03522399e-01,\n",
       "          1.06829576e-01]],\n",
       "\n",
       "       [[-1.22576341e-01,  2.17176303e-01,  2.03522399e-01,\n",
       "          1.06829576e-01],\n",
       "        [-1.18232809e-01,  1.98077057e-02,  2.05659002e-01,\n",
       "          4.56195503e-01]],\n",
       "\n",
       "       [[-5.35012111e-02, -6.20052636e-01,  9.89251286e-02,\n",
       "          1.01751804e+00],\n",
       "        [-6.59022629e-02, -4.26378638e-01,  1.19275488e-01,\n",
       "          7.57463992e-01]],\n",
       "\n",
       "       [[-8.71898141e-03,  5.65953255e-01, -6.04626536e-02,\n",
       "         -8.88464034e-01],\n",
       "        [ 2.60008313e-03,  3.71701658e-01, -7.82319382e-02,\n",
       "         -6.15384281e-01]],\n",
       "\n",
       "       [[-5.40142506e-02, -3.65426630e-01,  1.15479454e-02,\n",
       "          4.18888092e-01],\n",
       "        [-6.13227822e-02, -5.60710311e-01,  1.99257080e-02,\n",
       "          7.15189099e-01]],\n",
       "\n",
       "       [[ 1.79135166e-02, -4.23316777e-01,  2.37827860e-02,\n",
       "          6.18407905e-01],\n",
       "        [ 9.44718160e-03, -2.28534982e-01,  3.61509435e-02,\n",
       "          3.33309263e-01]],\n",
       "\n",
       "       [[ 3.67167145e-02, -1.15909623e-02, -1.44247962e-02,\n",
       "          1.86850391e-02],\n",
       "        [ 3.64848934e-02,  1.83734849e-01, -1.40510956e-02,\n",
       "         -2.78513938e-01]],\n",
       "\n",
       "       [[-5.09361317e-03, -1.24226799e-02, -2.43308805e-02,\n",
       "          5.17781638e-03],\n",
       "        [-5.34206675e-03,  1.83039606e-01, -2.42273230e-02,\n",
       "         -2.95081407e-01]],\n",
       "\n",
       "       [[ 6.81830049e-02,  8.29338133e-01, -8.30672309e-02,\n",
       "         -1.19358230e+00],\n",
       "        [ 8.47697631e-02,  6.35384440e-01, -1.06938876e-01,\n",
       "         -9.28048491e-01]],\n",
       "\n",
       "       [[ 1.15414143e-01,  7.91298568e-01, -2.11734533e-01,\n",
       "         -1.56621289e+00],\n",
       "        [ 6.27633464e-03, -3.54846083e-02, -4.23625968e-02,\n",
       "          2.46356819e-02]],\n",
       "\n",
       "       [[ 3.73072959e-02,  3.71144325e-01, -3.93915810e-02,\n",
       "         -6.11593604e-01],\n",
       "        [ 4.47301827e-02,  1.76594421e-01, -5.16234562e-02,\n",
       "         -3.31573278e-01]],\n",
       "\n",
       "       [[ 8.05310439e-03, -1.91105962e-01, -1.52208909e-01,\n",
       "         -2.35923544e-01],\n",
       "        [ 4.23098542e-03,  5.82583249e-03, -1.56927377e-01,\n",
       "         -5.72482824e-01]],\n",
       "\n",
       "       [[ 8.90289471e-02,  3.00970227e-02, -3.13329063e-02,\n",
       "          2.17872229e-03],\n",
       "        [ 8.96308944e-02,  2.25653991e-01, -3.12893316e-02,\n",
       "         -3.00223112e-01]],\n",
       "\n",
       "       [[ 8.83674901e-03,  2.03190580e-01, -1.42037887e-02,\n",
       "         -1.85583636e-01],\n",
       "        [ 1.29005602e-02,  3.98512840e-01, -1.79154612e-02,\n",
       "         -4.82713252e-01]],\n",
       "\n",
       "       [[-4.25387658e-02,  1.92047179e-01, -4.35655564e-02,\n",
       "         -2.97300905e-01],\n",
       "        [-3.86978239e-02,  3.87762219e-01, -4.95115742e-02,\n",
       "         -6.03399098e-01]],\n",
       "\n",
       "       [[ 2.65512288e-01,  2.11425975e-01,  2.23669596e-02,\n",
       "          3.39425534e-01],\n",
       "        [ 2.69740820e-01,  4.06222641e-01,  2.91554704e-02,\n",
       "          5.38789444e-02]],\n",
       "\n",
       "       [[-8.11670814e-03,  4.03769046e-01,  2.48720050e-02,\n",
       "         -5.62560201e-01],\n",
       "        [-4.13276284e-05,  2.08307073e-01,  1.36208013e-02,\n",
       "         -2.62146294e-01]],\n",
       "\n",
       "       [[-2.36852225e-02, -1.86118603e-01,  1.57469194e-02,\n",
       "          3.79206181e-01],\n",
       "        [-2.74075959e-02,  8.77621770e-03,  2.33310424e-02,\n",
       "          9.15295854e-02]],\n",
       "\n",
       "       [[ 4.67640758e-02,  4.37555104e-01, -5.40086180e-02,\n",
       "         -5.71867049e-01],\n",
       "        [ 5.55151813e-02,  6.33391142e-01, -6.54459596e-02,\n",
       "         -8.81063581e-01]],\n",
       "\n",
       "       [[ 7.13414093e-03, -3.47183675e-01, -2.63008587e-02,\n",
       "          5.19808054e-01],\n",
       "        [ 1.90467239e-04, -5.41925669e-01, -1.59046985e-02,\n",
       "          8.04088473e-01]],\n",
       "\n",
       "       [[ 1.40725687e-01,  6.41665161e-01, -2.25853920e-01,\n",
       "         -1.26062179e+00],\n",
       "        [-8.48292187e-03, -1.29621690e-02, -1.90415047e-02,\n",
       "          1.70803331e-02]],\n",
       "\n",
       "       [[-1.20247886e-01, -1.60943568e+00,  2.48970121e-01,\n",
       "          2.60602236e+00],\n",
       "        [ 2.47771647e-02,  1.02457013e-02, -2.14697793e-02,\n",
       "         -1.64444968e-02]],\n",
       "\n",
       "       [[-2.79609393e-02,  2.04583183e-01,  1.84314400e-02,\n",
       "         -2.16332808e-01],\n",
       "        [-2.38692760e-02,  9.20266192e-03,  1.41047835e-02,\n",
       "          8.21067467e-02]],\n",
       "\n",
       "       [[ 2.86144651e-02,  4.12061006e-01, -3.85259576e-02,\n",
       "         -5.92170298e-01],\n",
       "        [ 3.68556865e-02,  2.17498973e-01, -5.03693633e-02,\n",
       "         -3.11867625e-01]],\n",
       "\n",
       "       [[-4.04693075e-02, -2.27733046e-01,  7.72712827e-02,\n",
       "          3.83340508e-01],\n",
       "        [-4.50239666e-02, -4.23862189e-01,  8.49380940e-02,\n",
       "          6.99351549e-01]],\n",
       "\n",
       "       [[-1.21554332e-02,  2.15078607e-01, -3.28816883e-02,\n",
       "         -3.52107525e-01],\n",
       "        [-7.85386097e-03,  2.04392988e-02, -3.99238393e-02,\n",
       "         -6.99718595e-02]],\n",
       "\n",
       "       [[-2.63205916e-02, -1.91906780e-01,  7.05194175e-02,\n",
       "          4.32276487e-01],\n",
       "        [-3.01587265e-02, -3.87952656e-01,  7.91649446e-02,\n",
       "          7.46329963e-01]],\n",
       "\n",
       "       [[ 7.64642730e-02,  1.14383876e+00, -1.09759554e-01,\n",
       "         -1.61044371e+00],\n",
       "        [ 9.93410498e-02,  1.34007275e+00, -1.41968429e-01,\n",
       "         -1.93522811e+00]],\n",
       "\n",
       "       [[-3.78037430e-02, -7.91380465e-01,  6.65192902e-02,\n",
       "          1.19127464e+00],\n",
       "        [-5.36313541e-02, -9.87298250e-01,  9.03447792e-02,\n",
       "          1.50404358e+00]],\n",
       "\n",
       "       [[-6.85565472e-02, -4.30224031e-01,  1.64172761e-02,\n",
       "          5.21123230e-01],\n",
       "        [-7.71610290e-02, -2.35336989e-01,  2.68397406e-02,\n",
       "          2.33658507e-01]],\n",
       "\n",
       "       [[ 8.15523639e-02, -1.03807384e-02, -1.24420382e-01,\n",
       "         -2.19825670e-01],\n",
       "        [ 8.13447535e-02,  1.86279759e-01, -1.28816888e-01,\n",
       "         -5.49021363e-01]],\n",
       "\n",
       "       [[ 2.14778893e-02, -4.24038827e-01,  6.48775557e-03,\n",
       "          5.63985109e-01],\n",
       "        [ 1.29971132e-02, -2.29008496e-01,  1.77674592e-02,\n",
       "          2.73353189e-01]],\n",
       "\n",
       "       [[ 7.78934360e-02,  1.82946444e-01, -1.14936657e-01,\n",
       "         -4.74186063e-01],\n",
       "        [ 8.15523639e-02, -1.03807384e-02, -1.24420382e-01,\n",
       "         -2.19825670e-01]],\n",
       "\n",
       "       [[-4.86134924e-02,  3.07632294e-02,  1.01780333e-01,\n",
       "          1.38739273e-01],\n",
       "        [-4.79982272e-02, -1.65658057e-01,  1.04555115e-01,\n",
       "          4.61718231e-01]],\n",
       "\n",
       "       [[ 3.17538939e-02,  1.23860650e-02,  1.40389251e-02,\n",
       "         -2.15646252e-02],\n",
       "        [ 3.20016146e-02,  2.07303897e-01,  1.36076324e-02,\n",
       "         -3.09785247e-01]],\n",
       "\n",
       "       [[ 5.12123406e-02,  5.75073183e-01, -3.69663797e-02,\n",
       "         -8.88366640e-01],\n",
       "        [ 6.27138019e-02,  3.80471885e-01, -5.47337122e-02,\n",
       "         -6.07529759e-01]],\n",
       "\n",
       "       [[ 9.72950161e-02,  9.68382776e-01, -1.09820440e-01,\n",
       "         -1.54798961e+00],\n",
       "        [ 1.16662674e-01,  7.74737179e-01, -1.40780225e-01,\n",
       "         -1.29149342e+00]],\n",
       "\n",
       "       [[ 4.83323708e-02,  4.02190983e-01, -1.06137395e-02,\n",
       "         -5.97252250e-01],\n",
       "        [ 5.63761890e-02,  5.97459853e-01, -2.25587841e-02,\n",
       "         -8.93259406e-01]],\n",
       "\n",
       "       [[-6.08610138e-02, -9.77801144e-01,  5.34932502e-02,\n",
       "          1.44246781e+00],\n",
       "        [-8.04170370e-02, -1.17353928e+00,  8.23426098e-02,\n",
       "          1.75137460e+00]],\n",
       "\n",
       "       [[ 7.63170123e-02,  6.29749000e-01, -1.13792464e-01,\n",
       "         -9.74368513e-01],\n",
       "        [ 8.89119878e-02,  4.36322272e-01, -1.33279845e-01,\n",
       "         -7.19487727e-01]],\n",
       "\n",
       "       [[-4.35505062e-02,  1.13327224e-02,  1.32956663e-02,\n",
       "          3.51155289e-02],\n",
       "        [-4.33238521e-02, -1.83977351e-01,  1.39979767e-02,\n",
       "          3.31963539e-01]],\n",
       "\n",
       "       [[-6.08610138e-02, -9.77801144e-01,  5.34932502e-02,\n",
       "          1.44246781e+00],\n",
       "        [-8.04170370e-02, -1.17353928e+00,  8.23426098e-02,\n",
       "          1.75137460e+00]],\n",
       "\n",
       "       [[ 1.35892145e-02,  3.74040127e-01, -9.75062326e-02,\n",
       "         -6.68134809e-01],\n",
       "        [ 2.10700165e-02,  1.80399582e-01, -1.10868931e-01,\n",
       "         -4.07675147e-01]],\n",
       "\n",
       "       [[-2.24431381e-02, -4.20862883e-01,  8.48040208e-02,\n",
       "          6.75531864e-01],\n",
       "        [-3.08603942e-02, -2.27015376e-01,  9.83146578e-02,\n",
       "          4.10708070e-01]],\n",
       "\n",
       "       [[ 4.83323708e-02,  4.02190983e-01, -1.06137395e-02,\n",
       "         -5.97252250e-01],\n",
       "        [ 5.63761890e-02,  5.97459853e-01, -2.25587841e-02,\n",
       "         -8.93259406e-01]],\n",
       "\n",
       "       [[-1.36143612e-02,  3.05889137e-02,  3.81594934e-02,\n",
       "         -9.91117209e-03],\n",
       "        [-1.30025828e-02, -1.65058926e-01,  3.79612707e-02,\n",
       "          2.94563115e-01]],\n",
       "\n",
       "       [[-2.97927763e-02,  2.97689773e-02,  1.76473632e-02,\n",
       "          2.18667760e-02],\n",
       "        [-2.91973967e-02,  2.24633455e-01,  1.80846993e-02,\n",
       "         -2.65196383e-01]],\n",
       "\n",
       "       [[ 6.63871020e-02,  1.16670692e+00, -1.52373925e-01,\n",
       "         -1.95362926e+00],\n",
       "        [ 8.97212401e-02,  9.73497033e-01, -1.91446513e-01,\n",
       "         -1.71179724e+00]],\n",
       "\n",
       "       [[ 1.29971132e-02, -2.29008496e-01,  1.77674592e-02,\n",
       "          2.73353189e-01],\n",
       "        [ 8.41694325e-03, -4.24379408e-01,  2.32345220e-02,\n",
       "          5.71586668e-01]],\n",
       "\n",
       "       [[-3.46578769e-02,  2.05218405e-01,  6.10045157e-03,\n",
       "         -2.30307028e-01],\n",
       "        [-3.05535085e-02,  1.00098168e-02,  1.49431091e-03,\n",
       "          6.42939284e-02]]], dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.utils.common import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DynamicStepDriver.run of <tf_agents.drivers.dynamic_step_driver.DynamicStepDriver object at 0x000001FACDB3FC50>>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x000001FACE471BD0>>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_driver.run = function(collect_driver.run)\n",
    "agent.train = function(agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x1face3ce990>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x1facf816810>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_policy.get_initial_state(env.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       "  'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       " array([[ 0.02920513,  0.06443676, -0.1674954 , -0.6228573 ]],\n",
       "       dtype=float32)>}),\n",
       " ())"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run(None, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, ps = collect_driver.run(None,())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories, buffer_info = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(64, 2, 4), dtype=float32, numpy=\n",
       "array([[[ 9.59678888e-02, -3.50159496e-01, -2.02029198e-02,\n",
       "          6.93134129e-01],\n",
       "        [ 8.89647007e-02, -1.54763207e-01, -6.34023780e-03,\n",
       "          3.94160211e-01]],\n",
       "\n",
       "       [[ 2.69740820e-01,  4.06222641e-01,  2.91554704e-02,\n",
       "          5.38789444e-02],\n",
       "        [ 2.77865261e-01,  2.10695028e-01,  3.02330498e-02,\n",
       "          3.55616212e-01]],\n",
       "\n",
       "       [[-8.54397342e-02, -3.73708040e-01,  1.78225175e-01,\n",
       "          8.98352981e-01],\n",
       "        [-9.29138958e-02, -5.70739508e-01,  1.96192235e-01,\n",
       "          1.24133992e+00]],\n",
       "\n",
       "       [[ 4.23725200e-04, -3.72843519e-02, -1.01516634e-01,\n",
       "         -2.01786622e-01],\n",
       "        [-3.21961794e-04, -2.30818972e-01, -1.05552368e-01,\n",
       "          5.72260804e-02]],\n",
       "\n",
       "       [[ 5.33263534e-02,  3.27614620e-02, -8.75928700e-02,\n",
       "         -2.48790011e-01],\n",
       "        [ 5.39815836e-02,  2.29018033e-01, -9.25686657e-02,\n",
       "         -5.67765653e-01]],\n",
       "\n",
       "       [[ 1.09202601e-01,  1.01840055e+00, -2.11773634e-01,\n",
       "         -1.96919096e+00],\n",
       "        [ 2.05065068e-02, -3.19507793e-02,  2.23139543e-02,\n",
       "          8.19287356e-03]],\n",
       "\n",
       "       [[ 2.71133170e-03, -2.23466337e-01,  4.64916714e-02,\n",
       "          3.30915183e-01],\n",
       "        [-1.75799511e-03, -4.19218183e-01,  5.31099737e-02,\n",
       "          6.37889266e-01]],\n",
       "\n",
       "       [[ 1.32157415e-01,  9.71340001e-01, -1.66610107e-01,\n",
       "         -1.62473285e+00],\n",
       "        [ 1.51584223e-01,  7.78524399e-01, -1.99104756e-01,\n",
       "         -1.38827157e+00]],\n",
       "\n",
       "       [[-1.16402972e-02,  6.33540154e-01, -3.02377287e-02,\n",
       "         -9.14998055e-01],\n",
       "        [ 1.03050540e-03,  8.29057693e-01, -4.85376902e-02,\n",
       "         -1.21702886e+00]],\n",
       "\n",
       "       [[-2.97927763e-02,  2.97689773e-02,  1.76473632e-02,\n",
       "          2.18667760e-02],\n",
       "        [-2.91973967e-02,  2.24633455e-01,  1.80846993e-02,\n",
       "         -2.65196383e-01]],\n",
       "\n",
       "       [[-4.08374742e-02,  1.94373801e-02,  3.00871860e-02,\n",
       "          1.99220702e-02],\n",
       "        [-4.04487252e-02,  2.14115217e-01,  3.04856282e-02,\n",
       "         -2.63118237e-01]],\n",
       "\n",
       "       [[ 2.51386967e-02,  6.10956252e-01,  3.01253013e-02,\n",
       "         -8.49326849e-01],\n",
       "        [ 3.73578221e-02,  4.15436685e-01,  1.31387645e-02,\n",
       "         -5.47325075e-01]],\n",
       "\n",
       "       [[ 2.10700165e-02,  1.80399582e-01, -1.10868931e-01,\n",
       "         -4.07675147e-01],\n",
       "        [ 2.46780086e-02, -1.29900528e-02, -1.19022436e-01,\n",
       "         -1.51900440e-01]],\n",
       "\n",
       "       [[-4.17979211e-02, -3.30613955e-04,  1.03683002e-01,\n",
       "          2.17965364e-01],\n",
       "        [-4.18045335e-02,  1.93168148e-01,  1.08042307e-01,\n",
       "         -4.02958468e-02]],\n",
       "\n",
       "       [[-1.45710543e-01, -1.01446533e+00,  1.75560385e-01,\n",
       "          1.58267891e+00],\n",
       "        [-1.65999845e-01, -1.21118772e+00,  2.07213953e-01,\n",
       "          1.92457676e+00]],\n",
       "\n",
       "       [[-6.48340136e-02, -1.00952923e+00,  5.62444888e-02,\n",
       "          1.45482862e+00],\n",
       "        [-8.50246027e-02, -1.20529473e+00,  8.53410661e-02,\n",
       "          1.76453972e+00]],\n",
       "\n",
       "       [[-3.74417417e-02, -3.63990873e-01,  8.19982886e-02,\n",
       "          6.73035741e-01],\n",
       "        [-4.47215587e-02, -5.60151041e-01,  9.54590067e-02,\n",
       "          9.90367889e-01]],\n",
       "\n",
       "       [[-3.37544046e-02,  1.49121791e-01,  2.79801600e-02,\n",
       "         -2.94385105e-01],\n",
       "        [-3.07719689e-02,  3.43833894e-01,  2.20924579e-02,\n",
       "         -5.78113854e-01]],\n",
       "\n",
       "       [[ 5.85619435e-02,  4.25308198e-01, -1.03923984e-01,\n",
       "         -8.88116598e-01],\n",
       "        [ 6.70681074e-02,  2.31738538e-01, -1.21686310e-01,\n",
       "         -6.29827380e-01]],\n",
       "\n",
       "       [[ 1.24028139e-01,  7.96211600e-01, -1.25981897e-01,\n",
       "         -1.27413690e+00],\n",
       "        [ 1.39952376e-01,  9.92695272e-01, -1.51464626e-01,\n",
       "         -1.60346735e+00]],\n",
       "\n",
       "       [[ 1.23987250e-01,  7.72963524e-01, -6.57666028e-02,\n",
       "         -1.07655907e+00],\n",
       "        [ 1.39446512e-01,  5.78769088e-01, -8.72977823e-02,\n",
       "         -8.05218577e-01]],\n",
       "\n",
       "       [[-1.06460331e-02, -4.38705057e-01,  9.56966653e-02,\n",
       "          7.48858690e-01],\n",
       "        [-1.94201339e-02, -6.35007679e-01,  1.10673837e-01,\n",
       "          1.07005727e+00]],\n",
       "\n",
       "       [[ 8.87215286e-02,  2.21391380e-01, -5.02450392e-02,\n",
       "         -2.78606832e-01],\n",
       "        [ 9.31493565e-02,  4.17192757e-01, -5.58171757e-02,\n",
       "         -5.86704075e-01]],\n",
       "\n",
       "       [[ 8.67008045e-02,  2.84179933e-02, -3.32665779e-02,\n",
       "          3.92384641e-02],\n",
       "        [ 8.72691646e-02, -1.66211516e-01, -3.24818082e-02,\n",
       "          3.21242630e-01]],\n",
       "\n",
       "       [[-2.19502077e-02,  9.98084154e-03, -5.01736393e-03,\n",
       "          6.49341419e-02],\n",
       "        [-2.17505917e-02, -1.85068816e-01, -3.71868117e-03,\n",
       "          3.56029838e-01]],\n",
       "\n",
       "       [[ 1.46498187e-02,  3.80625933e-01,  4.47330959e-02,\n",
       "         -4.43887353e-01],\n",
       "        [ 2.22623367e-02,  1.84900537e-01,  3.58553492e-02,\n",
       "         -1.37445793e-01]],\n",
       "\n",
       "       [[-4.38683741e-02, -6.19803667e-01,  1.21182747e-01,\n",
       "          1.05691612e+00],\n",
       "        [-5.62644489e-02, -8.16304743e-01,  1.42321065e-01,\n",
       "          1.38504672e+00]],\n",
       "\n",
       "       [[-3.40839587e-02, -1.67889118e-01,  7.48438314e-02,\n",
       "          3.57723057e-01],\n",
       "        [-3.74417417e-02, -3.63990873e-01,  8.19982886e-02,\n",
       "          6.73035741e-01]],\n",
       "\n",
       "       [[ 7.52997771e-02,  3.78242075e-01, -2.07087677e-02,\n",
       "         -3.90815139e-01],\n",
       "        [ 8.28646198e-02,  1.83420062e-01, -2.85250694e-02,\n",
       "         -1.04732707e-01]],\n",
       "\n",
       "       [[ 2.35913545e-02, -5.78434626e-03,  1.91666987e-02,\n",
       "          5.74672706e-02],\n",
       "        [ 2.34756675e-02, -2.01175794e-01,  2.03160439e-02,\n",
       "          3.56135279e-01]],\n",
       "\n",
       "       [[ 2.51386967e-02,  6.10956252e-01,  3.01253013e-02,\n",
       "         -8.49326849e-01],\n",
       "        [ 3.73578221e-02,  4.15436685e-01,  1.31387645e-02,\n",
       "         -5.47325075e-01]],\n",
       "\n",
       "       [[ 8.83674901e-03,  2.03190580e-01, -1.42037887e-02,\n",
       "         -1.85583636e-01],\n",
       "        [ 1.29005602e-02,  3.98512840e-01, -1.79154612e-02,\n",
       "         -4.82713252e-01]],\n",
       "\n",
       "       [[ 4.21419412e-01,  5.96773505e-01, -1.01574808e-02,\n",
       "         -1.38007447e-01],\n",
       "        [ 4.33354884e-01,  4.01798517e-01, -1.29176294e-02,\n",
       "          1.51453733e-01]],\n",
       "\n",
       "       [[-2.60521304e-02,  2.05096141e-01, -4.65324643e-04,\n",
       "         -2.27601975e-01],\n",
       "        [-2.19502077e-02,  9.98084154e-03, -5.01736393e-03,\n",
       "          6.49341419e-02]],\n",
       "\n",
       "       [[-1.60239134e-02,  8.80893320e-03,  3.79464440e-02,\n",
       "          1.52607504e-02],\n",
       "        [-1.58477332e-02,  2.03366712e-01,  3.82516570e-02,\n",
       "         -2.65212268e-01]],\n",
       "\n",
       "       [[ 8.04026574e-02,  4.15943742e-01, -3.90704609e-02,\n",
       "         -5.58728874e-01],\n",
       "        [ 8.87215286e-02,  2.21391380e-01, -5.02450392e-02,\n",
       "         -2.78606832e-01]],\n",
       "\n",
       "       [[ 3.93758304e-02, -1.47150187e-02, -4.20092745e-03,\n",
       "          7.08575419e-04],\n",
       "        [ 3.90815288e-02,  1.80466920e-01, -4.18675598e-03,\n",
       "         -2.93296844e-01]],\n",
       "\n",
       "       [[ 3.68556865e-02,  2.17498973e-01, -5.03693633e-02,\n",
       "         -3.11867625e-01],\n",
       "        [ 4.12056670e-02,  4.13300991e-01, -5.66067137e-02,\n",
       "         -6.20000482e-01]],\n",
       "\n",
       "       [[ 8.67008045e-02,  2.84179933e-02, -3.32665779e-02,\n",
       "          3.92384641e-02],\n",
       "        [ 8.72691646e-02, -1.66211516e-01, -3.24818082e-02,\n",
       "          3.21242630e-01]],\n",
       "\n",
       "       [[ 9.72950161e-02,  9.68382776e-01, -1.09820440e-01,\n",
       "         -1.54798961e+00],\n",
       "        [ 1.16662674e-01,  7.74737179e-01, -1.40780225e-01,\n",
       "         -1.29149342e+00]],\n",
       "\n",
       "       [[ 4.46684152e-01, -1.84966505e-01,  7.26093873e-02,\n",
       "          1.06241989e+00],\n",
       "        [ 4.42984819e-01, -3.80970776e-01,  9.38577875e-02,\n",
       "          1.37697995e+00]],\n",
       "\n",
       "       [[ 3.17538939e-02,  1.23860650e-02,  1.40389251e-02,\n",
       "         -2.15646252e-02],\n",
       "        [ 3.20016146e-02,  2.07303897e-01,  1.36076324e-02,\n",
       "         -3.09785247e-01]],\n",
       "\n",
       "       [[ 2.34756675e-02, -2.01175794e-01,  2.03160439e-02,\n",
       "          3.56135279e-01],\n",
       "        [ 1.94521509e-02, -6.34849537e-03,  2.74387486e-02,\n",
       "          6.99271411e-02]],\n",
       "\n",
       "       [[-4.70319837e-02, -2.52648652e-01,  1.66132376e-01,\n",
       "          6.61623955e-01],\n",
       "        [-5.20849600e-02, -4.49644774e-01,  1.79364860e-01,\n",
       "          1.00166821e+00]],\n",
       "\n",
       "       [[ 9.94604197e-04,  2.07637578e-01,  1.64823867e-02,\n",
       "         -2.47387782e-01],\n",
       "        [ 5.14735607e-03,  1.22841578e-02,  1.15346313e-02,\n",
       "          5.04481494e-02]],\n",
       "\n",
       "       [[-5.41286729e-02, -3.65272552e-01,  1.28464893e-01,\n",
       "          8.57409835e-01],\n",
       "        [-6.14341237e-02, -5.61888695e-01,  1.45613089e-01,\n",
       "          1.18756866e+00]],\n",
       "\n",
       "       [[-4.59188633e-02, -5.56561016e-02,  1.59669369e-01,\n",
       "          3.23150158e-01],\n",
       "        [-4.70319837e-02, -2.52648652e-01,  1.66132376e-01,\n",
       "          6.61623955e-01]],\n",
       "\n",
       "       [[-5.08969128e-02,  1.45397499e-01, -1.33051677e-02,\n",
       "         -2.86088169e-01],\n",
       "        [-4.79889624e-02, -4.95321900e-02, -1.90269314e-02,\n",
       "          2.36887578e-03]],\n",
       "\n",
       "       [[-3.54900546e-02, -3.65623862e-01, -1.11660073e-02,\n",
       "          4.23277795e-01],\n",
       "        [-4.28025313e-02, -5.60585856e-01, -2.70045106e-03,\n",
       "          7.12419808e-01]],\n",
       "\n",
       "       [[-9.77939554e-03,  7.50475347e-01,  3.58699588e-04,\n",
       "         -9.49149072e-01],\n",
       "        [ 5.23011060e-03,  5.55348516e-01, -1.86242815e-02,\n",
       "         -6.56353474e-01]],\n",
       "\n",
       "       [[ 3.23493667e-02, -2.36259654e-01,  3.27497199e-02,\n",
       "          2.91811407e-01],\n",
       "        [ 2.76241750e-02, -4.16195951e-02,  3.85859497e-02,\n",
       "          9.63456370e-03]],\n",
       "\n",
       "       [[-6.67520463e-02, -5.81027508e-01,  1.44243345e-01,\n",
       "          1.11369967e+00],\n",
       "        [-7.83725977e-02, -3.88063461e-01,  1.66517347e-01,\n",
       "          8.69520068e-01]],\n",
       "\n",
       "       [[-1.63037609e-02, -3.60700935e-01,  4.38525341e-02,\n",
       "          5.98972678e-01],\n",
       "        [-2.35177800e-02, -1.66219100e-01,  5.58319874e-02,\n",
       "          3.20418864e-01]],\n",
       "\n",
       "       [[ 3.85631174e-01,  7.91519523e-01, -2.27814214e-03,\n",
       "         -4.22391504e-01],\n",
       "        [ 4.01461571e-01,  5.96429884e-01, -1.07259722e-02,\n",
       "         -1.30427629e-01]],\n",
       "\n",
       "       [[ 1.79135166e-02, -4.23316777e-01,  2.37827860e-02,\n",
       "          6.18407905e-01],\n",
       "        [ 9.44718160e-03, -2.28534982e-01,  3.61509435e-02,\n",
       "          3.33309263e-01]],\n",
       "\n",
       "       [[ 4.79865856e-02,  2.31805339e-01, -6.84327167e-03,\n",
       "         -2.73122966e-01],\n",
       "        [ 5.26226908e-02,  4.27024275e-01, -1.23057310e-02,\n",
       "         -5.67956388e-01]],\n",
       "\n",
       "       [[ 1.12705179e-01,  4.09012288e-01, -1.57189935e-01,\n",
       "         -7.22390234e-01],\n",
       "        [ 1.20885424e-01,  2.16373429e-01, -1.71637729e-01,\n",
       "         -4.83018279e-01]],\n",
       "\n",
       "       [[ 2.39394456e-02, -2.40489766e-01,  4.72934358e-02,\n",
       "          3.02518487e-01],\n",
       "        [ 1.91296507e-02, -4.60726321e-02,  5.33438027e-02,\n",
       "          2.51179375e-02]],\n",
       "\n",
       "       [[ 1.23987250e-01,  7.72963524e-01, -6.57666028e-02,\n",
       "         -1.07655907e+00],\n",
       "        [ 1.39446512e-01,  5.78769088e-01, -8.72977823e-02,\n",
       "         -8.05218577e-01]],\n",
       "\n",
       "       [[-3.75368744e-02, -1.53095797e-01,  3.98848578e-02,\n",
       "          2.49852389e-01],\n",
       "        [-4.05987911e-02, -3.48763973e-01,  4.48819064e-02,\n",
       "          5.54844260e-01]],\n",
       "\n",
       "       [[-3.21961794e-04, -2.30818972e-01, -1.05552368e-01,\n",
       "          5.72260804e-02],\n",
       "        [-4.93834121e-03, -4.24281567e-01, -1.04407847e-01,\n",
       "          3.14830124e-01]],\n",
       "\n",
       "       [[ 1.18804462e-01,  4.13546860e-01, -1.73417151e-01,\n",
       "         -9.40158427e-01],\n",
       "        [ 1.27075404e-01,  6.10528350e-01, -1.92220315e-01,\n",
       "         -1.28192842e+00]],\n",
       "\n",
       "       [[-1.99920358e-03, -3.54616910e-01,  1.83959510e-02,\n",
       "          6.16197586e-01],\n",
       "        [-9.09154117e-03, -5.49990952e-01,  3.07199024e-02,\n",
       "          9.14617181e-01]],\n",
       "\n",
       "       [[-1.99039057e-02, -8.13863039e-01, -6.85894676e-03,\n",
       "          1.14903831e+00],\n",
       "        [-3.61811668e-02, -6.18652225e-01,  1.61218196e-02,\n",
       "          8.54212523e-01]]], dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32)),\n",
       " 'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LossInfo(loss=<tf.Tensor: shape=(), dtype=float32, numpy=1.0772214>, extra=DqnLossInfo(td_loss=<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([1.0102874, 1.000267 , 1.1176362, 1.0181779, 1.0991364, 0.       ,\n",
       "       1.0637406, 1.4008298, 1.0881807, 1.1015971, 1.0964787, 1.1713035,\n",
       "       1.0485126, 1.0600985, 1.2188026, 1.1931905, 1.0958183, 1.0969179,\n",
       "       1.171158 , 1.0884794, 1.2536561, 1.1034644, 1.0999069, 1.0207505,\n",
       "       1.0325279, 1.0635626, 1.136952 , 1.0664694, 1.0692486, 1.0310467,\n",
       "       1.1713035, 1.0987087, 1.0697533, 1.0073216, 1.0959064, 1.1021773,\n",
       "       1.1008652, 1.1000414, 1.0207505, 1.3764472, 1.0294132, 1.1020159,\n",
       "       1.0094546, 1.0934191, 1.0073463, 1.107274 , 1.0642033, 1.023926 ,\n",
       "       1.0890372, 1.2064425, 1.0156872, 1.0089902, 1.0113282, 1.1757089,\n",
       "       1.0110266, 1.0976887, 1.1455642, 1.0156358, 1.2536561, 1.0596786,\n",
       "       1.0551097, 1.1017693, 1.0842642, 1.012057 ], dtype=float32)>, td_error=<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([1.0051305, 1.0001335, 1.0571831, 1.009048 , 1.0483971, 0.       ,\n",
       "       1.031378 , 1.1835666, 1.043159 , 1.04957  , 1.0471288, 1.0822678,\n",
       "       1.023969 , 1.0296109, 1.1039939, 1.0923326, 1.0468134, 1.0473385,\n",
       "       1.0822005, 1.0433022, 1.1196679, 1.0504591, 1.0487645, 1.010322 ,\n",
       "       1.0161338, 1.0312917, 1.0662795, 1.0327001, 1.0340447, 1.0154047,\n",
       "       1.0822678, 1.0481931, 1.0342888, 1.0036541, 1.0468554, 1.0498463,\n",
       "       1.0492213, 1.0488286, 1.010322 , 1.1732209, 1.0146   , 1.0497694,\n",
       "       1.0047162, 1.0456668, 1.0036664, 1.0522709, 1.0316023, 1.0118923,\n",
       "       1.0435694, 1.0983818, 1.0078131, 1.004485 , 1.0056481, 1.0843011,\n",
       "       1.0054982, 1.0477064, 1.0703104, 1.0077876, 1.1196679, 1.0294069,\n",
       "       1.0271853, 1.049652 , 1.04128  , 1.0060104], dtype=float32)>))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "        avg_return = total_return / num_episodes\n",
    "        return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = suite_gym.load('CartPole-v1')\n",
    "eval_env = TFPyEnvironment(eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(n_iteration):\n",
    "    losses = []\n",
    "    avg_returns = []\n",
    "    train_step.assign(0)\n",
    "    time_step = None\n",
    "    policy_state = agent.collect_policy.get_initial_state(env.batch_size)\n",
    "    iterator = iter(dataset)\n",
    "\n",
    "    for iteration in range(n_iteration):\n",
    "        time_step, policy_state = collect_driver.run(time_step, policy_state)\n",
    "        trajectories, buffer_info = next(iterator)\n",
    "        train_loss = agent.train(trajectories)\n",
    "        loss = train_loss.loss.numpy()\n",
    "        avg_return = train_metrics[0].result().numpy()\n",
    "        losses.append(loss)\n",
    "        avg_returns.append(avg_return)\n",
    "        if train_step%100 == 0:\n",
    "            \n",
    "            print(f'train step: {train_step.value()}      loss: {loss}     avg_return: {avg_return}     customreturn: {compute_avg_return(eval_env, agent.policy)}')\n",
    "\n",
    "    return losses, avg_returns\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step: 100      loss: 1.1937060356140137     avg_return: 20.700000762939453     customreturn: 1.0\n",
      "train step: 200      loss: 1.613093614578247     avg_return: 13.5     customreturn: 1.0\n",
      "train step: 300      loss: 1.552215337753296     avg_return: 13.699999809265137     customreturn: 0.8999999761581421\n",
      "train step: 400      loss: 0.9064115285873413     avg_return: 18.299999237060547     customreturn: 1.0\n",
      "train step: 500      loss: 1.3020970821380615     avg_return: 23.799999237060547     customreturn: 2.799999952316284\n",
      "train step: 600      loss: 0.4367882013320923     avg_return: 143.89999389648438     customreturn: 10.300000190734863\n",
      "train step: 700      loss: 0.3084270656108856     avg_return: 132.89999389648438     customreturn: 15.5\n",
      "train step: 800      loss: 0.25025248527526855     avg_return: 146.8000030517578     customreturn: 15.699999809265137\n",
      "train step: 900      loss: 0.17003373801708221     avg_return: 208.8000030517578     customreturn: 43.099998474121094\n",
      "train step: 1000      loss: 0.20278121531009674     avg_return: 68.80000305175781     customreturn: 7.599999904632568\n",
      "train step: 1100      loss: 0.10832777619361877     avg_return: 151.60000610351562     customreturn: 14.800000190734863\n",
      "train step: 1200      loss: 0.11276362836360931     avg_return: 115.80000305175781     customreturn: 15.800000190734863\n",
      "train step: 1300      loss: 0.07249051332473755     avg_return: 160.60000610351562     customreturn: 11.699999809265137\n",
      "train step: 1400      loss: 2.116957664489746     avg_return: 133.5     customreturn: 12.5\n",
      "train step: 1500      loss: 0.07300102710723877     avg_return: 197.89999389648438     customreturn: 16.700000762939453\n",
      "train step: 1600      loss: 0.09804937243461609     avg_return: 204.5     customreturn: 24.100000381469727\n",
      "train step: 1700      loss: 0.10003979504108429     avg_return: 158.5     customreturn: 13.0\n",
      "train step: 1800      loss: 0.08559656143188477     avg_return: 151.10000610351562     customreturn: 14.399999618530273\n",
      "train step: 1900      loss: 0.0965953916311264     avg_return: 196.39999389648438     customreturn: 15.100000381469727\n",
      "train step: 2000      loss: 0.273132860660553     avg_return: 184.8000030517578     customreturn: 13.699999809265137\n",
      "train step: 2100      loss: 0.08167038857936859     avg_return: 166.1999969482422     customreturn: 12.199999809265137\n",
      "train step: 2200      loss: 0.03707447648048401     avg_return: 306.20001220703125     customreturn: 31.100000381469727\n",
      "train step: 2300      loss: 0.4232320189476013     avg_return: 162.0     customreturn: 21.200000762939453\n",
      "train step: 2400      loss: 0.03350188955664635     avg_return: 163.60000610351562     customreturn: 19.100000381469727\n",
      "train step: 2500      loss: 0.05707710236310959     avg_return: 182.0     customreturn: 18.399999618530273\n",
      "train step: 2600      loss: 0.04180402308702469     avg_return: 158.1999969482422     customreturn: 14.0\n",
      "train step: 2700      loss: 0.02502688579261303     avg_return: 154.5     customreturn: 14.399999618530273\n",
      "train step: 2800      loss: 0.03122091293334961     avg_return: 135.1999969482422     customreturn: 19.100000381469727\n",
      "train step: 2900      loss: 0.41566652059555054     avg_return: 142.60000610351562     customreturn: 14.5\n",
      "train step: 3000      loss: 0.037395525723695755     avg_return: 123.69999694824219     customreturn: 18.899999618530273\n",
      "train step: 3100      loss: 0.3223927915096283     avg_return: 115.80000305175781     customreturn: 12.399999618530273\n",
      "train step: 3200      loss: 0.06690174341201782     avg_return: 145.10000610351562     customreturn: 13.899999618530273\n",
      "train step: 3300      loss: 0.6550408005714417     avg_return: 104.5     customreturn: 11.800000190734863\n",
      "train step: 3400      loss: 0.6118247509002686     avg_return: 26.700000762939453     customreturn: 3.299999952316284\n",
      "train step: 3500      loss: 0.09343628585338593     avg_return: 137.0     customreturn: 22.299999237060547\n",
      "train step: 3600      loss: 0.03771229833364487     avg_return: 125.5     customreturn: 13.199999809265137\n",
      "train step: 3700      loss: 0.019904453307390213     avg_return: 118.19999694824219     customreturn: 10.899999618530273\n",
      "train step: 3800      loss: 0.011829014867544174     avg_return: 113.0     customreturn: 10.0\n",
      "train step: 3900      loss: 0.5805724859237671     avg_return: 103.19999694824219     customreturn: 10.5\n",
      "train step: 4000      loss: 0.5323761701583862     avg_return: 67.30000305175781     customreturn: 11.0\n",
      "train step: 4100      loss: 4.191624641418457     avg_return: 160.60000610351562     customreturn: 17.0\n",
      "train step: 4200      loss: 0.06846258789300919     avg_return: 131.5     customreturn: 15.699999809265137\n",
      "train step: 4300      loss: 0.028430432081222534     avg_return: 162.5     customreturn: 15.699999809265137\n",
      "train step: 4400      loss: 0.04009260982275009     avg_return: 257.0     customreturn: 50.0\n",
      "train step: 4500      loss: 0.02251318097114563     avg_return: 244.8000030517578     customreturn: 31.899999618530273\n",
      "train step: 4600      loss: 0.04173163324594498     avg_return: 244.89999389648438     customreturn: 16.899999618530273\n",
      "train step: 4700      loss: 0.26019519567489624     avg_return: 265.29998779296875     customreturn: 19.100000381469727\n",
      "train step: 4800      loss: 0.024280309677124023     avg_return: 172.0     customreturn: 17.200000762939453\n",
      "train step: 4900      loss: 0.02495952695608139     avg_return: 165.89999389648438     customreturn: 16.200000762939453\n",
      "train step: 5000      loss: 0.02648044005036354     avg_return: 168.60000610351562     customreturn: 13.300000190734863\n",
      "train step: 5100      loss: 0.02948923036456108     avg_return: 167.6999969482422     customreturn: 43.400001525878906\n",
      "train step: 5200      loss: 0.806559681892395     avg_return: 149.0     customreturn: 13.899999618530273\n",
      "train step: 5300      loss: 0.0371231809258461     avg_return: 150.6999969482422     customreturn: 14.899999618530273\n",
      "train step: 5400      loss: 0.029511064291000366     avg_return: 150.0     customreturn: 16.0\n",
      "train step: 5500      loss: 0.03819406032562256     avg_return: 171.60000610351562     customreturn: 15.600000381469727\n",
      "train step: 5600      loss: 0.14990930259227753     avg_return: 159.3000030517578     customreturn: 14.199999809265137\n",
      "train step: 5700      loss: 0.2993387281894684     avg_return: 166.89999389648438     customreturn: 14.699999809265137\n",
      "train step: 5800      loss: 0.4190104901790619     avg_return: 153.39999389648438     customreturn: 15.5\n",
      "train step: 5900      loss: 0.03494776785373688     avg_return: 166.60000610351562     customreturn: 16.399999618530273\n",
      "train step: 6000      loss: 0.45459380745887756     avg_return: 163.6999969482422     customreturn: 13.0\n",
      "train step: 6100      loss: 0.03394562005996704     avg_return: 128.5     customreturn: 17.5\n",
      "train step: 6200      loss: 0.8193826079368591     avg_return: 150.5     customreturn: 14.300000190734863\n",
      "train step: 6300      loss: 0.03257261961698532     avg_return: 208.10000610351562     customreturn: 14.100000381469727\n",
      "train step: 6400      loss: 0.035036079585552216     avg_return: 232.0     customreturn: 22.0\n",
      "train step: 6500      loss: 0.02501497231423855     avg_return: 287.1000061035156     customreturn: 25.5\n",
      "train step: 6600      loss: 0.03520321846008301     avg_return: 299.8999938964844     customreturn: 16.100000381469727\n",
      "train step: 6700      loss: 0.02385570853948593     avg_return: 252.6999969482422     customreturn: 48.20000076293945\n",
      "train step: 6800      loss: 2.2145533561706543     avg_return: 157.0     customreturn: 10.5\n",
      "train step: 6900      loss: 0.04343423992395401     avg_return: 153.0     customreturn: 20.399999618530273\n",
      "train step: 7000      loss: 0.022071246057748795     avg_return: 128.89999389648438     customreturn: 11.300000190734863\n",
      "train step: 7100      loss: 0.036387257277965546     avg_return: 230.89999389648438     customreturn: 19.799999237060547\n",
      "train step: 7200      loss: 0.0646188035607338     avg_return: 139.89999389648438     customreturn: 47.099998474121094\n",
      "train step: 7300      loss: 0.051587462425231934     avg_return: 218.10000610351562     customreturn: 15.300000190734863\n",
      "train step: 7400      loss: 0.027045950293540955     avg_return: 156.8000030517578     customreturn: 30.600000381469727\n",
      "train step: 7500      loss: 0.22821171581745148     avg_return: 263.29998779296875     customreturn: 20.100000381469727\n",
      "train step: 7600      loss: 0.05729898065328598     avg_return: 181.5     customreturn: 17.5\n",
      "train step: 7700      loss: 0.04391879588365555     avg_return: 201.39999389648438     customreturn: 18.799999237060547\n",
      "train step: 7800      loss: 0.0615687295794487     avg_return: 185.89999389648438     customreturn: 17.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "losses, avg_returns = train_agent(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_returns})\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({'returns': avg_returns}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'losses': losses}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a evaluation environment to test policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_py_env = suite_gym.load('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tf_env = TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([-0.02632038, -0.04539856,  0.02695911, -0.0459032 ], dtype=float32)})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_py_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.04607582,  0.02035571,  0.02588396,  0.04543513]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tf_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([-0.04607582,  0.02035571,  0.02588396,  0.04543513], dtype=float32)})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_py_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.04607582,  0.02035571,  0.02588396,  0.04543513]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tf_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tf_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.04607582,  0.02035571,  0.02588396,  0.04543513]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tf_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_py_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([-0.04607582,  0.02035571,  0.02588396,  0.04543513], dtype=float32)})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_py_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.greedy_policy.GreedyPolicy at 0x15c228a88d0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_name': 'greedy_policy',\n",
       " '_name_scope': <tensorflow.python.framework.ops.name_scope_v2 at 0x15c24baf280>,\n",
       " '_time_step_spec': TimeStep(\n",
       " {'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       "  'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       "  'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "       dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "       dtype=float32))}),\n",
       " '_action_spec': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " '_policy_state_spec': (),\n",
       " '_emit_log_probability': False,\n",
       " '_validate_args': True,\n",
       " '_info_spec': (),\n",
       " '_policy_step_spec': PolicyStep(action=BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)), state=(), info=()),\n",
       " '_trajectory_spec': Trajectory(\n",
       " {'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "       dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "       dtype=float32)),\n",
       "  'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       "  'policy_info': (),\n",
       "  'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       "  'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))}),\n",
       " '_clip': True,\n",
       " '_action_fn': <function tf_agents.policies.tf_policy.TFPolicy._action(time_step: tf_agents.trajectories.time_step.TimeStep, policy_state: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], seed: Union[int, Sequence[int], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, float, str, bool, NoneType] = None) -> tf_agents.trajectories.policy_step.PolicyStep>,\n",
       " '_automatic_state_reset': True,\n",
       " '_observation_and_action_constraint_splitter': None,\n",
       " '_self_setattr_tracking': True,\n",
       " '_self_unconditional_checkpoint_dependencies': [TrackableReference(name=_wrapped_policy, ref=<tf_agents.policies.q_policy.QPolicy object at 0x0000015C24AB8F50>)],\n",
       " '_self_unconditional_dependency_names': {'_wrapped_policy': <tf_agents.policies.q_policy.QPolicy at 0x15c24ab8f50>},\n",
       " '_self_unconditional_deferred_dependencies': {},\n",
       " '_self_update_uid': -1,\n",
       " '_self_name_based_restores': set(),\n",
       " '_self_saveable_object_factories': {},\n",
       " '_wrapped_policy': <tf_agents.policies.q_policy.QPolicy at 0x15c24ab8f50>}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1], dtype=int64)>, state=(), info=())"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.action(eval_tf_env.current_time_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_flat_action_spec': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " '_self_setattr_tracking': True,\n",
       " '_self_unconditional_checkpoint_dependencies': [TrackableReference(name=_q_network, ref=<tf_agents.networks.q_network.QNetwork object at 0x0000015C2328CF90>)],\n",
       " '_self_unconditional_dependency_names': {'_q_network': <tf_agents.networks.q_network.QNetwork at 0x15c2328cf90>},\n",
       " '_self_unconditional_deferred_dependencies': {},\n",
       " '_self_update_uid': -1,\n",
       " '_self_name_based_restores': set(),\n",
       " '_self_saveable_object_factories': {},\n",
       " '_q_network': <tf_agents.networks.q_network.QNetwork at 0x15c2328cf90>,\n",
       " '_name': 'q_policy',\n",
       " '_name_scope': <tensorflow.python.framework.ops.name_scope_v2 at 0x15c24baeb30>,\n",
       " '_time_step_spec': TimeStep(\n",
       " {'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       "  'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       "  'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "       dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "       dtype=float32))}),\n",
       " '_action_spec': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " '_policy_state_spec': (),\n",
       " '_emit_log_probability': False,\n",
       " '_validate_args': True,\n",
       " '_info_spec': (),\n",
       " '_policy_step_spec': PolicyStep(action=BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)), state=(), info=()),\n",
       " '_trajectory_spec': Trajectory(\n",
       " {'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "       dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "       dtype=float32)),\n",
       "  'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       "  'policy_info': (),\n",
       "  'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       "  'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       "  'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))}),\n",
       " '_clip': False,\n",
       " '_action_fn': <function tf_agents.policies.tf_policy.TFPolicy._action(time_step: tf_agents.trajectories.time_step.TimeStep, policy_state: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], seed: Union[int, Sequence[int], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, float, str, bool, NoneType] = None) -> tf_agents.trajectories.policy_step.PolicyStep>,\n",
       " '_automatic_state_reset': True,\n",
       " '_observation_and_action_constraint_splitter': None}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.wrapped_policy.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    time_step = eval_tf_env.reset()\n",
    "\n",
    "    while not time_step.is_last():\n",
    "        time_step = eval_tf_env.step(policy.action(time_step))\n",
    "        eval_py_env.render(mode='human')\n",
    "\n",
    "eval_py_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_py_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a trained agent policy to be used in another program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies.policy_saver import PolicySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "this __dict__ descriptor does not support '_DictWrapper' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m policy_saver \u001b[38;5;241m=\u001b[39m \u001b[43mPolicySaver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_collect_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tf_agents\\policies\\policy_saver.py:333\u001b[0m, in \u001b[0;36mPolicySaver.__init__\u001b[1;34m(self, policy, batch_size, use_nest_path_signatures, seed, train_step, input_fn_and_spec, metadata)\u001b[0m\n\u001b[0;32m    326\u001b[0m get_initial_state_fn\u001b[38;5;241m.\u001b[39mget_concrete_function(\u001b[38;5;241m*\u001b[39mget_initial_state_input_specs)\n\u001b[0;32m    328\u001b[0m train_step_fn \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: saved_policy\u001b[38;5;241m.\u001b[39mtrain_step\n\u001b[0;32m    330\u001b[0m )\u001b[38;5;241m.\u001b[39mget_concrete_function()\n\u001b[0;32m    331\u001b[0m get_metadata_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\n\u001b[1;32m--> 333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m batched_time_step_spec \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m spec: add_batch_dim(spec, [batch_size]), policy\u001b[38;5;241m.\u001b[39mtime_step_spec\n\u001b[0;32m    337\u001b[0m )\n\u001b[0;32m    338\u001b[0m batched_time_step_spec \u001b[38;5;241m=\u001b[39m cast(ts\u001b[38;5;241m.\u001b[39mTimeStep, batched_time_step_spec)\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    693\u001b[0m )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:331\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    328\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_captures\u001b[38;5;241m.\u001b[39mmerge_by_ref_with(graph_capture_container)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# Create a new FunctionType including captures and outputs.\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m output_type \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraced_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_context\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m traced_func_type \u001b[38;5;241m=\u001b[39m function_type_lib\u001b[38;5;241m.\u001b[39mFunctionType(\n\u001b[0;32m    335\u001b[0m     function_type\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    336\u001b[0m     traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\u001b[38;5;241m.\u001b[39mcapture_types,\n\u001b[0;32m    337\u001b[0m     return_annotation\u001b[38;5;241m=\u001b[39moutput_type,\n\u001b[0;32m    338\u001b[0m )\n\u001b[0;32m    340\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m concrete_function_lib\u001b[38;5;241m.\u001b[39mConcreteFunction\u001b[38;5;241m.\u001b[39mfrom_func_graph(\n\u001b[0;32m    341\u001b[0m     traced_func_graph,\n\u001b[0;32m    342\u001b[0m     traced_func_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py:144\u001b[0m, in \u001b[0;36mfrom_value\u001b[1;34m(value, context)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mis_legacy_signature \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, trace\u001b[38;5;241m.\u001b[39mTraceType):\n\u001b[0;32m    143\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, trace\u001b[38;5;241m.\u001b[39mSupportsTracingProtocol):\n\u001b[0;32m    145\u001b[0m   generated_type \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39m__tf_tracing_type__(context)\n\u001b[0;32m    146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generated_type, trace\u001b[38;5;241m.\u001b[39mTraceType):\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\typing_extensions.py:577\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol_attrs__:\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetattr_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\inspect.py:1830\u001b[0m, in \u001b[0;36mgetattr_static\u001b[1;34m(obj, attr, default)\u001b[0m\n\u001b[0;32m   1827\u001b[0m     dict_attr \u001b[38;5;241m=\u001b[39m _shadowed_dict(klass)\n\u001b[0;32m   1828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types\u001b[38;5;241m.\u001b[39mMemberDescriptorType):\n\u001b[1;32m-> 1830\u001b[0m         instance_result \u001b[38;5;241m=\u001b[39m \u001b[43m_check_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1832\u001b[0m     klass \u001b[38;5;241m=\u001b[39m obj\n",
      "File \u001b[1;32mc:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\inspect.py:1777\u001b[0m, in \u001b[0;36m_check_instance\u001b[1;34m(obj, attr)\u001b[0m\n\u001b[0;32m   1775\u001b[0m instance_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1777\u001b[0m     instance_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__dict__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1778\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: this __dict__ descriptor does not support '_DictWrapper' objects"
     ]
    }
   ],
   "source": [
    "policy_saver = PolicySaver(policy= initial_collect_policy, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
