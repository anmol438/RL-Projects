{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the TF Agents to train the CartPole environment with DQN.\n",
    "TF Agents package makes the implementation of RL algo easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.environments import suite_gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = suite_gym.load(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.environments.wrappers.TimeLimit at 0x1e6c0659c10>"
      ]
     },
     "execution_count": 1330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<OrderEnforcing<CartPoleEnv<CartPole-v1>>>>"
      ]
     },
     "execution_count": 1331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.01262178,  0.04025272, -0.01962253,  0.00919425], dtype=float32)})"
      ]
     },
     "execution_count": 1332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(1),\n",
       " 'reward': array(1., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.01342683, -0.15458241, -0.01943865,  0.29562202], dtype=float32)})"
      ]
     },
     "execution_count": 1333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore Environment Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])"
      ]
     },
     "execution_count": 1334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 1335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': ArraySpec(shape=(), dtype=dtype('int32'), name='step_type'),\n",
       " 'reward': ArraySpec(shape=(), dtype=dtype('float32'), name='reward'),\n",
       " 'discount': BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0),\n",
       " 'observation': BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])})"
      ]
     },
     "execution_count": 1336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')"
      ]
     },
     "execution_count": 1337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)"
      ]
     },
     "execution_count": 1338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.discount_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(1),\n",
       " 'reward': array(1., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.01342683, -0.15458241, -0.01943865,  0.29562202], dtype=float32)})"
      ]
     },
     "execution_count": 1339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_time_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the environment with TFPyEnvironment which supports both py and tf environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments.tf_py_environment import TFPyEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TFPyEnvironment(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.environments.tf_py_environment.TFPyEnvironment at 0x1e6c22a89d0>"
      ]
     },
     "execution_count": 1342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.04740351, -0.01980463,  0.03243716,  0.01009236]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 1343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.0477996 , -0.21537639,  0.03263901,  0.31283054]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 1344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))"
      ]
     },
     "execution_count": 1345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64))"
      ]
     },
     "execution_count": 1346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))})"
      ]
     },
     "execution_count": 1347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(), dtype=tf.float32, name='reward')"
      ]
     },
     "execution_count": 1348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)"
      ]
     },
     "execution_count": 1349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.discount_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.0477996 , -0.21537639,  0.03263901,  0.31283054]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 1350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_time_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks.q_network import QNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class QNetwork in module tf_agents.networks.q_network:\n",
      "\n",
      "class QNetwork(tf_agents.networks.network.Network)\n",
      " |  QNetwork(input_tensor_spec, action_spec, preprocessing_layers=None, preprocessing_combiner=None, conv_layer_params=None, fc_layer_params=(75, 40), dropout_layer_params=None, activation_fn=<function relu at 0x000001E6AA0D1260>, kernel_initializer=None, batch_squash=True, dtype=tf.float32, q_layer_activation_fn=None, name='QNetwork')\n",
      " |  \n",
      " |  Feed Forward network.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      QNetwork\n",
      " |      tf_agents.networks.network.Network\n",
      " |      keras.src.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      keras.src.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_tensor_spec, action_spec, preprocessing_layers=None, preprocessing_combiner=None, conv_layer_params=None, fc_layer_params=(75, 40), dropout_layer_params=None, activation_fn=<function relu at 0x000001E6AA0D1260>, kernel_initializer=None, batch_squash=True, dtype=tf.float32, q_layer_activation_fn=None, name='QNetwork')\n",
      " |      Creates an instance of `QNetwork`.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_tensor_spec: A nest of `tensor_spec.TensorSpec` representing the\n",
      " |          input observations.\n",
      " |        action_spec: A nest of `tensor_spec.BoundedTensorSpec` representing the\n",
      " |          actions.\n",
      " |        preprocessing_layers: (Optional.) A nest of `tf.keras.layers.Layer`\n",
      " |          representing preprocessing for the different observations. All of these\n",
      " |          layers must not be already built. For more details see the documentation\n",
      " |          of `networks.EncodingNetwork`.\n",
      " |        preprocessing_combiner: (Optional.) A keras layer that takes a flat list\n",
      " |          of tensors and combines them. Good options include `tf.keras.layers.Add`\n",
      " |          and `tf.keras.layers.Concatenate(axis=-1)`. This layer must not be\n",
      " |          already built. For more details see the documentation of\n",
      " |          `networks.EncodingNetwork`.\n",
      " |        conv_layer_params: Optional list of convolution layers parameters, where\n",
      " |          each item is a length-three tuple indicating (filters, kernel_size,\n",
      " |          stride).\n",
      " |        fc_layer_params: Optional list of fully_connected parameters, where each\n",
      " |          item is the number of units in the layer.\n",
      " |        dropout_layer_params: Optional list of dropout layer parameters, where\n",
      " |          each item is the fraction of input units to drop. The dropout layers are\n",
      " |          interleaved with the fully connected layers; there is a dropout layer\n",
      " |          after each fully connected layer, except if the entry in the list is\n",
      " |          None. This list must have the same length of fc_layer_params, or be\n",
      " |          None.\n",
      " |        activation_fn: Activation function, e.g. tf.keras.activations.relu.\n",
      " |        kernel_initializer: Initializer to use for the kernels of the conv and\n",
      " |          dense layers. If none is provided a default variance_scaling_initializer\n",
      " |        batch_squash: If True the outer_ranks of the observation are squashed into\n",
      " |          the batch dimension. This allow encoding networks to be used with\n",
      " |          observations with shape [BxTx...].\n",
      " |        dtype: The dtype to use by the convolution and fully connected layers.\n",
      " |        q_layer_activation_fn: Activation function for the Q layer.\n",
      " |        name: A string representing the name of the network.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `input_tensor_spec` contains more than one observation. Or\n",
      " |          if `action_spec` contains more than one action.\n",
      " |  \n",
      " |  call(self, observation, step_type=None, network_state=(), training=False)\n",
      " |      Runs the given observation through the network.\n",
      " |      \n",
      " |      Args:\n",
      " |        observation: The observation to provide to the network.\n",
      " |        step_type: The step type for the given observation. See `StepType` in\n",
      " |          time_step.py.\n",
      " |        network_state: A state tuple to pass to the network, mainly used by RNNs.\n",
      " |        training: Whether the output is being used for training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple `(logits, network_state)`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tf_agents.networks.network.Network:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      A wrapper around `Network.call`.\n",
      " |      \n",
      " |      A typical `call` method in a class subclassing `Network` will have a\n",
      " |      signature that accepts `inputs`, as well as other `*args` and `**kwargs`.\n",
      " |      `call` can optionally also accept `step_type` and `network_state`\n",
      " |      (if `state_spec != ()` is not trivial).  e.g.:\n",
      " |      \n",
      " |      ```python\n",
      " |      def call(self,\n",
      " |               inputs,\n",
      " |               step_type=None,\n",
      " |               network_state=(),\n",
      " |               training=False):\n",
      " |          ...\n",
      " |          return outputs, new_network_state\n",
      " |      ```\n",
      " |      \n",
      " |      We will validate the first argument (`inputs`)\n",
      " |      against `self.input_tensor_spec` if one is available.\n",
      " |      \n",
      " |      If a `network_state` kwarg is given it is also validated against\n",
      " |      `self.state_spec`.  Similarly, the return value of the `call` method is\n",
      " |      expected to be a tuple/list with 2 values:  `(output, new_state)`.\n",
      " |      We validate `new_state` against `self.state_spec`.\n",
      " |      \n",
      " |      If no `network_state` kwarg is given (or if empty `network_state = ()` is\n",
      " |      given, it is up to `call` to assume a proper \"empty\" state, and to\n",
      " |      emit an appropriate `output_state`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: The input to `self.call`, matching `self.input_tensor_spec`.\n",
      " |        *args: Additional arguments to `self.call`.\n",
      " |        **kwargs: Additional keyword arguments to `self.call`. These can include\n",
      " |          `network_state` and `step_type`.  `step_type` is required if the\n",
      " |          network's `call` requires it. `network_state` is required if the\n",
      " |          underlying network's `call` requires it.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple `(outputs, new_network_state)`.\n",
      " |  \n",
      " |  copy(self, **kwargs)\n",
      " |      Create a shallow copy of this network.\n",
      " |      \n",
      " |      **NOTE** Network layer weights are *never* copied.  This method recreates\n",
      " |      the `Network` instance with the same arguments it was initialized with\n",
      " |      (excepting any new kwargs).\n",
      " |      \n",
      " |      Args:\n",
      " |        **kwargs: Args to override when recreating this network.  Commonly\n",
      " |          overridden args include 'name'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A shallow copy of this network.\n",
      " |  \n",
      " |  create_variables(self, input_tensor_spec=None, **kwargs)\n",
      " |      Force creation of the network's variables.\n",
      " |      \n",
      " |      Return output specs.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_tensor_spec: (Optional).  Override or provide an input tensor spec\n",
      " |          when creating variables.\n",
      " |        **kwargs: Other arguments to `network.call()`, e.g. `training=True`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output specs - a nested spec calculated from the outputs (excluding any\n",
      " |        batch dimensions).  If any of the output elements is a tfp `Distribution`,\n",
      " |        the associated spec entry returned is a `DistributionSpec`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If no `input_tensor_spec` is provided, and the network did\n",
      " |          not provide one during construction.\n",
      " |  \n",
      " |  get_initial_state(self, batch_size=None)\n",
      " |      Returns an initial state usable by the network.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: Tensor or constant: size of the batch dimension. Can be None\n",
      " |          in which case not dimensions gets added.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A nested object of type `self.state_spec` containing properly\n",
      " |        initialized Tensors.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Args:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Args:\n",
      " |          line_length: Total length of printed lines (e.g. set this to adapt the\n",
      " |            display to different terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements in each line.\n",
      " |            If not provided, defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`. It will be called\n",
      " |            on each line of the summary. You can set it to a custom function in\n",
      " |            order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tf_agents.networks.network.Network:\n",
      " |  \n",
      " |  input_tensor_spec\n",
      " |      Returns the spec of the input to the network of type InputSpec.\n",
      " |  \n",
      " |  layers\n",
      " |      Get the list of all (nested) sub-layers used in this Network.\n",
      " |  \n",
      " |  state_spec\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
      " |      not themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be\n",
      " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
      " |      the same layer on different inputs `a` and `b`, some entries in\n",
      " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
      " |      automatically keeps track of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      The same code works in distributed training: the input to `add_loss()`\n",
      " |      is treated like a regularization loss and averaged across replicas\n",
      " |      by the training loop (both built-in `Model.fit()` and compliant custom\n",
      " |      training loops).\n",
      " |      \n",
      " |      The `add_loss` method can also be called directly on a Functional Model\n",
      " |      during construction. In this case, any loss Tensors passed to this Model\n",
      " |      must be symbolic and be able to be traced back to the model's `Input`s.\n",
      " |      These losses become part of the model's topology and are tracked in\n",
      " |      `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss\n",
      " |      references a `Variable` of one of the model's layers), you can wrap your\n",
      " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
      " |      the model's topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
      " |          losses may also be zero-argument callables which create a loss\n",
      " |          tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This\n",
      " |      is because we cannot trace the metric result tensor back to the model's\n",
      " |      inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result\n",
      " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
      " |          default using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and\n",
      " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
      " |      passed when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case,\n",
      " |      variable updates are run on the fly and thus do not need to be tracked\n",
      " |      for later execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use a `ResourceVariable` or not.\n",
      " |          See [this guide](\n",
      " |          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
      " |           for more information.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set\n",
      " |          to `AUTO` and the current `DistributionStrategy` chooses when to\n",
      " |          synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n",
      " |          must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as\n",
      " |          `ON_READ`.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call. It is invoked automatically before\n",
      " |      the first execution of `call()`.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses\n",
      " |      (at the discretion of the subclass implementer).\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  build_from_config(self, config)\n",
      " |      Builds the layer's states with the supplied config dict.\n",
      " |      \n",
      " |      By default, this method calls the `build(config[\"input_shape\"])` method,\n",
      " |      which creates weights based on the layer's input shape in the supplied\n",
      " |      config. If your config contains other information needed to load the\n",
      " |      layer's state, you should override this method.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: Dict containing the input shape associated with this layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,\n",
      " |              or structure of shape tuples / `tf.TensorShape` instances\n",
      " |              (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `tf.TensorShape` instance\n",
      " |          or structure of `tf.TensorShape` instances.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
      " |          describing how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after\n",
      " |      updating a layer weights. It can be overridden to finalize any\n",
      " |      additional layer state after a weight update.\n",
      " |      \n",
      " |      This function will be called after weights of a layer have been restored\n",
      " |      from a loaded model.\n",
      " |  \n",
      " |  get_build_config(self)\n",
      " |      Returns a dictionary with the layer's input shape.\n",
      " |      \n",
      " |      This method returns a config dict that can be used by\n",
      " |      `build_from_config(config)` to create all states (e.g. Variables and\n",
      " |      Lookup tables) needed by the layer.\n",
      " |      \n",
      " |      By default, the config only contains the input shape that the layer\n",
      " |      was built with. If you're writing a custom layer that creates state in\n",
      " |      an unusual way, you should override this method to make sure this state\n",
      " |      is already created when Keras attempts to load its value upon model\n",
      " |      loading.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict containing the input shape associated with the layer.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of\n",
      " |      dict every time it is called. The callers should make a copy of the\n",
      " |      returned dict if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with\n",
      " |      this layer as a list of NumPy arrays, which can in turn be used to load\n",
      " |      state into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  load_own_variables(self, store)\n",
      " |      Loads the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is loaded upon calling `keras.models.load_model()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict from which the state of the model will be loaded.\n",
      " |  \n",
      " |  save_own_variables(self, store)\n",
      " |      Saves the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is saved upon calling `model.save()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict where the state of the model will be saved.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from tf_agents.networks.network._NetworkMeta\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which\n",
      " |      causes computations and the output to be in the compute dtype as well.\n",
      " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
      " |      have to insert these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision\n",
      " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
      " |      output will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is\n",
      " |      accessed, so it is eager safe: accessing `losses` under a\n",
      " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
      " |      variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics attached to the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are\n",
      " |      expected to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to\n",
      " |      enable the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
      " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a\n",
      " |      nicely-formatted error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from tf_agents.networks.network._NetworkMeta\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(QNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_net = QNetwork(env.observation_spec(), env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.agents.dqn.dqn_agent import DqnAgent\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DqnAgent in module tf_agents.agents.dqn.dqn_agent:\n",
      "\n",
      "class DqnAgent(tf_agents.agents.tf_agent.TFAgent)\n",
      " |  DqnAgent(time_step_spec: tf_agents.trajectories.time_step.TimeStep, action_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')]], q_network: tf_agents.networks.network.Network, optimizer: Union[keras.src.optimizers.optimizer.Optimizer, tensorflow.python.training.optimizer.Optimizer], observation_and_action_constraint_splitter: Optional[Callable[[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]], Iterable[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]]]] = None, epsilon_greedy: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = 0.1, n_step_update: int = 1, boltzmann_temperature: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = None, emit_log_probability: bool = False, target_q_network: Optional[tf_agents.networks.network.Network] = None, target_update_tau: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, target_update_period: int = 1, td_errors_loss_fn: Optional[Callable[..., Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor]]] = None, gamma: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, reward_scale_factor: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, gradient_clipping: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, NoneType] = None, debug_summaries: bool = False, summarize_grads_and_vars: bool = False, train_step_counter: Optional[tensorflow.python.ops.variables.Variable] = None, training_data_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], NoneType] = None, name: Optional[str] = None)\n",
      " |  \n",
      " |  A DQN Agent.\n",
      " |  \n",
      " |  Implements the DQN algorithm from\n",
      " |  \n",
      " |  \"Human level control through deep reinforcement learning\"\n",
      " |    Mnih et al., 2015\n",
      " |    https://deepmind.com/research/dqn/\n",
      " |  \n",
      " |  This agent also implements n-step updates. See \"Rainbow: Combining\n",
      " |  Improvements in Deep Reinforcement Learning\" by Hessel et al., 2017, for a\n",
      " |  discussion on its benefits: https://arxiv.org/abs/1710.02298\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DqnAgent\n",
      " |      tf_agents.agents.tf_agent.TFAgent\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, time_step_spec: tf_agents.trajectories.time_step.TimeStep, action_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')]], q_network: tf_agents.networks.network.Network, optimizer: Union[keras.src.optimizers.optimizer.Optimizer, tensorflow.python.training.optimizer.Optimizer], observation_and_action_constraint_splitter: Optional[Callable[[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]], Iterable[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]]]] = None, epsilon_greedy: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = 0.1, n_step_update: int = 1, boltzmann_temperature: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = None, emit_log_probability: bool = False, target_q_network: Optional[tf_agents.networks.network.Network] = None, target_update_tau: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, target_update_period: int = 1, td_errors_loss_fn: Optional[Callable[..., Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor]]] = None, gamma: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, reward_scale_factor: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, gradient_clipping: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, NoneType] = None, debug_summaries: bool = False, summarize_grads_and_vars: bool = False, train_step_counter: Optional[tensorflow.python.ops.variables.Variable] = None, training_data_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], NoneType] = None, name: Optional[str] = None)\n",
      " |      Creates a DQN Agent.\n",
      " |      \n",
      " |      Args:\n",
      " |        time_step_spec: A `TimeStep` spec of the expected time_steps.\n",
      " |        action_spec: A nest of BoundedTensorSpec representing the actions.\n",
      " |        q_network: A `tf_agents.network.Network` to be used by the agent. The\n",
      " |          network will be called with `call(observation, step_type)` and should\n",
      " |          emit logits over the action space.\n",
      " |        optimizer: The optimizer to use for training.\n",
      " |        observation_and_action_constraint_splitter: A function used to process\n",
      " |          observations with action constraints. These constraints can indicate,\n",
      " |          for example, a mask of valid/invalid actions for a given state of the\n",
      " |          environment. The function takes in a full observation and returns a\n",
      " |          tuple consisting of 1) the part of the observation intended as input to\n",
      " |          the network and 2) the constraint. An example\n",
      " |          `observation_and_action_constraint_splitter` could be as simple as: ```\n",
      " |          def observation_and_action_constraint_splitter(observation): return\n",
      " |          observation['network_input'], observation['constraint'] ``` *Note*: when\n",
      " |          using `observation_and_action_constraint_splitter`, make sure the\n",
      " |          provided `q_network` is compatible with the network-specific half of the\n",
      " |          output of the `observation_and_action_constraint_splitter`. In\n",
      " |          particular, `observation_and_action_constraint_splitter` will be called\n",
      " |          on the observation before passing to the network. If\n",
      " |          `observation_and_action_constraint_splitter` is None, action constraints\n",
      " |          are not applied.\n",
      " |        epsilon_greedy: probability of choosing a random action in the default\n",
      " |          epsilon-greedy collect policy (used only if a wrapper is not provided to\n",
      " |          the collect_policy method). Only one of epsilon_greedy and\n",
      " |          boltzmann_temperature should be provided.\n",
      " |        n_step_update: The number of steps to consider when computing TD error and\n",
      " |          TD loss. Defaults to single-step updates. Note that this requires the\n",
      " |          user to call train on Trajectory objects with a time dimension of\n",
      " |          `n_step_update + 1`. However, note that we do not yet support\n",
      " |          `n_step_update > 1` in the case of RNNs (i.e., non-empty\n",
      " |          `q_network.state_spec`).\n",
      " |        boltzmann_temperature: Temperature value to use for Boltzmann sampling of\n",
      " |          the actions during data collection. The closer to 0.0, the higher the\n",
      " |          probability of choosing the best action. Only one of epsilon_greedy and\n",
      " |          boltzmann_temperature should be provided.\n",
      " |        emit_log_probability: Whether policies emit log probabilities or not.\n",
      " |        target_q_network: (Optional.)  A `tf_agents.network.Network` to be used as\n",
      " |          the target network during Q learning.  Every `target_update_period`\n",
      " |          train steps, the weights from `q_network` are copied (possibly with\n",
      " |          smoothing via `target_update_tau`) to `target_q_network`.  If\n",
      " |          `target_q_network` is not provided, it is created by making a copy of\n",
      " |          `q_network`, which initializes a new network with the same structure and\n",
      " |          its own layers and weights.  Network copying is performed via the\n",
      " |          `Network.copy` superclass method, and may inadvertently lead to the\n",
      " |          resulting network to share weights with the original.  This can happen\n",
      " |          if, for example, the original network accepted a pre-built Keras layer\n",
      " |          in its `__init__`, or accepted a Keras layer that wasn't built, but\n",
      " |          neglected to create a new copy.  In these cases, it is up to you to\n",
      " |          provide a target Network having weights that are not shared with the\n",
      " |          original `q_network`. If you provide a `target_q_network` that shares\n",
      " |          any weights with `q_network`, a warning will be logged but no exception\n",
      " |          is thrown.  Note; shallow copies of Keras layers may be built via the\n",
      " |          code ```python new_layer =\n",
      " |          type(layer).from_config(layer.get_config())```\n",
      " |        target_update_tau: Factor for soft update of the target networks.\n",
      " |        target_update_period: Period for soft update of the target networks.\n",
      " |        td_errors_loss_fn: A function for computing the TD errors loss. If None, a\n",
      " |          default value of element_wise_huber_loss is used. This function takes as\n",
      " |          input the target and the estimated Q values and returns the loss for\n",
      " |          each element of the batch.\n",
      " |        gamma: A discount factor for future rewards.\n",
      " |        reward_scale_factor: Multiplicative scale for the reward.\n",
      " |        gradient_clipping: Norm length to clip gradients.\n",
      " |        debug_summaries: A bool to gather debug summaries.\n",
      " |        summarize_grads_and_vars: If True, gradient and network variable summaries\n",
      " |          will be written during training.\n",
      " |        train_step_counter: An optional counter to increment every time the train\n",
      " |          op is run.  Defaults to the global_step.\n",
      " |        training_data_spec: A nest of TensorSpec specifying the structure of data\n",
      " |          the train() function expects. If None, defaults to the trajectory_spec\n",
      " |          of the collect_policy.\n",
      " |        name: The name of this agent. All variables in this module will fall under\n",
      " |          that name. Defaults to the class name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `action_spec` contains more than one action or action\n",
      " |          spec minimum is not equal to 0.\n",
      " |        ValueError: If the q networks do not emit floating point outputs with\n",
      " |          inner shape matching `action_spec`.\n",
      " |        NotImplementedError: If `q_network` has non-empty `state_spec` (i.e., an\n",
      " |          RNN is provided) and `n_step_update > 1`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tf_agents.agents.tf_agent.TFAgent:\n",
      " |  \n",
      " |  initialize(self) -> Optional[tensorflow.python.framework.ops.Operation]\n",
      " |      Initializes the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An operation that can be used to initialize the agent.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  loss(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], weights: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, NoneType] = None, training: bool = False, **kwargs) -> tf_agents.agents.tf_agent.LossInfo\n",
      " |      Gets loss from the agent.\n",
      " |      \n",
      " |      If the user calls this from _train, it must be in a `tf.GradientTape` scope\n",
      " |      in order to apply gradients to trainable variables.\n",
      " |      If intermediate gradient steps are needed, _loss and _train will return\n",
      " |      different values since _loss only supports updating all gradients at once\n",
      " |      after all losses have been calculated.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: A batch of experience data in the form of a `Trajectory`. The\n",
      " |          structure of `experience` must match that of `self.training_data_spec`.\n",
      " |          All tensors in `experience` must be shaped `[batch, time, ...]` where\n",
      " |          `time` must be equal to `self.train_step_length` if that property is not\n",
      " |          `None`.\n",
      " |        weights: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`,\n",
      " |          containing weights to be used when calculating the total train loss.\n",
      " |          Weights are typically multiplied elementwise against the per-batch loss,\n",
      " |          but the implementation is up to the Agent.\n",
      " |        training: Explicit argument to pass to `loss`. This typically affects\n",
      " |          network computation paths like dropout and batch normalization.\n",
      " |        **kwargs: Any additional data as args to `loss`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `LossInfo` loss tuple containing loss and info tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  post_process_policy(self) -> tf_agents.policies.tf_policy.TFPolicy\n",
      " |      Post process policies after training.\n",
      " |      \n",
      " |      The policies of some agents require expensive post processing after training\n",
      " |      before they can be used. e.g. A Recommender agent might require rebuilding\n",
      " |      an index of actions. For such agents, this method will return a post\n",
      " |      processed version of the policy. The post processing may either update the\n",
      " |      existing policies in place or create a new policy, depnding on the agent.\n",
      " |      The default implementation for agents that do not want to override this\n",
      " |      method is to return agent.policy.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The post processed policy.\n",
      " |  \n",
      " |  preprocess_sequence(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]]) -> Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]]\n",
      " |      Defines preprocess_sequence function to be fed into replay buffers.\n",
      " |      \n",
      " |      This defines how we preprocess the collected data before training.\n",
      " |      Defaults to pass through for most agents.\n",
      " |      Structure of `experience` must match that of `self.collect_data_spec`.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: a `Trajectory` shaped [batch, time, ...] or [time, ...] which\n",
      " |          represents the collected experience data.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A post processed `Trajectory` with the same shape as the input.\n",
      " |  \n",
      " |  train(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], weights: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, NoneType] = None, **kwargs) -> tf_agents.agents.tf_agent.LossInfo\n",
      " |      Trains the agent.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: A batch of experience data in the form of a `Trajectory`. The\n",
      " |          structure of `experience` must match that of `self.training_data_spec`.\n",
      " |          All tensors in `experience` must be shaped `[batch, time, ...]` where\n",
      " |          `time` must be equal to `self.train_step_length` if that property is not\n",
      " |          `None`.\n",
      " |        weights: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`,\n",
      " |          containing weights to be used when calculating the total train loss.\n",
      " |          Weights are typically multiplied elementwise against the per-batch loss,\n",
      " |          but the implementation is up to the Agent.\n",
      " |        **kwargs: Any additional data to pass to the subclass.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `LossInfo` loss tuple containing loss and info tensors.\n",
      " |          - In eager mode, the loss values are first calculated, then a train step\n",
      " |            is performed before they are returned.\n",
      " |          - In graph mode, executing any or all of the loss tensors\n",
      " |            will first calculate the loss value(s), then perform a train step,\n",
      " |            and return the pre-train-step `LossInfo`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tf_agents.agents.tf_agent.TFAgent:\n",
      " |  \n",
      " |  action_spec\n",
      " |      TensorSpec describing the action produced by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An single BoundedTensorSpec, or a nested dict, list or tuple of\n",
      " |        `BoundedTensorSpec` objects, which describe the shape and\n",
      " |        dtype of each action Tensor.\n",
      " |  \n",
      " |  collect_data_context\n",
      " |  \n",
      " |  collect_data_spec\n",
      " |      Returns a `Trajectory` spec, as expected by the `collect_policy`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Trajectory` spec.\n",
      " |  \n",
      " |  collect_policy\n",
      " |      Return a policy that can be used to collect data from the environment.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf_policy.TFPolicy` object.\n",
      " |  \n",
      " |  data_context\n",
      " |  \n",
      " |  debug_summaries\n",
      " |  \n",
      " |  policy\n",
      " |      Return the current policy held by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf_policy.TFPolicy` object.\n",
      " |  \n",
      " |  summaries_enabled\n",
      " |  \n",
      " |  summarize_grads_and_vars\n",
      " |  \n",
      " |  time_step_spec\n",
      " |      Describes the `TimeStep` tensors expected by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `TimeStep` namedtuple with `TensorSpec` objects instead of Tensors,\n",
      " |        which describe the shape, dtype and name of each tensor.\n",
      " |  \n",
      " |  train_sequence_length\n",
      " |      The number of time steps needed in experience tensors passed to `train`.\n",
      " |      \n",
      " |      Train requires experience to be a `Trajectory` containing tensors shaped\n",
      " |      `[B, T, ...]`.  This argument describes the value of `T` required.\n",
      " |      \n",
      " |      For example, for non-RNN DQN training, `T=2` because DQN requires single\n",
      " |      transitions.\n",
      " |      \n",
      " |      If this value is `None`, then `train` can handle an unknown `T` (it can be\n",
      " |      determined at runtime from the data).  Most RNN-based agents fall into\n",
      " |      this category.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The number of time steps needed in experience tensors passed to `train`.\n",
      " |        May be `None` to mean no constraint.\n",
      " |  \n",
      " |  train_step_counter\n",
      " |  \n",
      " |  training_data_spec\n",
      " |      Returns a trajectory spec, as expected by the train() function.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from abc.ABCMeta\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  variables\n",
      " |      Sequence of variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.trackable.autotrackable.AutoTrackable:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DqnAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "loss = MeanSquaredError('none', 'mean_squared_error')\n",
    "loss_fn = loss.call\n",
    "discount_factor = 0.95\n",
    "epsilon_fn = PolynomialDecay(\n",
    "    initial_learning_rate=1.0,\n",
    "    decay_steps=1600,\n",
    "    end_learning_rate=0.0,\n",
    "    power=1\n",
    "    )\n",
    "target_model_update = 50\n",
    "train_step = tf.Variable(0)\n",
    "\n",
    "agent = DqnAgent(\n",
    "    env.time_step_spec(),\n",
    "    env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    gamma=discount_factor,\n",
    "    td_errors_loss_fn=loss_fn,\n",
    "    epsilon_greedy=lambda:epsilon_fn(train_step),\n",
    "    train_step_counter=train_step,\n",
    "    target_update_period=target_model_update,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))})"
      ]
     },
     "execution_count": 1357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Replay Buffer to store experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.replay_buffers.tf_uniform_replay_buffer import TFUniformReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32)),\n",
       " 'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})"
      ]
     },
     "execution_count": 1360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = TFUniformReplayBuffer(\n",
    "    data_spec= agent.collect_data_spec,\n",
    "    batch_size= env.batch_size,\n",
    "    max_length= 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an observer to write into the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer_observer = replay_buffer.add_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer at 0x1e6c1c5d590>"
      ]
     },
     "execution_count": 1363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ReplayBuffer.add_batch of <tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer object at 0x000001E6C1C5D590>>"
      ]
     },
     "execution_count": 1364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer_observer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Driver that explores environment using a given policy, collects experience and broadcast them to observer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.greedy_policy.GreedyPolicy at 0x1e6c2280390>"
      ]
     },
     "execution_count": 1366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_driver = DynamicStepDriver(\n",
    "    env=env,\n",
    "    policy= agent.collect_policy,\n",
    "    observers= [replay_buffer_observer],\n",
    "    num_steps=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a driver to just fill the replay buffer with some experiences with a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_collect_policy = RandomTFPolicy(env.time_step_spec(), env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.random_tf_policy.RandomTFPolicy at 0x1e6c1c73510>"
      ]
     },
     "execution_count": 1370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_driver = DynamicStepDriver(\n",
    "    env,\n",
    "    initial_collect_policy,\n",
    "    [replay_buffer_observer],\n",
    "    num_steps=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time_step, final_policy_state = initial_driver.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.05271898,  0.20753057, -0.17364648, -0.65162116]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 1373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 1374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_policy_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset of sample a batch of trajectories for agent to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.trajectories.trajectory import to_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories, buffer_info = replay_buffer.get_next(sample_batch_size=2, num_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[-0.09331799, -0.4235372 ,  0.04876883,  0.3151456 ],\n",
       "        [-0.10178874, -0.22914264,  0.05507175,  0.03823283],\n",
       "        [-0.10637159, -0.03485189,  0.0558364 , -0.23657854]],\n",
       "\n",
       "       [[ 0.01602175,  0.17876667,  0.00213026, -0.19927166],\n",
       "        [ 0.01959709,  0.3738581 , -0.00185518, -0.49128184],\n",
       "        [ 0.02707425,  0.56900615, -0.01168081, -0.7845489 ]]],\n",
       "      dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 0]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>})"
      ]
     },
     "execution_count": 1377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BufferInfo(ids=<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "array([[148, 149, 150],\n",
       "       [272, 273, 274]], dtype=int64)>, probabilities=<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00096061, 0.00096061], dtype=float32)>)"
      ]
     },
     "execution_count": 1378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps, action_steps, next_time_steps = to_transition(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(2, 2, 4), dtype=float32, numpy=\n",
       "array([[[-0.09331799, -0.4235372 ,  0.04876883,  0.3151456 ],\n",
       "        [-0.10178874, -0.22914264,  0.05507175,  0.03823283]],\n",
       "\n",
       "       [[ 0.01602175,  0.17876667,  0.00213026, -0.19927166],\n",
       "        [ 0.01959709,  0.3738581 , -0.00185518, -0.49128184]]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 1380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=<tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1]], dtype=int64)>, state=(), info=())"
      ]
     },
     "execution_count": 1381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=128,\n",
    "    num_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(Trajectory(\n",
       "{'step_type': TensorSpec(shape=(128, 2), dtype=tf.int32, name=None),\n",
       " 'observation': TensorSpec(shape=(128, 2, 4), dtype=tf.float32, name=None),\n",
       " 'action': TensorSpec(shape=(128, 2), dtype=tf.int64, name=None),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(128, 2), dtype=tf.int32, name=None),\n",
       " 'reward': TensorSpec(shape=(128, 2), dtype=tf.float32, name=None),\n",
       " 'discount': TensorSpec(shape=(128, 2), dtype=tf.float32, name=None)}), BufferInfo(ids=TensorSpec(shape=(128, 2), dtype=tf.int64, name=None), probabilities=TensorSpec(shape=(128,), dtype=tf.float32, name=None)))>"
      ]
     },
     "execution_count": 1383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x1e6b02ea410>"
      ]
     },
     "execution_count": 1385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]])>,\n",
       "  'observation': <tf.Tensor: shape=(128, 2, 4), dtype=float32, numpy=\n",
       " array([[[ 0.02559637, -0.4085926 , -0.01897375,  0.5800341 ],\n",
       "         [ 0.01742451, -0.21321   , -0.00737307,  0.28143495]],\n",
       " \n",
       "        [[ 0.04557235,  0.24018952, -0.03487691, -0.31450823],\n",
       "         [ 0.05037614,  0.0455813 , -0.04116707, -0.03302516]],\n",
       " \n",
       "        [[ 0.04368636,  0.16837542, -0.01266678, -0.1109917 ],\n",
       "         [ 0.04705387,  0.36367655, -0.01488662, -0.40764385]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.00776069, -0.22890905, -0.01274361,  0.32418194],\n",
       "         [-0.01233888, -0.03360798, -0.00625997,  0.02750761]],\n",
       " \n",
       "        [[-0.01485436, -0.5880396 ,  0.04419546,  0.9601071 ],\n",
       "         [-0.02661515, -0.39353868,  0.06339761,  0.6816299 ]],\n",
       " \n",
       "        [[-0.04823143, -0.00605229,  0.0065039 , -0.01293694],\n",
       "         [-0.04835248,  0.18897578,  0.00624516, -0.30356073]]],\n",
       "       dtype=float32)>,\n",
       "  'action': <tf.Tensor: shape=(128, 2), dtype=int64, numpy=\n",
       " array([[1, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1]], dtype=int64)>,\n",
       "  'policy_info': (),\n",
       "  'next_step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]])>,\n",
       "  'reward': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)>,\n",
       "  'discount': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)>}),\n",
       " BufferInfo(ids=<tf.Tensor: shape=(128, 2), dtype=int64, numpy=\n",
       " array([[ 649,  650],\n",
       "        [ 586,  587],\n",
       "        [ 560,  561],\n",
       "        [ 196,  197],\n",
       "        [ 497,  498],\n",
       "        [ 685,  686],\n",
       "        [ 343,  344],\n",
       "        [1009, 1010],\n",
       "        [1015, 1016],\n",
       "        [ 807,  808],\n",
       "        [  57,   58],\n",
       "        [ 899,  900],\n",
       "        [ 781,  782],\n",
       "        [ 463,  464],\n",
       "        [ 657,  658],\n",
       "        [ 668,  669],\n",
       "        [ 105,  106],\n",
       "        [ 377,  378],\n",
       "        [ 986,  987],\n",
       "        [ 145,  146],\n",
       "        [ 447,  448],\n",
       "        [ 357,  358],\n",
       "        [  31,   32],\n",
       "        [ 460,  461],\n",
       "        [ 800,  801],\n",
       "        [ 697,  698],\n",
       "        [ 432,  433],\n",
       "        [ 422,  423],\n",
       "        [ 113,  114],\n",
       "        [ 152,  153],\n",
       "        [ 674,  675],\n",
       "        [ 389,  390],\n",
       "        [ 733,  734],\n",
       "        [  75,   76],\n",
       "        [ 164,  165],\n",
       "        [ 680,  681],\n",
       "        [ 829,  830],\n",
       "        [ 931,  932],\n",
       "        [ 245,  246],\n",
       "        [ 592,  593],\n",
       "        [ 503,  504],\n",
       "        [ 279,  280],\n",
       "        [  61,   62],\n",
       "        [ 413,  414],\n",
       "        [  12,   13],\n",
       "        [ 772,  773],\n",
       "        [ 915,  916],\n",
       "        [ 142,  143],\n",
       "        [ 718,  719],\n",
       "        [ 529,  530],\n",
       "        [ 624,  625],\n",
       "        [ 130,  131],\n",
       "        [ 619,  620],\n",
       "        [ 714,  715],\n",
       "        [ 336,  337],\n",
       "        [ 410,  411],\n",
       "        [1032, 1033],\n",
       "        [ 296,  297],\n",
       "        [ 294,  295],\n",
       "        [  87,   88],\n",
       "        [ 755,  756],\n",
       "        [ 524,  525],\n",
       "        [ 742,  743],\n",
       "        [ 800,  801],\n",
       "        [ 325,  326],\n",
       "        [   7,    8],\n",
       "        [ 958,  959],\n",
       "        [ 618,  619],\n",
       "        [  70,   71],\n",
       "        [ 220,  221],\n",
       "        [  66,   67],\n",
       "        [ 866,  867],\n",
       "        [ 795,  796],\n",
       "        [ 738,  739],\n",
       "        [ 289,  290],\n",
       "        [ 362,  363],\n",
       "        [ 347,  348],\n",
       "        [ 114,  115],\n",
       "        [ 824,  825],\n",
       "        [ 406,  407],\n",
       "        [ 528,  529],\n",
       "        [ 941,  942],\n",
       "        [ 222,  223],\n",
       "        [ 943,  944],\n",
       "        [ 736,  737],\n",
       "        [ 482,  483],\n",
       "        [ 623,  624],\n",
       "        [ 246,  247],\n",
       "        [ 774,  775],\n",
       "        [ 953,  954],\n",
       "        [ 342,  343],\n",
       "        [  46,   47],\n",
       "        [ 377,  378],\n",
       "        [ 784,  785],\n",
       "        [ 124,  125],\n",
       "        [ 505,  506],\n",
       "        [ 599,  600],\n",
       "        [ 913,  914],\n",
       "        [ 696,  697],\n",
       "        [ 608,  609],\n",
       "        [ 660,  661],\n",
       "        [ 977,  978],\n",
       "        [ 559,  560],\n",
       "        [ 214,  215],\n",
       "        [  22,   23],\n",
       "        [ 510,  511],\n",
       "        [ 537,  538],\n",
       "        [ 607,  608],\n",
       "        [ 192,  193],\n",
       "        [ 969,  970],\n",
       "        [ 366,  367],\n",
       "        [ 114,  115],\n",
       "        [ 847,  848],\n",
       "        [ 460,  461],\n",
       "        [ 120,  121],\n",
       "        [ 129,  130],\n",
       "        [ 432,  433],\n",
       "        [ 680,  681],\n",
       "        [ 243,  244],\n",
       "        [ 962,  963],\n",
       "        [ 384,  385],\n",
       "        [ 168,  169],\n",
       "        [ 542,  543],\n",
       "        [   1,    2],\n",
       "        [ 348,  349],\n",
       "        [ 291,  292],\n",
       "        [ 489,  490],\n",
       "        [ 103,  104]], dtype=int64)>, probabilities=<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969, 0.00095969, 0.00095969,\n",
       "        0.00095969, 0.00095969, 0.00095969], dtype=float32)>))"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [0, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(128, 2, 4), dtype=float32, numpy=\n",
       "array([[[-0.08468142, -0.5716603 ,  0.1414329 ,  1.0943165 ],\n",
       "        [-0.09611463, -0.37865567,  0.16331923,  0.849143  ]],\n",
       "\n",
       "       [[ 0.01620368, -0.01956864, -0.00324073,  0.02139703],\n",
       "        [ 0.01581231,  0.17559963, -0.00281279, -0.27230662]],\n",
       "\n",
       "       [[-0.15294015, -0.61526835,  0.19853339,  1.130684  ],\n",
       "        [-0.16524552, -0.4232201 ,  0.22114708,  0.9062564 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.07648121, -0.21164869, -0.12049641,  0.04612929],\n",
       "        [ 0.07224824, -0.01502345, -0.11957382, -0.28201026]],\n",
       "\n",
       "       [[ 0.07604447,  1.4080479 , -0.06765957, -1.968085  ],\n",
       "        [ 0.10420543,  1.6038163 , -0.10702127, -2.2809424 ]],\n",
       "\n",
       "       [[-0.0718582 , -0.0054961 ,  0.09196546,  0.12495784],\n",
       "        [-0.07196812,  0.18819623,  0.09446461, -0.13735312]]],\n",
       "      dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(128, 2), dtype=int64, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>})"
      ]
     },
     "execution_count": 1387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.utils.common import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DynamicStepDriver.run of <tf_agents.drivers.dynamic_step_driver.DynamicStepDriver object at 0x000001E6C32CFF90>>"
      ]
     },
     "execution_count": 1389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x000001E6C1F69E50>>"
      ]
     },
     "execution_count": 1390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_driver.run = function(collect_driver.run)\n",
    "agent.train = function(agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x1e6bdae5f90>"
      ]
     },
     "execution_count": 1392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x1e6c33148d0>"
      ]
     },
     "execution_count": 1393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 1394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_policy.get_initial_state(env.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       "  'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       " array([[-0.11005878, -0.7993053 ,  0.09156413,  1.2002417 ]],\n",
       "       dtype=float32)>}),\n",
       " ())"
      ]
     },
     "execution_count": 1395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run(None, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories, buffer_info = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       "array([[0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 2],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(128, 2, 4), dtype=float32, numpy=\n",
       "array([[[ 0.03259517, -0.01903432,  0.01448839, -0.03446842],\n",
       "        [ 0.03221449,  0.1758769 ,  0.01379902, -0.3225451 ]],\n",
       "\n",
       "       [[-0.04810803,  0.21652555,  0.03944265, -0.23500675],\n",
       "        [-0.04377752,  0.02086291,  0.03474252,  0.06985208]],\n",
       "\n",
       "       [[-0.03232864,  0.41352776,  0.06981729, -0.3995717 ],\n",
       "        [-0.02405808,  0.6075934 ,  0.06182586, -0.6694514 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.01188136,  0.04431742,  0.04516524,  0.03630082],\n",
       "        [-0.01099501,  0.23876357,  0.04589126, -0.2417969 ]],\n",
       "\n",
       "       [[-0.12215704,  1.190642  , -0.11475048, -2.2660453 ],\n",
       "        [-0.0983442 ,  0.99676377, -0.16007139, -2.0108032 ]],\n",
       "\n",
       "       [[-0.0130469 ,  0.17556871,  0.02333417, -0.2697523 ],\n",
       "        [-0.00953553, -0.01987832,  0.01793912,  0.03019808]]],\n",
       "      dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(128, 2), dtype=int64, numpy=\n",
       "array([[1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>})"
      ]
     },
     "execution_count": 1397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32)),\n",
       " 'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})"
      ]
     },
     "execution_count": 1398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x000001E6C1F69E50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LossInfo(loss=<tf.Tensor: shape=(), dtype=float32, numpy=0.97520185>, extra=DqnLossInfo(td_loss=<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 0.       , 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 0.       , 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 0.       , 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 0.       , 0.       , 1.0148442,\n",
       "       1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442, 1.0148442,\n",
       "       1.0148442, 1.0148442], dtype=float32)>, td_error=<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([ 1.0077926,  1.0042635,  1.041354 ,  1.0111628,  1.0312346,\n",
       "        1.0112704,  1.0250587,  1.0109366,  1.0189284,  1.017443 ,\n",
       "        1.0269854,  1.0081887,  1.0264348,  1.0149695,  1.0117478,\n",
       "        1.0335755,  1.0097712,  1.0223296,  1.0090358,  1.0108529,\n",
       "        1.02396  ,  1.0299977,  0.       ,  1.026092 ,  1.0169263,\n",
       "        1.0110348,  1.0265291,  1.024168 ,  1.018626 ,  1.0244128,\n",
       "        1.0250587,  1.0262828,  1.0239451,  1.0392058,  1.0220954,\n",
       "        1.1409341,  1.2346134,  1.0845981,  1.0311117,  1.0090294,\n",
       "        1.0250587,  1.024782 ,  1.0154501,  1.0270227,  1.0378498,\n",
       "        1.014288 ,  1.0458735,  1.0114423,  1.2301283,  1.0064131,\n",
       "        1.0310179,  1.024782 ,  1.0181416,  1.0270174,  1.0218202,\n",
       "        1.0268972,  1.0111753,  1.0073227,  1.0240527,  1.0154049,\n",
       "        1.0137204,  1.0220665,  1.0261934,  1.027535 ,  1.0294963,\n",
       "        1.0223296,  1.0086678,  1.0244925,  1.0071808,  1.0223019,\n",
       "        1.0109156,  1.0190059,  1.0788356,  1.0675087,  1.1950884,\n",
       "        1.0114409,  1.0151135,  1.0266758,  1.0258044,  1.0084707,\n",
       "        1.0099137,  1.0261633,  1.005985 ,  1.0326434,  1.0081887,\n",
       "        1.0070838,  1.0249712,  1.0129975, -0.       ,  1.038999 ,\n",
       "        1.0209664,  1.0212188,  1.0059634,  0.       ,  1.0106778,\n",
       "        1.0078971,  1.0126855,  1.025832 ,  1.0092484,  1.0255426,\n",
       "        1.0266982,  1.0029798,  1.0257038,  1.0038542,  1.0114249,\n",
       "        1.0119886,  1.0065467,  1.0122341,  1.027795 ,  1.0286169,\n",
       "        1.02013  ,  1.0069277,  1.0261116,  1.0322236,  1.0464238,\n",
       "        1.0170655,  1.0078416,  0.       , -0.       ,  1.0051236,\n",
       "        1.0119143,  1.0090008,  1.0072703,  1.083428 ,  1.0089897,\n",
       "        1.0153234,  1.0428385,  1.0106568], dtype=float32)>))"
      ]
     },
     "execution_count": 1400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
