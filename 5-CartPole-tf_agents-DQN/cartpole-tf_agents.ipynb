{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the TF Agents to train the CartPole environment with DQN.\n",
    "TF Agents package makes the implementation of RL algo easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tf_agents\\typing\\types.py:114: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.environments import suite_gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = suite_gym.load(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.environments.wrappers.TimeLimit at 0x1560279eb90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<OrderEnforcing<CartPoleEnv<CartPole-v1>>>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.03297429, -0.01906034, -0.03026932, -0.04020157], dtype=float32)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(1),\n",
       " 'reward': array(1., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.03259308, -0.21373545, -0.03107335,  0.24277951], dtype=float32)})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore Environment Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': ArraySpec(shape=(), dtype=dtype('int32'), name='step_type'),\n",
       " 'reward': ArraySpec(shape=(), dtype=dtype('float32'), name='reward'),\n",
       " 'discount': BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0),\n",
       " 'observation': BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.discount_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(1),\n",
       " 'reward': array(1., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.03259308, -0.21373545, -0.03107335,  0.24277951], dtype=float32)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_time_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the environment with TFPyEnvironment which supports both py and tf environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments.tf_py_environment import TFPyEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TFPyEnvironment(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.environments.tf_py_environment.TFPyEnvironment at 0x15603843590>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.02358962,  0.03141514, -0.03042728,  0.04864902]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.02296132, -0.1632576 , -0.0294543 ,  0.33157873]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(), dtype=tf.float32, name='reward')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.discount_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.02296132, -0.1632576 , -0.0294543 ,  0.33157873]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_time_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks.q_network import QNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class QNetwork in module tf_agents.networks.q_network:\n",
      "\n",
      "class QNetwork(tf_agents.networks.network.Network)\n",
      " |  QNetwork(input_tensor_spec, action_spec, preprocessing_layers=None, preprocessing_combiner=None, conv_layer_params=None, fc_layer_params=(75, 40), dropout_layer_params=None, activation_fn=<function relu at 0x000001560075E5C0>, kernel_initializer=None, batch_squash=True, dtype=tf.float32, q_layer_activation_fn=None, name='QNetwork')\n",
      " |  \n",
      " |  Feed Forward network.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      QNetwork\n",
      " |      tf_agents.networks.network.Network\n",
      " |      keras.src.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      keras.src.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_tensor_spec, action_spec, preprocessing_layers=None, preprocessing_combiner=None, conv_layer_params=None, fc_layer_params=(75, 40), dropout_layer_params=None, activation_fn=<function relu at 0x000001560075E5C0>, kernel_initializer=None, batch_squash=True, dtype=tf.float32, q_layer_activation_fn=None, name='QNetwork')\n",
      " |      Creates an instance of `QNetwork`.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_tensor_spec: A nest of `tensor_spec.TensorSpec` representing the\n",
      " |          input observations.\n",
      " |        action_spec: A nest of `tensor_spec.BoundedTensorSpec` representing the\n",
      " |          actions.\n",
      " |        preprocessing_layers: (Optional.) A nest of `tf.keras.layers.Layer`\n",
      " |          representing preprocessing for the different observations. All of these\n",
      " |          layers must not be already built. For more details see the documentation\n",
      " |          of `networks.EncodingNetwork`.\n",
      " |        preprocessing_combiner: (Optional.) A keras layer that takes a flat list\n",
      " |          of tensors and combines them. Good options include `tf.keras.layers.Add`\n",
      " |          and `tf.keras.layers.Concatenate(axis=-1)`. This layer must not be\n",
      " |          already built. For more details see the documentation of\n",
      " |          `networks.EncodingNetwork`.\n",
      " |        conv_layer_params: Optional list of convolution layers parameters, where\n",
      " |          each item is a length-three tuple indicating (filters, kernel_size,\n",
      " |          stride).\n",
      " |        fc_layer_params: Optional list of fully_connected parameters, where each\n",
      " |          item is the number of units in the layer.\n",
      " |        dropout_layer_params: Optional list of dropout layer parameters, where\n",
      " |          each item is the fraction of input units to drop. The dropout layers are\n",
      " |          interleaved with the fully connected layers; there is a dropout layer\n",
      " |          after each fully connected layer, except if the entry in the list is\n",
      " |          None. This list must have the same length of fc_layer_params, or be\n",
      " |          None.\n",
      " |        activation_fn: Activation function, e.g. tf.keras.activations.relu.\n",
      " |        kernel_initializer: Initializer to use for the kernels of the conv and\n",
      " |          dense layers. If none is provided a default variance_scaling_initializer\n",
      " |        batch_squash: If True the outer_ranks of the observation are squashed into\n",
      " |          the batch dimension. This allow encoding networks to be used with\n",
      " |          observations with shape [BxTx...].\n",
      " |        dtype: The dtype to use by the convolution and fully connected layers.\n",
      " |        q_layer_activation_fn: Activation function for the Q layer.\n",
      " |        name: A string representing the name of the network.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `input_tensor_spec` contains more than one observation. Or\n",
      " |          if `action_spec` contains more than one action.\n",
      " |  \n",
      " |  call(self, observation, step_type=None, network_state=(), training=False)\n",
      " |      Runs the given observation through the network.\n",
      " |      \n",
      " |      Args:\n",
      " |        observation: The observation to provide to the network.\n",
      " |        step_type: The step type for the given observation. See `StepType` in\n",
      " |          time_step.py.\n",
      " |        network_state: A state tuple to pass to the network, mainly used by RNNs.\n",
      " |        training: Whether the output is being used for training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple `(logits, network_state)`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tf_agents.networks.network.Network:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      A wrapper around `Network.call`.\n",
      " |      \n",
      " |      A typical `call` method in a class subclassing `Network` will have a\n",
      " |      signature that accepts `inputs`, as well as other `*args` and `**kwargs`.\n",
      " |      `call` can optionally also accept `step_type` and `network_state`\n",
      " |      (if `state_spec != ()` is not trivial).  e.g.:\n",
      " |      \n",
      " |      ```python\n",
      " |      def call(self,\n",
      " |               inputs,\n",
      " |               step_type=None,\n",
      " |               network_state=(),\n",
      " |               training=False):\n",
      " |          ...\n",
      " |          return outputs, new_network_state\n",
      " |      ```\n",
      " |      \n",
      " |      We will validate the first argument (`inputs`)\n",
      " |      against `self.input_tensor_spec` if one is available.\n",
      " |      \n",
      " |      If a `network_state` kwarg is given it is also validated against\n",
      " |      `self.state_spec`.  Similarly, the return value of the `call` method is\n",
      " |      expected to be a tuple/list with 2 values:  `(output, new_state)`.\n",
      " |      We validate `new_state` against `self.state_spec`.\n",
      " |      \n",
      " |      If no `network_state` kwarg is given (or if empty `network_state = ()` is\n",
      " |      given, it is up to `call` to assume a proper \"empty\" state, and to\n",
      " |      emit an appropriate `output_state`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: The input to `self.call`, matching `self.input_tensor_spec`.\n",
      " |        *args: Additional arguments to `self.call`.\n",
      " |        **kwargs: Additional keyword arguments to `self.call`. These can include\n",
      " |          `network_state` and `step_type`.  `step_type` is required if the\n",
      " |          network's `call` requires it. `network_state` is required if the\n",
      " |          underlying network's `call` requires it.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple `(outputs, new_network_state)`.\n",
      " |  \n",
      " |  copy(self, **kwargs)\n",
      " |      Create a shallow copy of this network.\n",
      " |      \n",
      " |      **NOTE** Network layer weights are *never* copied.  This method recreates\n",
      " |      the `Network` instance with the same arguments it was initialized with\n",
      " |      (excepting any new kwargs).\n",
      " |      \n",
      " |      Args:\n",
      " |        **kwargs: Args to override when recreating this network.  Commonly\n",
      " |          overridden args include 'name'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A shallow copy of this network.\n",
      " |  \n",
      " |  create_variables(self, input_tensor_spec=None, **kwargs)\n",
      " |      Force creation of the network's variables.\n",
      " |      \n",
      " |      Return output specs.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_tensor_spec: (Optional).  Override or provide an input tensor spec\n",
      " |          when creating variables.\n",
      " |        **kwargs: Other arguments to `network.call()`, e.g. `training=True`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output specs - a nested spec calculated from the outputs (excluding any\n",
      " |        batch dimensions).  If any of the output elements is a tfp `Distribution`,\n",
      " |        the associated spec entry returned is a `DistributionSpec`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If no `input_tensor_spec` is provided, and the network did\n",
      " |          not provide one during construction.\n",
      " |  \n",
      " |  get_initial_state(self, batch_size=None)\n",
      " |      Returns an initial state usable by the network.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: Tensor or constant: size of the batch dimension. Can be None\n",
      " |          in which case not dimensions gets added.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A nested object of type `self.state_spec` containing properly\n",
      " |        initialized Tensors.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Args:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Args:\n",
      " |          line_length: Total length of printed lines (e.g. set this to adapt the\n",
      " |            display to different terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements in each line.\n",
      " |            If not provided, defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`. It will be called\n",
      " |            on each line of the summary. You can set it to a custom function in\n",
      " |            order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tf_agents.networks.network.Network:\n",
      " |  \n",
      " |  input_tensor_spec\n",
      " |      Returns the spec of the input to the network of type InputSpec.\n",
      " |  \n",
      " |  layers\n",
      " |      Get the list of all (nested) sub-layers used in this Network.\n",
      " |  \n",
      " |  state_spec\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
      " |      not themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be\n",
      " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
      " |      the same layer on different inputs `a` and `b`, some entries in\n",
      " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
      " |      automatically keeps track of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      The same code works in distributed training: the input to `add_loss()`\n",
      " |      is treated like a regularization loss and averaged across replicas\n",
      " |      by the training loop (both built-in `Model.fit()` and compliant custom\n",
      " |      training loops).\n",
      " |      \n",
      " |      The `add_loss` method can also be called directly on a Functional Model\n",
      " |      during construction. In this case, any loss Tensors passed to this Model\n",
      " |      must be symbolic and be able to be traced back to the model's `Input`s.\n",
      " |      These losses become part of the model's topology and are tracked in\n",
      " |      `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss\n",
      " |      references a `Variable` of one of the model's layers), you can wrap your\n",
      " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
      " |      the model's topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
      " |          losses may also be zero-argument callables which create a loss\n",
      " |          tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This\n",
      " |      is because we cannot trace the metric result tensor back to the model's\n",
      " |      inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result\n",
      " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
      " |          default using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and\n",
      " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
      " |      passed when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case,\n",
      " |      variable updates are run on the fly and thus do not need to be tracked\n",
      " |      for later execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use a `ResourceVariable` or not.\n",
      " |          See [this guide](\n",
      " |          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
      " |           for more information.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set\n",
      " |          to `AUTO` and the current `DistributionStrategy` chooses when to\n",
      " |          synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n",
      " |          must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as\n",
      " |          `ON_READ`.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call. It is invoked automatically before\n",
      " |      the first execution of `call()`.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses\n",
      " |      (at the discretion of the subclass implementer).\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  build_from_config(self, config)\n",
      " |      Builds the layer's states with the supplied config dict.\n",
      " |      \n",
      " |      By default, this method calls the `build(config[\"input_shape\"])` method,\n",
      " |      which creates weights based on the layer's input shape in the supplied\n",
      " |      config. If your config contains other information needed to load the\n",
      " |      layer's state, you should override this method.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: Dict containing the input shape associated with this layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,\n",
      " |              or structure of shape tuples / `tf.TensorShape` instances\n",
      " |              (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `tf.TensorShape` instance\n",
      " |          or structure of `tf.TensorShape` instances.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
      " |          describing how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after\n",
      " |      updating a layer weights. It can be overridden to finalize any\n",
      " |      additional layer state after a weight update.\n",
      " |      \n",
      " |      This function will be called after weights of a layer have been restored\n",
      " |      from a loaded model.\n",
      " |  \n",
      " |  get_build_config(self)\n",
      " |      Returns a dictionary with the layer's input shape.\n",
      " |      \n",
      " |      This method returns a config dict that can be used by\n",
      " |      `build_from_config(config)` to create all states (e.g. Variables and\n",
      " |      Lookup tables) needed by the layer.\n",
      " |      \n",
      " |      By default, the config only contains the input shape that the layer\n",
      " |      was built with. If you're writing a custom layer that creates state in\n",
      " |      an unusual way, you should override this method to make sure this state\n",
      " |      is already created when Keras attempts to load its value upon model\n",
      " |      loading.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict containing the input shape associated with the layer.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of\n",
      " |      dict every time it is called. The callers should make a copy of the\n",
      " |      returned dict if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with\n",
      " |      this layer as a list of NumPy arrays, which can in turn be used to load\n",
      " |      state into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  load_own_variables(self, store)\n",
      " |      Loads the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is loaded upon calling `keras.models.load_model()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict from which the state of the model will be loaded.\n",
      " |  \n",
      " |  save_own_variables(self, store)\n",
      " |      Saves the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is saved upon calling `model.save()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict where the state of the model will be saved.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from tf_agents.networks.network._NetworkMeta\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which\n",
      " |      causes computations and the output to be in the compute dtype as well.\n",
      " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
      " |      have to insert these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision\n",
      " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
      " |      output will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is\n",
      " |      accessed, so it is eager safe: accessing `losses` under a\n",
      " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
      " |      variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics attached to the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are\n",
      " |      expected to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to\n",
      " |      enable the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
      " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a\n",
      " |      nicely-formatted error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from tf_agents.networks.network._NetworkMeta\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(QNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_net = QNetwork(env.observation_spec(), env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.agents.dqn.dqn_agent import DqnAgent\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DqnAgent in module tf_agents.agents.dqn.dqn_agent:\n",
      "\n",
      "class DqnAgent(tf_agents.agents.tf_agent.TFAgent)\n",
      " |  DqnAgent(time_step_spec: tf_agents.trajectories.time_step.TimeStep, action_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')]], q_network: tf_agents.networks.network.Network, optimizer: Union[keras.src.optimizers.optimizer.Optimizer, tensorflow.python.training.optimizer.Optimizer], observation_and_action_constraint_splitter: Optional[Callable[[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]], Iterable[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]]]] = None, epsilon_greedy: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = 0.1, n_step_update: int = 1, boltzmann_temperature: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = None, emit_log_probability: bool = False, target_q_network: Optional[tf_agents.networks.network.Network] = None, target_update_tau: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, target_update_period: int = 1, td_errors_loss_fn: Optional[Callable[..., Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor]]] = None, gamma: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, reward_scale_factor: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, gradient_clipping: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, NoneType] = None, debug_summaries: bool = False, summarize_grads_and_vars: bool = False, train_step_counter: Optional[tensorflow.python.ops.variables.Variable] = None, training_data_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], NoneType] = None, name: Optional[str] = None)\n",
      " |  \n",
      " |  A DQN Agent.\n",
      " |  \n",
      " |  Implements the DQN algorithm from\n",
      " |  \n",
      " |  \"Human level control through deep reinforcement learning\"\n",
      " |    Mnih et al., 2015\n",
      " |    https://deepmind.com/research/dqn/\n",
      " |  \n",
      " |  This agent also implements n-step updates. See \"Rainbow: Combining\n",
      " |  Improvements in Deep Reinforcement Learning\" by Hessel et al., 2017, for a\n",
      " |  discussion on its benefits: https://arxiv.org/abs/1710.02298\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DqnAgent\n",
      " |      tf_agents.agents.tf_agent.TFAgent\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, time_step_spec: tf_agents.trajectories.time_step.TimeStep, action_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')]], q_network: tf_agents.networks.network.Network, optimizer: Union[keras.src.optimizers.optimizer.Optimizer, tensorflow.python.training.optimizer.Optimizer], observation_and_action_constraint_splitter: Optional[Callable[[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]], Iterable[Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], ForwardRef('tf_agents.specs.array_spec.ArraySpec'), Iterable[ForwardRef('NestedArraySpec')], Mapping[str, ForwardRef('NestedArraySpec')], tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')], numpy.ndarray, int, float, str, bool, Iterable[ForwardRef('NestedArray')], Mapping[str, ForwardRef('NestedArray')]]]]] = None, epsilon_greedy: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = 0.1, n_step_update: int = 1, boltzmann_temperature: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, Callable[[], Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool]], NoneType] = None, emit_log_probability: bool = False, target_q_network: Optional[tf_agents.networks.network.Network] = None, target_update_tau: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, target_update_period: int = 1, td_errors_loss_fn: Optional[Callable[..., Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor]]] = None, gamma: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, reward_scale_factor: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool] = 1.0, gradient_clipping: Union[float, numpy.float16, numpy.float32, numpy.float64, tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, numpy.ndarray, int, str, bool, NoneType] = None, debug_summaries: bool = False, summarize_grads_and_vars: bool = False, train_step_counter: Optional[tensorflow.python.ops.variables.Variable] = None, training_data_spec: Union[tensorflow.python.framework.type_spec.TypeSpec, tensorflow.python.framework.tensor.TensorSpec, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec, tensorflow.python.framework.sparse_tensor.SparseTensorSpec, ForwardRef('tf_agents.distributions.utils.DistributionSpecV2'), Iterable[ForwardRef('NestedTensorSpec')], Mapping[str, ForwardRef('NestedTensorSpec')], NoneType] = None, name: Optional[str] = None)\n",
      " |      Creates a DQN Agent.\n",
      " |      \n",
      " |      Args:\n",
      " |        time_step_spec: A `TimeStep` spec of the expected time_steps.\n",
      " |        action_spec: A nest of BoundedTensorSpec representing the actions.\n",
      " |        q_network: A `tf_agents.network.Network` to be used by the agent. The\n",
      " |          network will be called with `call(observation, step_type)` and should\n",
      " |          emit logits over the action space.\n",
      " |        optimizer: The optimizer to use for training.\n",
      " |        observation_and_action_constraint_splitter: A function used to process\n",
      " |          observations with action constraints. These constraints can indicate,\n",
      " |          for example, a mask of valid/invalid actions for a given state of the\n",
      " |          environment. The function takes in a full observation and returns a\n",
      " |          tuple consisting of 1) the part of the observation intended as input to\n",
      " |          the network and 2) the constraint. An example\n",
      " |          `observation_and_action_constraint_splitter` could be as simple as: ```\n",
      " |          def observation_and_action_constraint_splitter(observation): return\n",
      " |          observation['network_input'], observation['constraint'] ``` *Note*: when\n",
      " |          using `observation_and_action_constraint_splitter`, make sure the\n",
      " |          provided `q_network` is compatible with the network-specific half of the\n",
      " |          output of the `observation_and_action_constraint_splitter`. In\n",
      " |          particular, `observation_and_action_constraint_splitter` will be called\n",
      " |          on the observation before passing to the network. If\n",
      " |          `observation_and_action_constraint_splitter` is None, action constraints\n",
      " |          are not applied.\n",
      " |        epsilon_greedy: probability of choosing a random action in the default\n",
      " |          epsilon-greedy collect policy (used only if a wrapper is not provided to\n",
      " |          the collect_policy method). Only one of epsilon_greedy and\n",
      " |          boltzmann_temperature should be provided.\n",
      " |        n_step_update: The number of steps to consider when computing TD error and\n",
      " |          TD loss. Defaults to single-step updates. Note that this requires the\n",
      " |          user to call train on Trajectory objects with a time dimension of\n",
      " |          `n_step_update + 1`. However, note that we do not yet support\n",
      " |          `n_step_update > 1` in the case of RNNs (i.e., non-empty\n",
      " |          `q_network.state_spec`).\n",
      " |        boltzmann_temperature: Temperature value to use for Boltzmann sampling of\n",
      " |          the actions during data collection. The closer to 0.0, the higher the\n",
      " |          probability of choosing the best action. Only one of epsilon_greedy and\n",
      " |          boltzmann_temperature should be provided.\n",
      " |        emit_log_probability: Whether policies emit log probabilities or not.\n",
      " |        target_q_network: (Optional.)  A `tf_agents.network.Network` to be used as\n",
      " |          the target network during Q learning.  Every `target_update_period`\n",
      " |          train steps, the weights from `q_network` are copied (possibly with\n",
      " |          smoothing via `target_update_tau`) to `target_q_network`.  If\n",
      " |          `target_q_network` is not provided, it is created by making a copy of\n",
      " |          `q_network`, which initializes a new network with the same structure and\n",
      " |          its own layers and weights.  Network copying is performed via the\n",
      " |          `Network.copy` superclass method, and may inadvertently lead to the\n",
      " |          resulting network to share weights with the original.  This can happen\n",
      " |          if, for example, the original network accepted a pre-built Keras layer\n",
      " |          in its `__init__`, or accepted a Keras layer that wasn't built, but\n",
      " |          neglected to create a new copy.  In these cases, it is up to you to\n",
      " |          provide a target Network having weights that are not shared with the\n",
      " |          original `q_network`. If you provide a `target_q_network` that shares\n",
      " |          any weights with `q_network`, a warning will be logged but no exception\n",
      " |          is thrown.  Note; shallow copies of Keras layers may be built via the\n",
      " |          code ```python new_layer =\n",
      " |          type(layer).from_config(layer.get_config())```\n",
      " |        target_update_tau: Factor for soft update of the target networks.\n",
      " |        target_update_period: Period for soft update of the target networks.\n",
      " |        td_errors_loss_fn: A function for computing the TD errors loss. If None, a\n",
      " |          default value of element_wise_huber_loss is used. This function takes as\n",
      " |          input the target and the estimated Q values and returns the loss for\n",
      " |          each element of the batch.\n",
      " |        gamma: A discount factor for future rewards.\n",
      " |        reward_scale_factor: Multiplicative scale for the reward.\n",
      " |        gradient_clipping: Norm length to clip gradients.\n",
      " |        debug_summaries: A bool to gather debug summaries.\n",
      " |        summarize_grads_and_vars: If True, gradient and network variable summaries\n",
      " |          will be written during training.\n",
      " |        train_step_counter: An optional counter to increment every time the train\n",
      " |          op is run.  Defaults to the global_step.\n",
      " |        training_data_spec: A nest of TensorSpec specifying the structure of data\n",
      " |          the train() function expects. If None, defaults to the trajectory_spec\n",
      " |          of the collect_policy.\n",
      " |        name: The name of this agent. All variables in this module will fall under\n",
      " |          that name. Defaults to the class name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `action_spec` contains more than one action or action\n",
      " |          spec minimum is not equal to 0.\n",
      " |        ValueError: If the q networks do not emit floating point outputs with\n",
      " |          inner shape matching `action_spec`.\n",
      " |        NotImplementedError: If `q_network` has non-empty `state_spec` (i.e., an\n",
      " |          RNN is provided) and `n_step_update > 1`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tf_agents.agents.tf_agent.TFAgent:\n",
      " |  \n",
      " |  initialize(self) -> Optional[tensorflow.python.framework.ops.Operation]\n",
      " |      Initializes the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An operation that can be used to initialize the agent.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  loss(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], weights: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, NoneType] = None, training: bool = False, **kwargs) -> tf_agents.agents.tf_agent.LossInfo\n",
      " |      Gets loss from the agent.\n",
      " |      \n",
      " |      If the user calls this from _train, it must be in a `tf.GradientTape` scope\n",
      " |      in order to apply gradients to trainable variables.\n",
      " |      If intermediate gradient steps are needed, _loss and _train will return\n",
      " |      different values since _loss only supports updating all gradients at once\n",
      " |      after all losses have been calculated.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: A batch of experience data in the form of a `Trajectory`. The\n",
      " |          structure of `experience` must match that of `self.training_data_spec`.\n",
      " |          All tensors in `experience` must be shaped `[batch, time, ...]` where\n",
      " |          `time` must be equal to `self.train_step_length` if that property is not\n",
      " |          `None`.\n",
      " |        weights: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`,\n",
      " |          containing weights to be used when calculating the total train loss.\n",
      " |          Weights are typically multiplied elementwise against the per-batch loss,\n",
      " |          but the implementation is up to the Agent.\n",
      " |        training: Explicit argument to pass to `loss`. This typically affects\n",
      " |          network computation paths like dropout and batch normalization.\n",
      " |        **kwargs: Any additional data as args to `loss`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `LossInfo` loss tuple containing loss and info tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  post_process_policy(self) -> tf_agents.policies.tf_policy.TFPolicy\n",
      " |      Post process policies after training.\n",
      " |      \n",
      " |      The policies of some agents require expensive post processing after training\n",
      " |      before they can be used. e.g. A Recommender agent might require rebuilding\n",
      " |      an index of actions. For such agents, this method will return a post\n",
      " |      processed version of the policy. The post processing may either update the\n",
      " |      existing policies in place or create a new policy, depnding on the agent.\n",
      " |      The default implementation for agents that do not want to override this\n",
      " |      method is to return agent.policy.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The post processed policy.\n",
      " |  \n",
      " |  preprocess_sequence(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]]) -> Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]]\n",
      " |      Defines preprocess_sequence function to be fed into replay buffers.\n",
      " |      \n",
      " |      This defines how we preprocess the collected data before training.\n",
      " |      Defaults to pass through for most agents.\n",
      " |      Structure of `experience` must match that of `self.collect_data_spec`.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: a `Trajectory` shaped [batch, time, ...] or [time, ...] which\n",
      " |          represents the collected experience data.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A post processed `Trajectory` with the same shape as the input.\n",
      " |  \n",
      " |  train(self, experience: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, Iterable[ForwardRef('NestedTensor')], Mapping[str, ForwardRef('NestedTensor')]], weights: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.EagerTensor, NoneType] = None, **kwargs) -> tf_agents.agents.tf_agent.LossInfo\n",
      " |      Trains the agent.\n",
      " |      \n",
      " |      Args:\n",
      " |        experience: A batch of experience data in the form of a `Trajectory`. The\n",
      " |          structure of `experience` must match that of `self.training_data_spec`.\n",
      " |          All tensors in `experience` must be shaped `[batch, time, ...]` where\n",
      " |          `time` must be equal to `self.train_step_length` if that property is not\n",
      " |          `None`.\n",
      " |        weights: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`,\n",
      " |          containing weights to be used when calculating the total train loss.\n",
      " |          Weights are typically multiplied elementwise against the per-batch loss,\n",
      " |          but the implementation is up to the Agent.\n",
      " |        **kwargs: Any additional data to pass to the subclass.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `LossInfo` loss tuple containing loss and info tensors.\n",
      " |          - In eager mode, the loss values are first calculated, then a train step\n",
      " |            is performed before they are returned.\n",
      " |          - In graph mode, executing any or all of the loss tensors\n",
      " |            will first calculate the loss value(s), then perform a train step,\n",
      " |            and return the pre-train-step `LossInfo`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the class was not initialized properly (`super.__init__`\n",
      " |          was not called).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tf_agents.agents.tf_agent.TFAgent:\n",
      " |  \n",
      " |  action_spec\n",
      " |      TensorSpec describing the action produced by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An single BoundedTensorSpec, or a nested dict, list or tuple of\n",
      " |        `BoundedTensorSpec` objects, which describe the shape and\n",
      " |        dtype of each action Tensor.\n",
      " |  \n",
      " |  collect_data_context\n",
      " |  \n",
      " |  collect_data_spec\n",
      " |      Returns a `Trajectory` spec, as expected by the `collect_policy`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Trajectory` spec.\n",
      " |  \n",
      " |  collect_policy\n",
      " |      Return a policy that can be used to collect data from the environment.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf_policy.TFPolicy` object.\n",
      " |  \n",
      " |  data_context\n",
      " |  \n",
      " |  debug_summaries\n",
      " |  \n",
      " |  policy\n",
      " |      Return the current policy held by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf_policy.TFPolicy` object.\n",
      " |  \n",
      " |  summaries_enabled\n",
      " |  \n",
      " |  summarize_grads_and_vars\n",
      " |  \n",
      " |  time_step_spec\n",
      " |      Describes the `TimeStep` tensors expected by the agent.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `TimeStep` namedtuple with `TensorSpec` objects instead of Tensors,\n",
      " |        which describe the shape, dtype and name of each tensor.\n",
      " |  \n",
      " |  train_sequence_length\n",
      " |      The number of time steps needed in experience tensors passed to `train`.\n",
      " |      \n",
      " |      Train requires experience to be a `Trajectory` containing tensors shaped\n",
      " |      `[B, T, ...]`.  This argument describes the value of `T` required.\n",
      " |      \n",
      " |      For example, for non-RNN DQN training, `T=2` because DQN requires single\n",
      " |      transitions.\n",
      " |      \n",
      " |      If this value is `None`, then `train` can handle an unknown `T` (it can be\n",
      " |      determined at runtime from the data).  Most RNN-based agents fall into\n",
      " |      this category.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The number of time steps needed in experience tensors passed to `train`.\n",
      " |        May be `None` to mean no constraint.\n",
      " |  \n",
      " |  train_step_counter\n",
      " |  \n",
      " |  training_data_spec\n",
      " |      Returns a trajectory spec, as expected by the train() function.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from abc.ABCMeta\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  variables\n",
      " |      Sequence of variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.trackable.autotrackable.AutoTrackable:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DqnAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "loss = MeanSquaredError('none', 'mean_squared_error')\n",
    "loss_fn = loss.call\n",
    "discount_factor = 0.95\n",
    "epsilon_fn = PolynomialDecay(\n",
    "    initial_learning_rate=1.0,\n",
    "    decay_steps=1600,\n",
    "    end_learning_rate=0.0,\n",
    "    power=1\n",
    "    )\n",
    "target_model_update = 50\n",
    "train_step = tf.Variable(0)\n",
    "\n",
    "agent = DqnAgent(\n",
    "    env.time_step_spec(),\n",
    "    env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    gamma=discount_factor,\n",
    "    td_errors_loss_fn=loss_fn,\n",
    "    epsilon_greedy=lambda:epsilon_fn(train_step),\n",
    "    train_step_counter=train_step,\n",
    "    target_update_period=target_model_update,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32))})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Replay Buffer to store experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.replay_buffers.tf_uniform_replay_buffer import TFUniformReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32)),\n",
       " 'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = TFUniformReplayBuffer(\n",
    "    data_spec= agent.collect_data_spec,\n",
    "    batch_size= env.batch_size,\n",
    "    max_length= 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an observer to write into the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer_observer = replay_buffer.add_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer at 0x15603840b10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ReplayBuffer.add_batch of <tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer object at 0x0000015603840B10>>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer_observer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Driver that explores environment using a given policy, collects experience and broadcast them to observer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver\n",
    "from tf_agents.metrics import tf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = [\n",
    "    tf_metrics.AverageReturnMetric()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_driver = DynamicStepDriver(\n",
    "    env=env,\n",
    "    policy= agent.collect_policy,\n",
    "    observers= [replay_buffer_observer] + train_metrics,\n",
    "    num_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metrics[0].result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a driver to just fill the replay buffer with some experiences with a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_collect_policy = RandomTFPolicy(env.time_step_spec(), env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.random_tf_policy.RandomTFPolicy at 0x156037ea390>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_driver = DynamicStepDriver(\n",
    "    env,\n",
    "    initial_collect_policy,\n",
    "    [replay_buffer_observer],\n",
    "    num_steps=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time_step, final_policy_state = initial_driver.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 7.8460239e-02, -3.8251477e-01, -2.0286982e-04,  5.2276886e-01]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_policy_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset of sample a batch of trajectories for agent to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.trajectories.trajectory import to_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iitka\\AppData\\Local\\Temp\\ipykernel_9100\\3194907317.py:1: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "trajectories, buffer_info = replay_buffer.get_next(sample_batch_size=2, num_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[-0.04653021, -0.03298026, -0.03113363, -0.120386  ],\n",
       "        [-0.04718982,  0.1625736 , -0.03354136, -0.42272645],\n",
       "        [-0.04393835, -0.03205751, -0.04199588, -0.14080329]],\n",
       "\n",
       "       [[ 0.02501486,  0.16101441,  0.03516561, -0.2775992 ],\n",
       "        [ 0.02823515, -0.03459112,  0.02961363,  0.02596427],\n",
       "        [ 0.02754333, -0.23012497,  0.03013291,  0.32784158]]],\n",
       "      dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "array([[1, 0, 1],\n",
       "       [0, 0, 0]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BufferInfo(ids=<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "array([[746, 747, 748],\n",
       "       [ 51,  52,  53]], dtype=int64)>, probabilities=<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00095602, 0.00095602], dtype=float32)>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps, action_steps, next_time_steps = to_transition(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(2, 2, 4), dtype=float32, numpy=\n",
       "array([[[-0.04653021, -0.03298026, -0.03113363, -0.120386  ],\n",
       "        [-0.04718982,  0.1625736 , -0.03354136, -0.42272645]],\n",
       "\n",
       "       [[ 0.02501486,  0.16101441,  0.03516561, -0.2775992 ],\n",
       "        [ 0.02823515, -0.03459112,  0.02961363,  0.02596427]]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=<tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
       "array([[1, 0],\n",
       "       [0, 0]], dtype=int64)>, state=(), info=())"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=128,\n",
    "    num_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(Trajectory(\n",
       "{'step_type': TensorSpec(shape=(128, 2), dtype=tf.int32, name=None),\n",
       " 'observation': TensorSpec(shape=(128, 2, 4), dtype=tf.float32, name=None),\n",
       " 'action': TensorSpec(shape=(128, 2), dtype=tf.int64, name=None),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(128, 2), dtype=tf.int32, name=None),\n",
       " 'reward': TensorSpec(shape=(128, 2), dtype=tf.float32, name=None),\n",
       " 'discount': TensorSpec(shape=(128, 2), dtype=tf.float32, name=None)}), BufferInfo(ids=TensorSpec(shape=(128, 2), dtype=tf.int64, name=None), probabilities=TensorSpec(shape=(128,), dtype=tf.float32, name=None)))>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x15604f3d910>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2]])>,\n",
       "  'observation': <tf.Tensor: shape=(128, 2, 4), dtype=float32, numpy=\n",
       " array([[[ 2.1076391e-02,  4.2004785e-01, -5.3900755e-03, -5.6867796e-01],\n",
       "         [ 2.9477347e-02,  6.1524498e-01, -1.6763635e-02, -8.6305410e-01]],\n",
       " \n",
       "        [[-3.7360109e-02, -2.2499201e-01,  6.6162534e-02,  3.6323202e-01],\n",
       "         [-4.1859951e-02, -3.0869735e-02,  7.3427171e-02,  9.2123292e-02]],\n",
       " \n",
       "        [[ 8.9261485e-03, -5.0334817e-01, -2.0296235e-01, -2.6204532e-01],\n",
       "         [-1.1408154e-03, -3.0599499e-01, -2.0820326e-01, -6.1126083e-01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.0578941e-01, -9.4311750e-01,  1.4359808e-01,  1.5467811e+00],\n",
       "         [-1.2465176e-01, -7.4998212e-01,  1.7453369e-01,  1.3021326e+00]],\n",
       " \n",
       "        [[-2.0716531e-02,  6.0990256e-01, -8.6020872e-02, -9.5196313e-01],\n",
       "         [-8.5184798e-03,  8.0607015e-01, -1.0506014e-01, -1.2703855e+00]],\n",
       " \n",
       "        [[-7.1289092e-02, -1.2120525e+00,  1.8216750e-01,  1.9565887e+00],\n",
       "         [-9.5530137e-02, -1.0192720e+00,  2.2129928e-01,  1.7254643e+00]]],\n",
       "       dtype=float32)>,\n",
       "  'action': <tf.Tensor: shape=(128, 2), dtype=int64, numpy=\n",
       " array([[1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0]], dtype=int64)>,\n",
       "  'policy_info': (),\n",
       "  'next_step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [2, 0]])>,\n",
       "  'reward': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32)>,\n",
       "  'discount': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.]], dtype=float32)>}),\n",
       " BufferInfo(ids=<tf.Tensor: shape=(128, 2), dtype=int64, numpy=\n",
       " array([[ 395,  396],\n",
       "        [ 530,  531],\n",
       "        [ 426,  427],\n",
       "        [ 218,  219],\n",
       "        [ 949,  950],\n",
       "        [ 715,  716],\n",
       "        [ 781,  782],\n",
       "        [ 315,  316],\n",
       "        [ 236,  237],\n",
       "        [ 637,  638],\n",
       "        [ 334,  335],\n",
       "        [  45,   46],\n",
       "        [ 485,  486],\n",
       "        [ 407,  408],\n",
       "        [ 419,  420],\n",
       "        [ 854,  855],\n",
       "        [ 401,  402],\n",
       "        [ 527,  528],\n",
       "        [ 782,  783],\n",
       "        [ 178,  179],\n",
       "        [ 529,  530],\n",
       "        [ 706,  707],\n",
       "        [ 590,  591],\n",
       "        [ 861,  862],\n",
       "        [ 323,  324],\n",
       "        [ 604,  605],\n",
       "        [ 231,  232],\n",
       "        [ 937,  938],\n",
       "        [1040, 1041],\n",
       "        [ 684,  685],\n",
       "        [ 340,  341],\n",
       "        [ 550,  551],\n",
       "        [  35,   36],\n",
       "        [ 264,  265],\n",
       "        [ 357,  358],\n",
       "        [ 761,  762],\n",
       "        [ 911,  912],\n",
       "        [ 986,  987],\n",
       "        [ 954,  955],\n",
       "        [ 934,  935],\n",
       "        [ 338,  339],\n",
       "        [ 240,  241],\n",
       "        [ 472,  473],\n",
       "        [ 314,  315],\n",
       "        [ 589,  590],\n",
       "        [ 303,  304],\n",
       "        [ 210,  211],\n",
       "        [ 159,  160],\n",
       "        [ 640,  641],\n",
       "        [ 200,  201],\n",
       "        [ 890,  891],\n",
       "        [ 871,  872],\n",
       "        [ 397,  398],\n",
       "        [ 579,  580],\n",
       "        [ 164,  165],\n",
       "        [ 103,  104],\n",
       "        [ 455,  456],\n",
       "        [  69,   70],\n",
       "        [ 846,  847],\n",
       "        [ 297,  298],\n",
       "        [ 200,  201],\n",
       "        [ 967,  968],\n",
       "        [ 998,  999],\n",
       "        [ 543,  544],\n",
       "        [ 386,  387],\n",
       "        [ 829,  830],\n",
       "        [ 526,  527],\n",
       "        [ 157,  158],\n",
       "        [ 696,  697],\n",
       "        [ 754,  755],\n",
       "        [ 101,  102],\n",
       "        [ 630,  631],\n",
       "        [ 246,  247],\n",
       "        [ 313,  314],\n",
       "        [ 213,  214],\n",
       "        [ 136,  137],\n",
       "        [ 971,  972],\n",
       "        [ 173,  174],\n",
       "        [ 965,  966],\n",
       "        [ 622,  623],\n",
       "        [ 321,  322],\n",
       "        [ 335,  336],\n",
       "        [ 803,  804],\n",
       "        [  36,   37],\n",
       "        [ 409,  410],\n",
       "        [ 955,  956],\n",
       "        [ 767,  768],\n",
       "        [ 133,  134],\n",
       "        [ 357,  358],\n",
       "        [ 375,  376],\n",
       "        [ 380,  381],\n",
       "        [ 378,  379],\n",
       "        [ 185,  186],\n",
       "        [ 825,  826],\n",
       "        [ 506,  507],\n",
       "        [ 764,  765],\n",
       "        [   8,    9],\n",
       "        [ 640,  641],\n",
       "        [ 314,  315],\n",
       "        [ 415,  416],\n",
       "        [ 225,  226],\n",
       "        [ 418,  419],\n",
       "        [  72,   73],\n",
       "        [ 341,  342],\n",
       "        [ 198,  199],\n",
       "        [ 412,  413],\n",
       "        [ 637,  638],\n",
       "        [  59,   60],\n",
       "        [ 623,  624],\n",
       "        [ 442,  443],\n",
       "        [1044, 1045],\n",
       "        [  30,   31],\n",
       "        [ 561,  562],\n",
       "        [ 585,  586],\n",
       "        [  37,   38],\n",
       "        [ 401,  402],\n",
       "        [ 594,  595],\n",
       "        [ 222,  223],\n",
       "        [ 696,  697],\n",
       "        [ 855,  856],\n",
       "        [ 238,  239],\n",
       "        [  97,   98],\n",
       "        [ 676,  677],\n",
       "        [  15,   16],\n",
       "        [ 872,  873],\n",
       "        [ 577,  578],\n",
       "        [ 434,  435],\n",
       "        [  60,   61]], dtype=int64)>, probabilities=<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511, 0.00095511, 0.00095511,\n",
       "        0.00095511, 0.00095511, 0.00095511], dtype=float32)>))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       "array([[0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [2, 0],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0]])>,\n",
       " 'observation': <tf.Tensor: shape=(128, 2, 4), dtype=float32, numpy=\n",
       "array([[[ 2.2144055e-02,  4.7823876e-02, -1.8327048e-02,  2.2325026e-02],\n",
       "        [ 2.3100533e-02, -1.4703052e-01, -1.7880546e-02,  3.0916968e-01]],\n",
       "\n",
       "       [[ 6.7675233e-02,  4.2306563e-01, -6.9919959e-02, -6.3654369e-01],\n",
       "        [ 7.6136544e-02,  2.2898488e-01, -8.2650833e-02, -3.6667359e-01]],\n",
       "\n",
       "       [[ 9.9294774e-02,  4.3097860e-01, -1.2512493e-01, -8.1542414e-01],\n",
       "        [ 1.0791434e-01,  2.3777167e-01, -1.4143342e-01, -5.6457031e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.3146286e-01,  5.4091489e-01, -1.5228419e-01, -9.7725821e-01],\n",
       "        [ 1.4228114e-01,  7.3771453e-01, -1.7182936e-01, -1.3136400e+00]],\n",
       "\n",
       "       [[-2.5874678e-02,  1.6461785e-01,  9.9498287e-02, -1.2080462e-01],\n",
       "        [-2.2582322e-02,  3.5818389e-01,  9.7082190e-02, -3.8051343e-01]],\n",
       "\n",
       "       [[ 1.7038164e-01,  5.5020911e-01, -2.3510908e-01, -1.0884014e+00],\n",
       "        [ 2.0100061e-04, -3.0635078e-02, -5.0376734e-04,  1.4144008e-02]]],\n",
       "      dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(128, 2), dtype=int64, numpy=\n",
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.utils.common import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DynamicStepDriver.run of <tf_agents.drivers.dynamic_step_driver.DynamicStepDriver object at 0x000001560383A110>>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x000001565FF54610>>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_driver.run = function(collect_driver.run)\n",
    "agent.train = function(agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x15605162310>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x156051635d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_policy.get_initial_state(env.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1])>,\n",
       "  'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       " array([[ 0.03337283,  0.18590651, -0.17194998, -0.7338841 ]],\n",
       "       dtype=float32)>}),\n",
       " ())"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_driver.run(None, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, ps = collect_driver.run(None,())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories, buffer_info = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'observation': <tf.Tensor: shape=(128, 2, 4), dtype=float32, numpy=\n",
       "array([[[-0.05313006, -0.573155  ,  0.03853654,  0.9019265 ],\n",
       "        [-0.06459315, -0.3785757 ,  0.05657507,  0.6216012 ]],\n",
       "\n",
       "       [[-0.01373483, -0.58444357,  0.10629775,  0.97723293],\n",
       "        [-0.0254237 , -0.39089516,  0.1258424 ,  0.71974176]],\n",
       "\n",
       "       [[ 0.01369639,  0.4117233 ,  0.03305893, -0.49997315],\n",
       "        [ 0.02193085,  0.60636395,  0.02305947, -0.7820571 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.01063721,  0.2438734 , -0.05304931, -0.35155955],\n",
       "        [ 0.01551468,  0.43970805, -0.0600805 , -0.6604875 ]],\n",
       "\n",
       "       [[-0.06248915, -0.387084  ,  0.0026987 ,  0.5831521 ],\n",
       "        [-0.07023083, -0.19199996,  0.01436174,  0.29132053]],\n",
       "\n",
       "       [[-0.09911014, -0.99597526,  0.00649541,  1.0614007 ],\n",
       "        [-0.11902965, -1.1911826 ,  0.02772343,  1.3561151 ]]],\n",
       "      dtype=float32)>,\n",
       " 'action': <tf.Tensor: shape=(128, 2), dtype=int64, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0]], dtype=int64)>,\n",
       " 'policy_info': (),\n",
       " 'next_step_type': <tf.Tensor: shape=(128, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>,\n",
       " 'reward': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(128, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32)),\n",
       " 'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " 'policy_info': (),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iitka\\.conda\\envs\\tf2.15\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LossInfo(loss=<tf.Tensor: shape=(), dtype=float32, numpy=1.0429308>, extra=DqnLossInfo(td_loss=<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 0.       , 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 0.       , 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       0.       , 1.0853264, 1.0853264, 1.0853264, 0.       , 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 0.       , 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264, 1.0853264,\n",
       "       1.0853264, 1.0853264], dtype=float32)>, td_error=<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([ 1.1582042 ,  1.1828451 ,  1.0665381 ,  1.0186961 ,  1.0484666 ,\n",
       "        1.0215676 ,  0.99510384,  1.0418957 ,  1.0643878 ,  1.2199833 ,\n",
       "        1.0209111 ,  1.0010737 ,  1.0217711 ,  1.1320949 ,  1.3387021 ,\n",
       "        1.0665381 ,  1.0443822 ,  1.0989503 ,  1.0216777 ,  1.0734881 ,\n",
       "        1.0792553 ,  0.9979372 ,  1.1102135 ,  1.0477195 ,  1.2597536 ,\n",
       "        1.1226697 ,  1.0024431 ,  1.1396618 ,  1.0185047 ,  1.0711418 ,\n",
       "        1.0020725 ,  1.1118189 ,  1.0208545 ,  1.020354  ,  1.1039186 ,\n",
       "        1.0203104 ,  1.018601  ,  1.0039886 , -0.        ,  0.99491405,\n",
       "        1.0213459 ,  1.001644  ,  1.0218111 ,  1.2399075 ,  1.0212469 ,\n",
       "        1.0764084 ,  1.0776244 ,  1.0955744 ,  0.9945591 ,  1.020977  ,\n",
       "        1.0388582 ,  1.1070954 ,  1.3183557 ,  0.99250156,  1.0402468 ,\n",
       "        1.0638458 ,  1.0210538 ,  0.9972067 ,  1.1082306 ,  1.0191383 ,\n",
       "        0.996799  , -0.        ,  1.0848932 ,  1.020843  ,  1.086574  ,\n",
       "        1.0017155 ,  0.        ,  1.2392    ,  1.1343699 ,  1.0219334 ,\n",
       "       -0.        ,  1.0160842 ,  1.0623009 ,  1.0227195 ,  1.0215542 ,\n",
       "        1.0054762 ,  0.        ,  1.0991249 ,  1.0100412 ,  1.1660819 ,\n",
       "        1.0206091 ,  1.0183884 ,  1.1466663 ,  0.99758947,  1.0375752 ,\n",
       "        1.0422733 ,  1.0269521 ,  1.1055901 ,  1.1090968 ,  1.0397906 ,\n",
       "        1.0163335 ,  1.0829424 ,  1.068421  ,  1.0190268 ,  1.0210953 ,\n",
       "        1.0209565 ,  1.0305419 ,  1.0211247 ,  1.0059268 ,  1.0270123 ,\n",
       "        1.0375752 ,  1.025929  ,  1.0227234 ,  1.01973   ,  1.0210327 ,\n",
       "        1.2403704 ,  1.0215545 ,  1.0191569 ,  1.2742159 ,  1.0464904 ,\n",
       "        0.9964198 ,  1.0279123 ,  1.020309  ,  1.0438354 ,  1.1075453 ,\n",
       "        1.1126022 ,  1.019514  ,  1.0219464 ,  1.0032125 ,  1.1100658 ,\n",
       "        0.99953604,  1.0370208 ,  1.0200521 ,  1.0758053 ,  1.0438354 ,\n",
       "        1.0379176 ,  1.0994189 ,  1.0180869 ], dtype=float32)>))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(n_iteration):\n",
    "    losses = []\n",
    "    avg_returns = []\n",
    "    train_step.assign(0)\n",
    "    time_step = None\n",
    "    policy_state = agent.collect_policy.get_initial_state(env.batch_size)\n",
    "    iterator = iter(dataset)\n",
    "\n",
    "    for iteration in range(n_iteration):\n",
    "        time_step, policy_state = collect_driver.run(time_step, policy_state)\n",
    "        trajectories, buffer_info = next(iterator)\n",
    "        train_loss = agent.train(trajectories)\n",
    "        loss = train_loss.loss.numpy()\n",
    "        avg_return = train_metrics[0].result().numpy()\n",
    "        losses.append(loss)\n",
    "        avg_returns.append(avg_return)\n",
    "        if train_step%50 == 0:\n",
    "            print(f'train step: {train_step.value()}      loss: {loss}     avg_return: {avg_return}')\n",
    "\n",
    "    return losses, avg_returns\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step: 50      loss: 1.0331037044525146     avg_return: 16.5\n",
      "train step: 100      loss: 1.2153359651565552     avg_return: 17.100000381469727\n",
      "train step: 150      loss: 1.284913420677185     avg_return: 23.600000381469727\n",
      "train step: 200      loss: 1.0926604270935059     avg_return: 20.700000762939453\n",
      "train step: 250      loss: 0.9317574501037598     avg_return: 18.899999618530273\n",
      "train step: 300      loss: 0.9085379242897034     avg_return: 17.600000381469727\n",
      "train step: 350      loss: 0.9430125951766968     avg_return: 33.29999923706055\n",
      "train step: 400      loss: 1.1868312358856201     avg_return: 24.600000381469727\n",
      "train step: 450      loss: 0.7493051290512085     avg_return: 38.70000076293945\n",
      "train step: 500      loss: 1.9475162029266357     avg_return: 65.0999984741211\n",
      "train step: 550      loss: 1.5751426219940186     avg_return: 53.900001525878906\n",
      "train step: 600      loss: 1.20961594581604     avg_return: 53.0\n",
      "train step: 650      loss: 1.6753227710723877     avg_return: 62.5\n",
      "train step: 700      loss: 0.8674540519714355     avg_return: 61.20000076293945\n",
      "train step: 750      loss: 1.1083130836486816     avg_return: 87.5\n",
      "train step: 800      loss: 0.5875909328460693     avg_return: 87.19999694824219\n",
      "train step: 850      loss: 0.5232527256011963     avg_return: 113.5\n",
      "train step: 900      loss: 1.322062373161316     avg_return: 102.0\n",
      "train step: 950      loss: 0.47722601890563965     avg_return: 138.1999969482422\n",
      "train step: 1000      loss: 0.21397684514522552     avg_return: 189.0\n",
      "train step: 1050      loss: 0.663214385509491     avg_return: 164.60000610351562\n",
      "train step: 1100      loss: 0.22387740015983582     avg_return: 162.6999969482422\n",
      "train step: 1150      loss: 0.3729613125324249     avg_return: 211.3000030517578\n",
      "train step: 1200      loss: 1.1324737071990967     avg_return: 183.1999969482422\n",
      "train step: 1250      loss: 0.15405625104904175     avg_return: 192.89999389648438\n",
      "train step: 1300      loss: 1.3289036750793457     avg_return: 184.39999389648438\n",
      "train step: 1350      loss: 0.18865813314914703     avg_return: 226.3000030517578\n",
      "train step: 1400      loss: 0.1681976616382599     avg_return: 185.3000030517578\n",
      "train step: 1450      loss: 0.15443044900894165     avg_return: 185.10000610351562\n",
      "train step: 1500      loss: 0.24014566838741302     avg_return: 243.5\n",
      "train step: 1550      loss: 1.1859331130981445     avg_return: 171.10000610351562\n",
      "train step: 1600      loss: 1.3308680057525635     avg_return: 208.5\n",
      "train step: 1650      loss: 0.07695826888084412     avg_return: 196.39999389648438\n",
      "train step: 1700      loss: 0.06399840116500854     avg_return: 209.5\n",
      "train step: 1750      loss: 0.09109518676996231     avg_return: 186.0\n",
      "train step: 1800      loss: 3.586616039276123     avg_return: 225.6999969482422\n",
      "train step: 1850      loss: 0.04540436342358589     avg_return: 173.39999389648438\n",
      "train step: 1900      loss: 0.03873177617788315     avg_return: 192.8000030517578\n",
      "train step: 1950      loss: 1.5479393005371094     avg_return: 159.5\n",
      "train step: 2000      loss: 1.3889844417572021     avg_return: 206.5\n"
     ]
    }
   ],
   "source": [
    "losses, avg_returns = train_agent(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'returns': avg_returns}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'losses': losses}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a evaluation environment to test policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_py_env = suite_gym.load('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tf_env = TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.04382595, -0.02935016, -0.02053633, -0.01220229], dtype=float32)})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_py_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.04247502, -0.03643599, -0.0249455 , -0.01637346]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tf_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.04247502, -0.03643599, -0.0249455 , -0.01637346], dtype=float32)})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_py_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.04247502, -0.03643599, -0.0249455 , -0.01637346]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tf_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tf_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.04247502, -0.03643599, -0.0249455 , -0.01637346]],\n",
       "      dtype=float32)>})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tf_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_py_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'step_type': array(0),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.04247502, -0.03643599, -0.0249455 , -0.01637346], dtype=float32)})"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_py_env.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.greedy_policy.GreedyPolicy at 0x1d718109e50>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0], dtype=int64)>, state=(), info=())"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.action(eval_tf_env.current_time_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    time_step = eval_tf_env.reset()\n",
    "\n",
    "    while not time_step.is_last():\n",
    "        time_step = eval_tf_env.step(policy.action(time_step))\n",
    "        eval_py_env.render(mode='human')\n",
    "\n",
    "eval_py_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_py_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a trained agent policy to be used in another program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies.policy_saver import PolicySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_saver = PolicySaver(policy= agent.policy, batch_size=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
